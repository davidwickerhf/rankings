{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Centrality Metrics\n",
    "\n",
    "This notebook analyzes and compares different centrality metrics for a citation network.\n",
    "\n",
    "It loads node and edge data from JSON files, calculates various centrality metrics (like degree, betweenness, closeness etc.), and compares them against ground truth measures like importance and document type.\n",
    "\n",
    "The notebook defines constants for:\n",
    "- Input data file paths\n",
    "- Centrality metrics to analyze \n",
    "- Ground truth measures to compare against\n",
    "\n",
    "It also defines TypedDict classes to type the network statistics and results.\n",
    "\n",
    "**Note:** This is an analysis notebook. To modify the code that generates the network and calculates centralities, please refer to the Main section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Union, TypedDict, Tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkStats(TypedDict):\n",
    "    n_nodes: int\n",
    "    n_edges: int\n",
    "\n",
    "class BestCentralities(TypedDict):\n",
    "    high: str\n",
    "    low: str\n",
    "\n",
    "class AnalysisResults(TypedDict):\n",
    "    network_stats: NetworkStats\n",
    "    correlations: Dict[str, Dict[str, Dict[tuple[str, str], float]]]  # ground_truth -> composite_function -> (centrality, ground_truth) -> correlation\n",
    "    best_centralities: Dict[str, BestCentralities]  # ground_truth -> best centralities\n",
    "    composite_rankings: Dict[str, Dict[str, Dict[str, float]]]  # ground_truth -> composite_function -> ecli -> rank\n",
    "    dataframe: pd.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert doctypebranch to a numeric value\n",
    "def categorise_total_branch_numerically(branches: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Convert branch categorisation from strings into numbers.\n",
    "    \n",
    "    :param branches: The column containing branch data, categorized with strings.\n",
    "    :return: A pandas Series with numerical categorization.\n",
    "    \"\"\"\n",
    "    mapping = {\n",
    "        \"GRANDCHAMBER\": 1,\n",
    "        \"CHAMBER\": 2,\n",
    "        \"COMMITTEE\": 3,\n",
    "    }\n",
    "    \n",
    "    # Convert to uppercase to ensure consistent matching\n",
    "    branches = branches.str.upper()\n",
    "    \n",
    "    # Print any values that don't match our mapping\n",
    "    unmapped = set(branches.unique()) - set(mapping.keys())\n",
    "    if unmapped:\n",
    "        print(f\"Warning: Found unmapped values: {unmapped}\")\n",
    "    \n",
    "    return branches.map(mapping)\n",
    "\n",
    "def prep_data(df: pd.DataFrame, include: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare the dataset by selecting the appropriate columns and filtering out rows with uncomputed metric values.\n",
    "    \n",
    "    :param df: The DataFrame to process.\n",
    "    :param include: Columns to include.\n",
    "    :return: The processed DataFrame.\n",
    "    \"\"\"\n",
    "    headers = include + ['ecli']  # Ensure essential columns are included\n",
    "    headers = list(set(headers))  # Removing duplicates\n",
    "\n",
    "    data = df[headers]\n",
    "\n",
    "    # Filter out rows with uncomputed metric values (-2)\n",
    "    metric_column = include[-1]\n",
    "    data = data[data[metric_column] >= -1]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centrality Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_disruptions_new(graph: nx.Graph) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate the disruption score for each node in the graph.\n",
    "\n",
    "    Args:\n",
    "        graph (nx.Graph): The input directed graph.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with nodes as keys and their disruption scores as values.\n",
    "    \"\"\"\n",
    "    disruptions = {}\n",
    "    for node in graph.nodes:\n",
    "        i, j, k = 0, 0, 0\n",
    "\n",
    "        # count j\n",
    "        for in_node in graph.predecessors(node):\n",
    "            for out_node in graph.successors(node):\n",
    "                if graph.has_edge(in_node, out_node):\n",
    "                    j += 1\n",
    "                    break\n",
    "\n",
    "        # count i\n",
    "        i = graph.in_degree(node) - j\n",
    "\n",
    "        # count k\n",
    "        for out_node in graph.successors(node):\n",
    "            for in_out_node in graph.predecessors(out_node):\n",
    "                if in_out_node != node and not graph.has_edge(in_out_node, node):\n",
    "                    k += 1\n",
    "\n",
    "        try:\n",
    "            disruptions[node] = (i - j) / (i + j + k)\n",
    "        except ZeroDivisionError:\n",
    "            disruptions[node] = np.nan\n",
    "\n",
    "    return disruptions\n",
    "\n",
    "\n",
    "# Function to calculate centrality measures\n",
    "def calculate_centrality_measures(graph):\n",
    "    \"\"\"Calculate various centrality measures for the graph.\"\"\"\n",
    "    measures = {\n",
    "        'degree_centrality': nx.degree_centrality(graph),\n",
    "        'in_degree_centrality': nx.in_degree_centrality(graph),\n",
    "        'out_degree_centrality': nx.out_degree_centrality(graph),\n",
    "        'betweenness_centrality': nx.betweenness_centrality(graph),\n",
    "        'closeness_centrality': nx.closeness_centrality(graph),\n",
    "        'core_number': nx.core_number(graph),\n",
    "        'relative_in_degree_centrality': {node: degree/len(graph) \n",
    "                                        for node, degree in graph.in_degree()},\n",
    "        'harmonic_centrality': nx.harmonic_centrality(graph)\n",
    "    }\n",
    "    \n",
    "    # Handle potentially failing measures with try-except\n",
    "    try:\n",
    "        measures['eigenvector_centrality'] = nx.eigenvector_centrality(graph, max_iter=1000)\n",
    "    except (nx.PowerIterationFailedConvergence, nx.NetworkXError):\n",
    "        # Fill with zeros if calculation fails\n",
    "        measures['eigenvector_centrality'] = {node: 0.0 for node in graph.nodes()}\n",
    "    \n",
    "    try:\n",
    "        measures['pagerank'] = nx.pagerank(graph)\n",
    "    except:\n",
    "        measures['pagerank'] = {node: 0.0 for node in graph.nodes()}\n",
    "    \n",
    "    try:\n",
    "        hub_dict, authority_dict = nx.hits(graph)\n",
    "        measures['hits_hub'] = hub_dict\n",
    "        measures['hits_authority'] = authority_dict\n",
    "    except:\n",
    "        measures['hits_hub'] = {node: 0.0 for node in graph.nodes()}\n",
    "        measures['hits_authority'] = {node: 0.0 for node in graph.nodes()}\n",
    "    \n",
    "    try:\n",
    "        measures['disruption'] = calculate_disruptions_new(graph)\n",
    "    except:\n",
    "        measures['disruption'] = {node: 0.0 for node in graph.nodes()}\n",
    "        \n",
    "    return measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composite Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script analyzes the relationship between various centrality measures and ground truth scores\n",
    "for legal cases. It aims to find the best centrality measures for predicting high and low relevance\n",
    "scores, create a composite ranking, and evaluate its performance against individual centrality measures.\n",
    "\n",
    "The main steps are:\n",
    "1. Plot error bars for centrality measures vs. ground truth scores\n",
    "2. Find the best centrality measures for predicting high and low scores\n",
    "3. Create a composite ranking using the best measures\n",
    "4. Calculate correlations between rankings and ground truth scores\n",
    "5. Visualize and save the results\n",
    "\"\"\"\n",
    "\n",
    "def plot_error_bars(df, centrality, ground_truth):\n",
    "    \"\"\"\n",
    "    Plot error bars for a given centrality measure against a ground truth score.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the data\n",
    "    centrality (str): The name of the centrality measure column\n",
    "    ground_truth (str): The name of the ground truth score column\n",
    "\n",
    "    This function visualizes the relationship between a centrality measure and a ground truth score,\n",
    "    showing the mean centrality value for each ground truth score category along with error bars\n",
    "    representing the standard deviation.\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    include = [ground_truth, centrality]\n",
    "    data = prep_data(df, include)\n",
    "\n",
    "    x_header = centrality\n",
    "    y_header = ground_truth\n",
    "    x, y = list(data[x_header]), list(data[y_header])\n",
    "    categories = list(set(y))\n",
    "    categories.sort()\n",
    "    num_categories, num_instances = len(categories), len(x)\n",
    "    y_instances = [[] for _ in range(num_categories)]\n",
    "    for category_no in range(num_categories):\n",
    "        for instance_no in range(num_instances):\n",
    "            if y[instance_no] == categories[category_no]:\n",
    "                y_instances[category_no].append(x[instance_no])\n",
    "    x = [statistics.mean(y_instances[category_no]) for category_no in range(num_categories)]\n",
    "    y = categories\n",
    "\n",
    "    # Draw graph\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    title = f\"{centrality.capitalize()} vs Average {y_header.capitalize()}\"\n",
    "    plt.suptitle(title, fontsize=22)\n",
    "    plt.xlabel(f\"{centrality.capitalize()}\", fontsize=22)\n",
    "    plt.ylabel(f\"{y_header.capitalize()}\", fontsize=22)\n",
    "    plt.yticks(categories, fontsize=16)\n",
    "\n",
    "    # Calculate error bars\n",
    "    stds = [statistics.stdev(y_instances[category_no]) for category_no in range(num_categories)]\n",
    "    plt.errorbar(x, y, xerr=stds, fmt='o')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def find_best_centralities(df, centralities, ground_truth):\n",
    "    \"\"\"\n",
    "    Find the best centrality measures for predicting high and low ground truth scores.\n",
    "    TODO: Include considerations for multiple ground truth scores\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the data\n",
    "    centralities (list): List of centrality measure column names\n",
    "    ground_truth (str): The name of the ground truth score column\n",
    "\n",
    "    Returns:\n",
    "    tuple: (best_high, best_low) - the names of the best centrality measures for high and low scores\n",
    "\n",
    "    This function calculates the Spearman correlation between each centrality measure and the ground truth,\n",
    "    using 1 - |correlation| as an error metric. The centrality with the lowest error is chosen as best_high,\n",
    "    and the second-lowest (excluding best_high) is chosen as best_low.\n",
    "    \"\"\"\n",
    "    errors = {}\n",
    "    \n",
    "    for centrality in centralities:\n",
    "        # Calculate correlation across the full range\n",
    "        corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
    "        errors[centrality] = 1 - abs(corr)  # Use 1 - |correlation| as error\n",
    "    \n",
    "    best_high = min(errors, key=errors.get)\n",
    "    \n",
    "    # Remove the best_high centrality from consideration for best_low\n",
    "    errors.pop(best_high, None)\n",
    "    \n",
    "    best_low = min(errors, key=errors.get)\n",
    "    \n",
    "    return best_high, best_low\n",
    "\n",
    "def rank_cases(df, centrality):\n",
    "    \"\"\"\n",
    "    Rank cases based on a given centrality measure.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the data\n",
    "    centrality (str): The name of the centrality measure column\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: A series of rankings for each case\n",
    "\n",
    "    This function ranks the cases in descending order of the centrality measure,\n",
    "    with the highest centrality receiving rank 1.\n",
    "    \"\"\"\n",
    "    return df[centrality].rank(ascending=False)\n",
    "\n",
    "def create_treashold_composite_ranking(df, high_centrality, low_centrality, ground_truth):\n",
    "    \"\"\"\n",
    "    Create a composite ranking based on a threshold approach using two centrality measures.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the centrality measures\n",
    "        high_centrality: Centrality measure that performs best for high scores\n",
    "        low_centrality: Centrality measure that performs best for low scores\n",
    "        ground_truth: Name of the ground truth column\n",
    "        \n",
    "    Returns:\n",
    "        Series containing the composite ranking\n",
    "    \"\"\"\n",
    "    # Normalize both centrality measures to [0,1] range\n",
    "    high_normalized = (df[high_centrality] - df[high_centrality].min()) / (df[high_centrality].max() - df[high_centrality].min())\n",
    "    low_normalized = (df[low_centrality] - df[low_centrality].min()) / (df[low_centrality].max() - df[low_centrality].min())\n",
    "    \n",
    "    # Find optimal threshold by testing different values\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    best_correlation = -1\n",
    "    optimal_threshold = 0\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        # Create composite ranking using current threshold\n",
    "        composite = np.where(\n",
    "            high_normalized > threshold,\n",
    "            high_normalized,  # Use high centrality measure\n",
    "            low_normalized    # Use low centrality measure\n",
    "        )\n",
    "        \n",
    "        # Calculate correlation with ground truth\n",
    "        correlation = abs(spearmanr(composite, df[ground_truth])[0])\n",
    "        \n",
    "        # Update if better correlation found\n",
    "        if correlation > best_correlation:\n",
    "            best_correlation = correlation\n",
    "            optimal_threshold = threshold\n",
    "    \n",
    "    # Create final composite ranking using optimal threshold\n",
    "    final_composite = np.where(\n",
    "        high_normalized > optimal_threshold,\n",
    "        high_normalized,\n",
    "        low_normalized\n",
    "    )\n",
    "    \n",
    "    print(f\"Optimal threshold found: {optimal_threshold:.6f}\")\n",
    "    return final_composite\n",
    "\n",
    "def create_composite_ranking(df, high_centrality, low_centrality, weight):\n",
    "    \"\"\"\n",
    "    Create a composite ranking using two centrality measures.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the data\n",
    "    high_centrality (str): The name of the centrality measure best for high scores\n",
    "    low_centrality (str): The name of the centrality measure best for low scores\n",
    "    weight (float): The weight given to the high_centrality ranking (0-1)\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: A series of composite rankings for each case\n",
    "\n",
    "    This function creates a weighted average of the rankings from two centrality measures,\n",
    "    allowing for a balance between predicting high and low ground truth scores.\n",
    "    \"\"\"\n",
    "    high_ranks = rank_cases(df, high_centrality)\n",
    "    low_ranks = rank_cases(df, low_centrality)\n",
    "    return weight * high_ranks + (1 - weight) * low_ranks\n",
    "\n",
    "def find_optimal_weight(df, high_centrality, low_centrality, ground_truth):\n",
    "    \"\"\"\n",
    "    Find the optimal weight for creating a composite ranking.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the data\n",
    "    high_centrality (str): The name of the centrality measure best for high scores\n",
    "    low_centrality (str): The name of the centrality measure best for low scores\n",
    "    ground_truth (str): The name of the ground truth score column\n",
    "\n",
    "    Returns:\n",
    "    float: The optimal weight (0-1) for the high_centrality ranking\n",
    "\n",
    "    This function tests different weights to find the one that produces the composite ranking\n",
    "    with the highest correlation to the ground truth scores.\n",
    "    \"\"\"\n",
    "    best_corr = -1\n",
    "    best_weight = 0\n",
    "    for weight in np.arange(0, 1.01, 0.01):\n",
    "        composite = create_composite_ranking(df, high_centrality, low_centrality, weight)\n",
    "        corr, _ = stats.spearmanr(composite, df[ground_truth])\n",
    "        if abs(corr) > best_corr:\n",
    "            best_corr = abs(corr)\n",
    "            best_weight = weight\n",
    "    return best_weight\n",
    "\n",
    "def calculate_correlations(df, centralities, ground_truths, composite_ranking):\n",
    "    \"\"\"\n",
    "    Calculate correlations between rankings and ground truth scores.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the data\n",
    "    centralities (list): List of centrality measure column names\n",
    "    ground_truths (list): List of ground truth score column names\n",
    "    composite_ranking (str): The name of the composite ranking column\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary of correlation coefficients\n",
    "\n",
    "    This function calculates Spearman correlations between the rankings of each centrality measure\n",
    "    (including the composite ranking) and each ground truth score.\n",
    "    \"\"\"\n",
    "    correlations = {}\n",
    "    \n",
    "    for centrality in centralities:\n",
    "        centrality_ranking = rank_cases(df, centrality)\n",
    "        for ground_truth in ground_truths:\n",
    "            # Check if arrays have variation before calculating correlation\n",
    "            if df[centrality].nunique() > 1 and df[ground_truth].nunique() > 1:\n",
    "                corr, _ = stats.spearmanr(centrality_ranking, df[ground_truth])\n",
    "                correlations[(centrality, ground_truth)] = corr\n",
    "            else:\n",
    "                correlations[(centrality, ground_truth)] = np.nan\n",
    "    \n",
    "    for ground_truth in ground_truths:\n",
    "        if df[composite_ranking].nunique() > 1 and df[ground_truth].nunique() > 1:\n",
    "            corr, _ = stats.spearmanr(df[composite_ranking], df[ground_truth])\n",
    "            correlations[('composite', ground_truth)] = corr\n",
    "        else:\n",
    "            correlations[('composite', ground_truth)] = np.nan\n",
    "    \n",
    "    return correlations\n",
    "\n",
    "def plot_correlations(correlations, ground_truth, output_file, best_high, best_low):\n",
    "    \"\"\"\n",
    "    Plot correlations between rankings and ground truth scores.\n",
    "\n",
    "    Args:\n",
    "    correlations (dict): Dictionary of correlation coefficients\n",
    "    ground_truth (str): The name of the current ground truth score\n",
    "    output_file (str): The name of the output file for the plot\n",
    "    best_high (str): The name of the best centrality for high scores\n",
    "    best_low (str): The name of the best centrality for low scores\n",
    "\n",
    "    This function creates a bar plot showing the correlations between each centrality measure\n",
    "    (including the composite ranking) and the ground truth scores.\n",
    "    \"\"\"\n",
    "    centralities = list(set([k[0] for k in correlations.keys() if k[0] != 'composite']))\n",
    "    ground_truths = list(set([k[1] for k in correlations.keys()]))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Add text to show which centralities were used for the composite ranking\n",
    "    ax.text(0.02, 0.98, f\"Composite: {best_high} (high) + {best_low} (low)\", \n",
    "            transform=ax.transAxes, ha='left', va='top', \n",
    "            bbox=dict(facecolor='white', edgecolor='gray', alpha=0.8))\n",
    "    \n",
    "    x = np.arange(len(ground_truths))\n",
    "    width = 0.8 / (len(centralities) + 1)\n",
    "    \n",
    "    for i, centrality in enumerate(centralities + ['composite']):\n",
    "        offset = width * i - 0.4 + width/2\n",
    "        rects = ax.bar(x + offset, [correlations[(centrality, gt)] for gt in ground_truths], width, label=centrality)\n",
    "    \n",
    "    ax.set_ylabel('Correlation Coefficient')\n",
    "    ax.set_title(f'Correlations between Rankings and Ground Truths (optimized for {ground_truth})')\n",
    "    ax.set_xticks(x, ground_truths)\n",
    "    ax.legend(loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "\n",
    "def save_correlations_to_csv(correlations, ground_truth, output_file, best_high, best_low):\n",
    "    \"\"\"\n",
    "    Save correlation results to a CSV file.\n",
    "\n",
    "    Args:\n",
    "    correlations (dict): Dictionary of correlation coefficients\n",
    "    ground_truth (str): The name of the current ground truth score\n",
    "    output_file (str): The name of the output CSV file\n",
    "    best_high (str): The name of the best centrality for high scores\n",
    "    best_low (str): The name of the best centrality for low scores\n",
    "\n",
    "    This function saves the correlation results to a CSV file for further analysis or reporting.\n",
    "    \"\"\"\n",
    "    df_correlations = pd.DataFrame(correlations.items(), columns=['Pair', 'Correlation'])\n",
    "    df_correlations[['Centrality', 'Ground Truth']] = pd.DataFrame(df_correlations['Pair'].tolist(), index=df_correlations.index)\n",
    "    df_correlations = df_correlations.drop('Pair', axis=1)\n",
    "    df_correlations.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Network Function\n",
    "> The `analyze_network()` function performs comprehensive network analysis using various centrality measures and composite rankings.\n",
    "\n",
    "## Input Parameters\n",
    "\n",
    "- `nodes_df`: Pandas DataFrame containing node information, including ground truth scores and node attributes\n",
    "- `edges_df`: Pandas DataFrame containing edge information (connections between nodes)  \n",
    "- `ground_truths`: List of column names in nodes_df that contain ground truth scores to analyze\n",
    "- `centralities`: List of centrality measures to calculate (e.g. degree, betweenness, etc.)\n",
    "- `composite_functions`: List of functions that combine multiple centrality measures into composite rankings\n",
    "- `output_path`: Directory path where analysis outputs will be saved\n",
    "\n",
    "## Processing Steps\n",
    "\n",
    "1. Creates output directory if it doesn't exist\n",
    "2. Makes a copy of the input nodes DataFrame\n",
    "3. For each ground truth measure:\n",
    "   - Calculates an inverted version (max value - original value)\n",
    "   - Stores inverted versions with \"_inverted\" suffix\n",
    "4. Cleans data by:\n",
    "   - Dropping rows with missing ECLI identifiers\n",
    "   - Converting doctypebranch to numeric values if present\n",
    "5. Calculates centrality measures specified\n",
    "6. Creates composite rankings using provided functions\n",
    "7. Computes correlations between:\n",
    "   - Individual centrality measures and ground truths\n",
    "   - Composite rankings and ground truths\n",
    "\n",
    "## Return Value\n",
    "\n",
    "Returns an `AnalysisResults` dictionary containing:\n",
    "- `network_stats`: Basic statistics about the network (nodes, edges, density etc.)\n",
    "- `correlations`: Correlation coefficients between rankings and ground truths\n",
    "- `best_centralities`: Best performing centrality measures for each ground truth\n",
    "- `composite_rankings`: Results of composite ranking calculations\n",
    "- `dataframe`: Final processed DataFrame with all measures included\n",
    "\n",
    "## Output Files\n",
    "\n",
    "Saves various analysis results to the specified output directory, including:\n",
    "- Correlation plots\n",
    "- CSV files with detailed results\n",
    "- Network statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_network(nodes_df: pd.DataFrame, \n",
    "                edges_df: pd.DataFrame, \n",
    "                ground_truths: list, \n",
    "                centralities: list,\n",
    "                composite_functions: list,\n",
    "                output_path: str) -> AnalysisResults:\n",
    "    \"\"\"\n",
    "    Analyze a network using various centrality measures and composite rankings.\n",
    "    \n",
    "    Args:\n",
    "        nodes_df: DataFrame containing node information\n",
    "        edges_df: DataFrame containing edge information\n",
    "        ground_truths: List of ground truth column names to analyze\n",
    "        centralities: List of centrality measures to calculate\n",
    "        composite_functions: List of composite ranking functions to use\n",
    "        output_path: Path where to save output files\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing:\n",
    "        - 'network_stats': Dict with network statistics (nodes, edges, density)\n",
    "        - 'correlations': Dict mapping ground truth names to correlation results\n",
    "        - 'best_centralities': Dict mapping ground truth names to their best centrality measures\n",
    "        - 'composite_rankings': Dict mapping composite function names to their results\n",
    "        - 'dataframe': pandas DataFrame with all calculated measures and rankings\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Make a copy of nodes dataframe\n",
    "    total_df = nodes_df.copy()\n",
    "\n",
    "    # Convert doctypebranch to numeric if it exists\n",
    "    if 'doctypebranch' in total_df.columns:\n",
    "        total_df['doctypebranch'] = categorise_total_branch_numerically(total_df['doctypebranch'])\n",
    "        # Remove rows with Nan doctypebranch\n",
    "        total_df = total_df.dropna(subset=['doctypebranch'])\n",
    "\n",
    "    # Convert ground truth columns to numeric\n",
    "    for truth in ground_truths:\n",
    "        total_df[truth] = pd.to_numeric(total_df[truth], errors='coerce')\n",
    "    \n",
    "    # Invert ground truth values\n",
    "    ground_truths_inverted = []\n",
    "    for truth in ground_truths:\n",
    "        max_value = total_df[truth].max()\n",
    "        inverted_col = f'{truth}_inverted'\n",
    "        total_df[inverted_col] = max_value - total_df[truth]\n",
    "        ground_truths_inverted.append(inverted_col)\n",
    "    \n",
    "    # Drop rows with missing ecli\n",
    "    total_df = total_df.dropna(subset=['ecli'])\n",
    "    \n",
    "    # Create graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes with attributes\n",
    "    for idx, row in total_df.iterrows():\n",
    "        node_attrs = {truth: row[truth] for truth in ground_truths if truth in row}\n",
    "        G.add_node(row['ecli'], **node_attrs)\n",
    "    \n",
    "    # Add edges between existing nodes\n",
    "    valid_nodes = set(total_df['ecli'].values)\n",
    "    for idx, row in edges_df.iterrows():\n",
    "        source = row['ecli']\n",
    "        targets = row['references']\n",
    "        if source in valid_nodes:\n",
    "            for target in targets:\n",
    "                if target and target in valid_nodes:\n",
    "                    G.add_edge(source, target)\n",
    "    \n",
    "    # Remove self-loops\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    \n",
    "    # Calculate centrality measures\n",
    "    centrality_measures = calculate_centrality_measures(G)\n",
    "    centrality_df = pd.DataFrame(centrality_measures)\n",
    "    \n",
    "    # Merge centrality measures with total_df\n",
    "    total_df = pd.merge(total_df, centrality_df, left_on='ecli', right_index=True, how='left')\n",
    "    \n",
    "    # Plot initial correlations\n",
    "    numeric_cols = total_df.select_dtypes(include=[float, int]).columns\n",
    "    for centrality in centralities:\n",
    "        if centrality in numeric_cols:\n",
    "            correlation_results = total_df[ground_truths_inverted + [centrality]].corr()[centrality][ground_truths_inverted]\n",
    "            \n",
    "            # Plot correlation results\n",
    "            plt.figure()\n",
    "            correlation_results.plot(kind='bar', \n",
    "                                title=f'Correlation of {centrality} with Ground Truths')\n",
    "            plt.ylabel('Correlation Coefficient')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(f'{output_path}/correlation_{centrality}.png')\n",
    "            plt.close()\n",
    "    \n",
    "    # Run composite rankings analysis and prepare results structure\n",
    "    results = {\n",
    "        'network_stats': {\n",
    "            'n_nodes': len(total_df),\n",
    "            'n_edges': len(edges_df)\n",
    "        },\n",
    "        'correlations': {},\n",
    "        'best_centralities': {},\n",
    "        'composite_rankings': {},\n",
    "        'dataframe': total_df\n",
    "    }\n",
    "\n",
    "    # Initialize result dictionaries for each ground truth\n",
    "    for ground_truth in ground_truths:\n",
    "        results['correlations'][ground_truth] = {}\n",
    "        results['best_centralities'][ground_truth] = {}\n",
    "        results['composite_rankings'][ground_truth] = {}\n",
    "        \n",
    "        # Find best centralities once per ground truth\n",
    "        best_high, best_low = find_best_centralities(total_df, centralities, ground_truth)\n",
    "        results['best_centralities'][ground_truth] = {\n",
    "            'high': best_high,\n",
    "            'low': best_low\n",
    "        }\n",
    "        # Log the best centralities found for this ground truth\n",
    "        print(f\"\\nBest centralities for {ground_truth}:\")\n",
    "        print(f\"Best high correlation: {best_high}\")\n",
    "        print(f\"Best low correlation: {best_low}\")\n",
    "        \n",
    "        # Process each composite function\n",
    "        for composite_function in composite_functions:\n",
    "            print(f\"\\nAnalyzing ground truth: {ground_truth} with {composite_function}\")\n",
    "            \n",
    "            # Create composite ranking based on function type\n",
    "            if composite_function == 'weight_composite_ranking':\n",
    "                optimal_weight = find_optimal_weight(total_df, best_high, best_low, ground_truth)\n",
    "                composite_ranking = create_composite_ranking(total_df, best_high, best_low, optimal_weight)\n",
    "            else:\n",
    "                composite_ranking = create_treashold_composite_ranking(total_df, best_high, best_low, ground_truth)\n",
    "            \n",
    "            # Add composite ranking to dataframe\n",
    "            ranking_col = f'composite_ranking_{ground_truth}_{composite_function}'\n",
    "            total_df[ranking_col] = composite_ranking\n",
    "            \n",
    "            # Calculate correlations once and store them\n",
    "            correlations = calculate_correlations(total_df, centralities, ground_truths, ranking_col)\n",
    "            results['correlations'][ground_truth][composite_function] = correlations\n",
    "            \n",
    "            # Store composite rankings\n",
    "            results['composite_rankings'][ground_truth][composite_function] = total_df[ranking_col].to_dict()\n",
    "            \n",
    "            # Save visualization outputs\n",
    "            plot_correlations(\n",
    "                correlations, \n",
    "                ground_truth, \n",
    "                f'{output_path}/correlations_plot_{ground_truth}_{composite_function}.png',\n",
    "                best_high, \n",
    "                best_low\n",
    "            )\n",
    "            \n",
    "            save_correlations_to_csv(\n",
    "                correlations,\n",
    "                ground_truth,\n",
    "                f'{output_path}/correlations_{ground_truth}_{composite_function}.csv',\n",
    "                best_high,\n",
    "                best_low\n",
    "            )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Function\n",
    "This section implements network comparison functionality to analyze and compare results across different networks.\n",
    "\n",
    "The main function `compare_networks()` takes results from multiple network analyses and performs the following comparisons:\n",
    "\n",
    "1. Correlation Comparisons:\n",
    "   - Compares how different centrality measures correlate with ground truth metrics across networks\n",
    "   - Creates comparison tables showing correlation values for each network\n",
    "   - Saves correlation comparisons to CSV files\n",
    "\n",
    "2. Ranking Comparisons: \n",
    "   - Analyzes how centrality measures rank relative to each other in different networks\n",
    "   - Converts absolute correlation values to rankings\n",
    "   - Shows which centrality measures perform consistently well across networks\n",
    "   - Saves ranking comparisons to CSV files\n",
    "\n",
    "The comparisons are performed for each combination of:\n",
    "- Ground truth metrics (e.g., PageRank, degree centrality)\n",
    "- Composite ranking functions (different ways of combining centrality measures)\n",
    "\n",
    "This allows us to:\n",
    "- Identify which centrality measures work best across different network types\n",
    "- Understand how network structure affects centrality measure performance\n",
    "- Compare the effectiveness of different composite ranking approaches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_networks(network_results: Dict[str, AnalysisResults], output_path: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Compare centrality measure performance across different networks.\n",
    "    \n",
    "    Args:\n",
    "        network_results: Dictionary mapping network names to their analysis results\n",
    "        output_path: Path to save comparison results\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing aggregated analysis results per ground truth\n",
    "    \"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Get ground truths from first network\n",
    "    first_network = list(network_results.values())[0]\n",
    "    ground_truths = list(first_network['correlations'].keys())\n",
    "    \n",
    "    analysis = {gt: {\n",
    "        'centrality_counts': {\n",
    "            'high': defaultdict(int),      # Times selected as best high\n",
    "            'low': defaultdict(int),       # Times selected as best low\n",
    "            'best_overall': defaultdict(int)  # Times had best correlation\n",
    "        },\n",
    "        'combination_counts': defaultdict(int),  # Times each high+low pair was selected\n",
    "        'composite_performance': {\n",
    "            'outperformed_count': 0,  # Times composite ranking beat individual centralities\n",
    "            'best_combinations': []    # Combinations that achieved best performance\n",
    "        }\n",
    "    } for gt in ground_truths}\n",
    "    \n",
    "    # Analyze each network's results\n",
    "    for network_name, results in network_results.items():\n",
    "        for ground_truth in ground_truths:\n",
    "            # Get best centralities selected for this network\n",
    "            best_centralities = results['best_centralities'][ground_truth]\n",
    "            best_high = best_centralities['high']\n",
    "            best_low = best_centralities['low']\n",
    "            \n",
    "            # Count individual centrality selections\n",
    "            analysis[ground_truth]['centrality_counts']['high'][best_high] += 1\n",
    "            analysis[ground_truth]['centrality_counts']['low'][best_low] += 1\n",
    "            \n",
    "            # Count combination selections\n",
    "            combination = f\"{best_high}+{best_low}\"\n",
    "            analysis[ground_truth]['combination_counts'][combination] += 1\n",
    "            \n",
    "            # Find best overall centrality (highest correlation)\n",
    "            correlations = results['correlations'][ground_truth]\n",
    "            for composite_func, corr_dict in correlations.items():\n",
    "                # Get correlation values for individual centralities\n",
    "                centrality_correlations = {\n",
    "                    cent: abs(corr) \n",
    "                    for (cent, gt), corr in corr_dict.items() \n",
    "                    if cent != 'composite'\n",
    "                }\n",
    "                \n",
    "                # Find best performing centrality\n",
    "                best_centrality = max(centrality_correlations.items(), key=lambda x: x[1])[0]\n",
    "                analysis[ground_truth]['centrality_counts']['best_overall'][best_centrality] += 1\n",
    "                \n",
    "                # Check if composite ranking outperformed individual centralities\n",
    "                composite_corr = abs(corr_dict[('composite', ground_truth)])\n",
    "                if composite_corr > max(centrality_correlations.values()):\n",
    "                    analysis[ground_truth]['composite_performance']['outperformed_count'] += 1\n",
    "                    analysis[ground_truth]['composite_performance']['best_combinations'].append({\n",
    "                        'network': network_name,\n",
    "                        'combination': combination,\n",
    "                        'correlation': composite_corr\n",
    "                    })\n",
    "    \n",
    "    # Save results\n",
    "    for ground_truth in ground_truths:\n",
    "        results_file = f'{output_path}/network_analysis_{ground_truth}.json'\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(analysis[ground_truth], f, indent=4)\n",
    "        \n",
    "        # Create summary DataFrames\n",
    "        centrality_summary = pd.DataFrame([{\n",
    "            'centrality': cent,\n",
    "            'times_best_high': analysis[ground_truth]['centrality_counts']['high'][cent],\n",
    "            'times_best_low': analysis[ground_truth]['centrality_counts']['low'][cent],\n",
    "            'times_best_overall': analysis[ground_truth]['centrality_counts']['best_overall'][cent]\n",
    "        } for cent in set(\n",
    "            list(analysis[ground_truth]['centrality_counts']['high'].keys()) +\n",
    "            list(analysis[ground_truth]['centrality_counts']['low'].keys()) +\n",
    "            list(analysis[ground_truth]['centrality_counts']['best_overall'].keys())\n",
    "        )])\n",
    "        \n",
    "        centrality_summary.to_csv(\n",
    "            f'{output_path}/centrality_summary_{ground_truth}.csv', \n",
    "            index=False\n",
    "        )\n",
    "        \n",
    "        # Combination summary\n",
    "        combination_summary = pd.DataFrame([{\n",
    "            'combination': comb,\n",
    "            'times_selected': count\n",
    "        } for comb, count in analysis[ground_truth]['combination_counts'].items()])\n",
    "        \n",
    "        combination_summary.to_csv(\n",
    "            f'{output_path}/combination_summary_{ground_truth}.csv',\n",
    "            index=False\n",
    "        )\n",
    "    \n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_network_commonalities(analysis_results: Dict, output_path: str):\n",
    "    \"\"\"\n",
    "    Visualize commonalities between networks focusing on centrality performance.\n",
    "    \n",
    "    Args:\n",
    "        analysis_results: Dictionary containing the analysis results from compare_networks()\n",
    "        output_path: Path to save visualization outputs\n",
    "    \"\"\"\n",
    "    # Set the aesthetic style\n",
    "    plt.style.use('default')\n",
    "    \n",
    "    # Create figure with five subplots (3x2 grid, with the last spot empty for summary)\n",
    "    fig = plt.figure(figsize=(20, 25))\n",
    "    gs = plt.GridSpec(3, 2, figure=fig)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])  # High performers\n",
    "    ax2 = fig.add_subplot(gs[0, 1])  # Low performers\n",
    "    ax3 = fig.add_subplot(gs[1, 0])  # Best overall performers\n",
    "    ax4 = fig.add_subplot(gs[1, 1])  # Composite performance\n",
    "    ax5 = fig.add_subplot(gs[2, 0])  # Total best occurrences\n",
    "    \n",
    "    # Colors for different ground truths\n",
    "    colors = {'importance': 'skyblue', 'doctypebranch': 'lightgreen'}\n",
    "    \n",
    "    # 1. High Importance Performers Graph\n",
    "    for ground_truth in analysis_results:\n",
    "        high_counts = analysis_results[ground_truth]['centrality_counts']['high']\n",
    "        if high_counts:\n",
    "            centralities = list(high_counts.keys())\n",
    "            counts = list(high_counts.values())\n",
    "            ax1.bar(centralities, counts, label=ground_truth, alpha=0.7, color=colors[ground_truth])\n",
    "    \n",
    "    ax1.set_ylabel('Times Selected as Best High Predictor')\n",
    "    ax1.set_title('Best Performing Centralities for High Scores')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    ax1.set_xticklabels(ax1.get_xticklabels(), ha='right')\n",
    "    ax1.legend()\n",
    "    \n",
    "    # 2. Low Importance Performers Graph\n",
    "    for ground_truth in analysis_results:\n",
    "        low_counts = analysis_results[ground_truth]['centrality_counts']['low']\n",
    "        if low_counts:\n",
    "            centralities = list(low_counts.keys())\n",
    "            counts = list(low_counts.values())\n",
    "            ax2.bar(centralities, counts, label=ground_truth, alpha=0.7, color=colors[ground_truth])\n",
    "    \n",
    "    ax2.set_ylabel('Times Selected as Best Low Predictor')\n",
    "    ax2.set_title('Best Performing Centralities for Low Scores')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    ax2.set_xticklabels(ax2.get_xticklabels(), ha='right')\n",
    "    ax2.legend()\n",
    "    \n",
    "    # 3. Best Overall Performers Graph\n",
    "    for ground_truth in analysis_results:\n",
    "        best_overall = analysis_results[ground_truth]['centrality_counts']['best_overall']\n",
    "        if best_overall:\n",
    "            centralities = list(best_overall.keys())\n",
    "            counts = list(best_overall.values())\n",
    "            ax3.bar(centralities, counts, label=ground_truth, alpha=0.7, color=colors[ground_truth])\n",
    "    \n",
    "    ax3.set_ylabel('Times Selected as Best Overall')\n",
    "    ax3.set_title('Best Overall Performing Centralities')\n",
    "    ax3.tick_params(axis='x', rotation=45)\n",
    "    ax3.set_xticklabels(ax3.get_xticklabels(), ha='right')\n",
    "    ax3.legend()\n",
    "    \n",
    "    # 4. Combination Performance Graph\n",
    "    for ground_truth in analysis_results:\n",
    "        combinations = analysis_results[ground_truth]['combination_counts']\n",
    "        if combinations:\n",
    "            combo_names = list(combinations.keys())\n",
    "            combo_counts = list(combinations.values())\n",
    "            ax4.bar(combo_names, combo_counts, label=ground_truth, alpha=0.7, color=colors[ground_truth])\n",
    "    \n",
    "    ax4.set_ylabel('Times Selected as Best Combination')\n",
    "    ax4.set_title('Best Performing Centrality Combinations')\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "    ax4.set_xticklabels(ax4.get_xticklabels(), ha='right')\n",
    "    ax4.legend()\n",
    "    \n",
    "    # 5. Total Best Occurrences Graph\n",
    "    # Combine counts across all categories and ground truths\n",
    "    total_counts = {}\n",
    "    for ground_truth in analysis_results:\n",
    "        for category in ['high', 'low', 'best_overall']:\n",
    "            counts = analysis_results[ground_truth]['centrality_counts'][category]\n",
    "            for centrality, count in counts.items():\n",
    "                if centrality not in total_counts:\n",
    "                    total_counts[centrality] = 0\n",
    "                total_counts[centrality] += count\n",
    "    \n",
    "    # Plot total counts\n",
    "    if total_counts:\n",
    "        centralities = list(total_counts.keys())\n",
    "        counts = list(total_counts.values())\n",
    "        ax5.bar(centralities, counts, color='lightcoral', alpha=0.7)\n",
    "    \n",
    "    ax5.set_ylabel('Total Times Selected as Best')\n",
    "    ax5.set_title('Overall Best Performing Centralities (All Categories)')\n",
    "    ax5.tick_params(axis='x', rotation=45)\n",
    "    ax5.set_xticklabels(ax5.get_xticklabels(), ha='right')\n",
    "    \n",
    "    # Add a text box with summary statistics in the empty space (bottom right)\n",
    "    summary_text = \"\"\n",
    "    for ground_truth in analysis_results:\n",
    "        summary_text += f\"\\n{ground_truth.upper()} SUMMARY:\\n\"\n",
    "        # Most common high performer\n",
    "        high_counts = analysis_results[ground_truth]['centrality_counts']['high']\n",
    "        if high_counts:\n",
    "            best_high = max(high_counts.items(), key=lambda x: x[1])\n",
    "            summary_text += f\"Best High: {best_high[0]} ({best_high[1]} times)\\n\"\n",
    "        \n",
    "        # Most common low performer\n",
    "        low_counts = analysis_results[ground_truth]['centrality_counts']['low']\n",
    "        if low_counts:\n",
    "            best_low = max(low_counts.items(), key=lambda x: x[1])\n",
    "            summary_text += f\"Best Low: {best_low[0]} ({best_low[1]} times)\\n\"\n",
    "        \n",
    "        # Most common combination\n",
    "        combinations = analysis_results[ground_truth]['combination_counts']\n",
    "        if combinations:\n",
    "            best_combo = max(combinations.items(), key=lambda x: x[1])\n",
    "            summary_text += f\"Best Combination: {best_combo[0]} ({best_combo[1]} times)\\n\"\n",
    "        \n",
    "        # Add outperformance statistics\n",
    "        outperformed_count = analysis_results[ground_truth]['composite_performance']['outperformed_count']\n",
    "        best_combinations = analysis_results[ground_truth]['composite_performance']['best_combinations']\n",
    "        summary_text += f\"Times composites outperformed: {outperformed_count}\\n\"\n",
    "        \n",
    "        if best_combinations:\n",
    "            # Count occurrences of each combination that outperformed\n",
    "            combo_counts = {}\n",
    "            for entry in best_combinations:\n",
    "                combo = entry['combination']\n",
    "                combo_counts[combo] = combo_counts.get(combo, 0) + 1\n",
    "            \n",
    "            # Get the combination that outperformed most often\n",
    "            best_outperforming = max(combo_counts.items(), key=lambda x: x[1])\n",
    "            summary_text += f\"Best outperforming combo: {best_outperforming[0]} ({best_outperforming[1]} times)\\n\"\n",
    "            \n",
    "            # Add the highest correlation achieved\n",
    "            best_correlation = max(entry['correlation'] for entry in best_combinations)\n",
    "            summary_text += f\"Highest correlation achieved: {best_correlation:.3f}\\n\"\n",
    "    \n",
    "    # Add overall best performer from total counts\n",
    "    if total_counts:\n",
    "        best_overall = max(total_counts.items(), key=lambda x: x[1])\n",
    "        summary_text += f\"\\nOVERALL BEST PERFORMER:\\n{best_overall[0]} (Selected {best_overall[1]} times total)\"\n",
    "    \n",
    "    # Add text box to figure in bottom right\n",
    "    plt.figtext(0.65, 0.15, summary_text, fontsize=10, \n",
    "                bbox=dict(facecolor='white', alpha=0.8, edgecolor='gray'))\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/network_performance_analysis.png', \n",
    "                bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Save detailed numerical results\n",
    "    summary = {\n",
    "        ground_truth: {\n",
    "            'high_performers': dict(analysis_results[ground_truth]['centrality_counts']['high']),\n",
    "            'low_performers': dict(analysis_results[ground_truth]['centrality_counts']['low']),\n",
    "            'best_overall': dict(analysis_results[ground_truth]['centrality_counts']['best_overall']),\n",
    "            'combinations': dict(analysis_results[ground_truth]['combination_counts']),\n",
    "            'composite_performance': {\n",
    "                'outperformed_count': analysis_results[ground_truth]['composite_performance']['outperformed_count'],\n",
    "                'best_combinations': analysis_results[ground_truth]['composite_performance']['best_combinations']\n",
    "            },\n",
    "            'best_performers': {\n",
    "                'high': max(analysis_results[ground_truth]['centrality_counts']['high'].items(), \n",
    "                           key=lambda x: x[1])[0] if analysis_results[ground_truth]['centrality_counts']['high'] else None,\n",
    "                'low': max(analysis_results[ground_truth]['centrality_counts']['low'].items(), \n",
    "                          key=lambda x: x[1])[0] if analysis_results[ground_truth]['centrality_counts']['low'] else None,\n",
    "                'overall': max(analysis_results[ground_truth]['centrality_counts']['best_overall'].items(), \n",
    "                             key=lambda x: x[1])[0] if analysis_results[ground_truth]['centrality_counts']['best_overall'] else None,\n",
    "                'combination': max(analysis_results[ground_truth]['combination_counts'].items(), \n",
    "                                 key=lambda x: x[1])[0] if analysis_results[ground_truth]['combination_counts'] else None\n",
    "            }\n",
    "        }\n",
    "        for ground_truth in analysis_results\n",
    "    }\n",
    "    \n",
    "    # Add total counts to summary\n",
    "    summary['total_counts'] = total_counts\n",
    "    \n",
    "    with open(f'{output_path}/visualization_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_networks(path, max=100):\n",
    "    networks = {}\n",
    "    split_dir = path\n",
    "\n",
    "    # Verify split directory exists and print absolute path\n",
    "    abs_split_dir = os.path.abspath(split_dir)\n",
    "    print(f\"Looking for networks in: {abs_split_dir}\")\n",
    "\n",
    "    if not os.path.exists(abs_split_dir):\n",
    "        raise ValueError(f\"Directory {abs_split_dir} does not exist\")\n",
    "\n",
    "    # Get list of article directories with more detailed logging\n",
    "    article_dirs = [d for d in os.listdir(abs_split_dir) if d.startswith('article_') and os.path.isdir(os.path.join(abs_split_dir, d))]\n",
    "    if not article_dirs:\n",
    "        raise ValueError(f\"No article directories found in {abs_split_dir}\")\n",
    "\n",
    "    print(f\"Found {len(article_dirs)} article networks\")\n",
    "\n",
    "    # Load each article network\n",
    "    for article_dir in article_dirs[:max]:\n",
    "        network_path = os.path.join(abs_split_dir, article_dir)\n",
    "        nodes_file = os.path.join(network_path, 'nodes.json')\n",
    "        edges_file = os.path.join(network_path, 'edges.json')\n",
    "        \n",
    "        # More detailed file existence checking\n",
    "        print(f\"\\nChecking {article_dir}:\")\n",
    "        print(f\"  Network path: {network_path}\")\n",
    "        print(f\"  Nodes file: {nodes_file} (exists: {os.path.exists(nodes_file)})\")\n",
    "        print(f\"  Edges file: {edges_file} (exists: {os.path.exists(edges_file)})\")\n",
    "        \n",
    "        # Check if required files exist\n",
    "        if not os.path.exists(nodes_file):\n",
    "            print(f\"Warning: Missing nodes.json in {article_dir}\")\n",
    "            # List contents of the directory to debug\n",
    "            try:\n",
    "                dir_contents = os.listdir(network_path)\n",
    "                print(f\"  Directory contents: {dir_contents}\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error listing directory: {str(e)}\")\n",
    "            continue\n",
    "        \n",
    "        if not os.path.exists(edges_file):\n",
    "            print(f\"Warning: Missing edges.json in {article_dir}\")\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Load nodes and edges data\n",
    "            print(f\"  Loading data files...\")\n",
    "            nodes_df = pd.read_json(nodes_file)\n",
    "            edges_df = pd.read_json(edges_file)\n",
    "            \n",
    "            # Basic validation with more detailed output\n",
    "            required_node_cols = ['ecli', 'importance', 'doctypebranch']\n",
    "            missing_cols = [col for col in required_node_cols if col not in nodes_df.columns]\n",
    "            if missing_cols:\n",
    "                print(f\"  Warning: Missing columns in nodes.json: {missing_cols}\")\n",
    "                print(f\"  Available columns: {nodes_df.columns.tolist()}\")\n",
    "                continue\n",
    "                \n",
    "            required_edge_cols = ['ecli', 'references']\n",
    "            missing_edge_cols = [col for col in required_edge_cols if col not in edges_df.columns]\n",
    "            if missing_edge_cols:\n",
    "                print(f\"  Warning: Missing columns in edges.json: {missing_edge_cols}\")\n",
    "                print(f\"  Available columns: {edges_df.columns.tolist()}\")\n",
    "                continue\n",
    "            \n",
    "            networks[article_dir] = {\n",
    "                'nodes': nodes_df,\n",
    "                'edges': edges_df\n",
    "            }\n",
    "            print(f\"  Successfully loaded network with {len(nodes_df)} nodes and {len(edges_df)} edges\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading {article_dir}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\nSuccessfully loaded {len(networks)} networks\")\n",
    "    return networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centralities of interest\n",
    "CENTRALITIES = ['degree_centrality', 'in_degree_centrality', 'out_degree_centrality', \n",
    "                'betweenness_centrality', 'closeness_centrality', 'core_number', \n",
    "                'relative_in_degree_centrality', 'eigenvector_centrality', \n",
    "                'pagerank', 'hits_hub', 'hits_authority', 'harmonic_centrality', 'disruption']\n",
    "\n",
    "# Ground truths of interest\n",
    "GROUND_TRUTHS = ['importance', 'doctypebranch']\n",
    "GROUND_TRUTHS_INVERTED = ['importance_inverted',  'doctypebranch_inverted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all networks from data/split directory\n",
    "network_results = {}\n",
    "\n",
    "networks = load_networks('networks')\n",
    "\n",
    "# Analyze Networks\n",
    "for network_name, data in networks.items():\n",
    "    print(f\"\\nAnalyzing network: {network_name}\")\n",
    "    results = analyze_network(\n",
    "        nodes_df=data['nodes'],\n",
    "        edges_df=data['edges'],\n",
    "        ground_truths=GROUND_TRUTHS,\n",
    "        centralities=CENTRALITIES,\n",
    "        composite_functions=['weight_composite_ranking',],\n",
    "        output_path=f'results/{network_name}'\n",
    "    )\n",
    "    network_results[network_name] = results\n",
    "\n",
    "\n",
    "# Before comparison\n",
    "if not network_results:\n",
    "    raise ValueError(\"No networks were successfully analyzed. Check if data/split directory contains valid network data.\")\n",
    "\n",
    "\n",
    "# Compare results across networks\n",
    "analysis = compare_networks(network_results, 'results/comparisons')\n",
    "\n",
    "# Visualize results\n",
    "visualize_network_commonalities(analysis, 'results/comparisons')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
