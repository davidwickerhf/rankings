{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Centrality Metrics\n",
    "\n",
    "This notebook analyzes and compares different centrality metrics for a citation network.\n",
    "\n",
    "It loads node and edge data from JSON files, calculates various centrality metrics (like degree, betweenness, closeness etc.), and compares them against ground truth measures like importance and document type.\n",
    "\n",
    "The notebook defines constants for:\n",
    "- Input data file paths\n",
    "- Centrality metrics to analyze \n",
    "- Ground truth measures to compare against\n",
    "\n",
    "It also defines TypedDict classes to type the network statistics and results.\n",
    "\n",
    "**Note:** This is an analysis notebook. To modify the code that generates the network and calculates centralities, please refer to the Main section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import datetime\n",
    "import dateutil.parser\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List, Union, TypedDict, Tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkStats(TypedDict):\n",
    "    n_nodes: int\n",
    "    n_edges: int\n",
    "\n",
    "class BestCentralities(TypedDict):\n",
    "    high: str\n",
    "    low: str\n",
    "\n",
    "class AnalysisResults(TypedDict):\n",
    "    network_stats: NetworkStats\n",
    "    correlations: Dict[str, Dict[str, Dict[tuple[str, str], float]]]  # ground_truth -> composite_function -> (centrality, ground_truth) -> correlation\n",
    "    best_centralities: Dict[str, BestCentralities]  # ground_truth -> best centralities\n",
    "    composite_rankings: Dict[str, Dict[str, Dict[str, float]]]  # ground_truth -> composite_function -> ecli -> rank\n",
    "    dataframe: pd.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert doctypebranch to a numeric value\n",
    "def categorise_total_branch_numerically(branches: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Convert branch categorisation from strings into numbers.\n",
    "    \n",
    "    :param branches: The column containing branch data, categorized with strings.\n",
    "    :return: A pandas Series with numerical categorization.\n",
    "    \"\"\"\n",
    "    mapping = {\n",
    "        \"GRANDCHAMBER\": 1,\n",
    "        \"CHAMBER\": 2,\n",
    "        \"COMMITTEE\": 3,\n",
    "    }\n",
    "    \n",
    "    # Convert to uppercase to ensure consistent matching\n",
    "    branches = branches.str.upper()\n",
    "    \n",
    "    # Print any values that don't match our mapping\n",
    "    unmapped = set(branches.unique()) - set(mapping.keys())\n",
    "    if unmapped:\n",
    "        print(f\"Warning: Found unmapped values: {unmapped}\")\n",
    "    \n",
    "    return branches.map(mapping)\n",
    "\n",
    "def prep_data(df: pd.DataFrame, include: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare the dataset by selecting the appropriate columns and filtering out rows with uncomputed metric values.\n",
    "    \n",
    "    :param df: The DataFrame to process.\n",
    "    :param include: Columns to include.\n",
    "    :return: The processed DataFrame.\n",
    "    \"\"\"\n",
    "    headers = include + ['ecli']  # Ensure essential columns are included\n",
    "    headers = list(set(headers))  # Removing duplicates\n",
    "\n",
    "    data = df[headers]\n",
    "\n",
    "    # Filter out rows with uncomputed metric values (-2)\n",
    "    metric_column = include[-1]\n",
    "    data = data[data[metric_column] >= -1]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centrality Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_disruptions_new(graph: nx.Graph) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate the disruption score for each node in the graph.\n",
    "\n",
    "    Args:\n",
    "        graph (nx.Graph): The input directed graph.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with nodes as keys and their disruption scores as values.\n",
    "    \"\"\"\n",
    "    disruptions = {}\n",
    "    for node in graph.nodes:\n",
    "        i, j, k = 0, 0, 0\n",
    "\n",
    "        # count j - papers that cite both the current paper and its references\n",
    "        for in_node in graph.predecessors(node):\n",
    "            for out_node in graph.successors(node):\n",
    "                if graph.has_edge(in_node, out_node):\n",
    "                    j += 1\n",
    "                    break\n",
    "\n",
    "        # count i - papers that only cite the current paper\n",
    "        i = graph.in_degree(node) - j\n",
    "\n",
    "        # count k - papers that only cite papers cited by the current paper\n",
    "        for out_node in graph.successors(node):\n",
    "            for in_out_node in graph.predecessors(out_node):\n",
    "                if in_out_node != node and not graph.has_edge(in_out_node, node):\n",
    "                    k += 1\n",
    "\n",
    "        # Calculate disruption index with better edge case handling\n",
    "        denominator = i + j + k\n",
    "        if denominator == 0:\n",
    "            # If paper has no citations and cites no one, assign neutral disruption\n",
    "            disruptions[node] = 0.0\n",
    "        else:\n",
    "            disruptions[node] = (i - j) / denominator\n",
    "\n",
    "    # Verify we have at least some non-zero values\n",
    "    values = list(disruptions.values())\n",
    "    if all(v == 0 for v in values):\n",
    "        print(\"Warning: All disruption values are 0\")\n",
    "    if len(set(values)) == 1:\n",
    "        print(f\"Warning: All disruption values are identical: {values[0]}\")\n",
    "\n",
    "    return disruptions\n",
    "\n",
    "\n",
    "# Function to calculate centrality measures\n",
    "def calculate_centrality_measures(graph):\n",
    "    \"\"\"Calculate various centrality measures for the graph.\"\"\"\n",
    "    measures = {\n",
    "        'degree_centrality': nx.degree_centrality(graph),\n",
    "        'in_degree_centrality': nx.in_degree_centrality(graph),\n",
    "        'out_degree_centrality': nx.out_degree_centrality(graph),\n",
    "        'betweenness_centrality': nx.betweenness_centrality(graph),\n",
    "        'closeness_centrality': nx.closeness_centrality(graph),\n",
    "        'core_number': nx.core_number(graph),\n",
    "        'relative_in_degree_centrality': {node: degree/len(graph) \n",
    "                                        for node, degree in graph.in_degree()},\n",
    "        'harmonic_centrality': nx.harmonic_centrality(graph)\n",
    "    }\n",
    "    \n",
    "    # Handle potentially failing measures with try-except\n",
    "    try:\n",
    "        measures['eigenvector_centrality'] = nx.eigenvector_centrality(graph, max_iter=1000)\n",
    "    except (nx.PowerIterationFailedConvergence, nx.NetworkXError):\n",
    "        # Fill with zeros if calculation fails\n",
    "        measures['eigenvector_centrality'] = {node: 0.0 for node in graph.nodes()}\n",
    "    \n",
    "    try:\n",
    "        measures['pagerank'] = nx.pagerank(graph)\n",
    "    except:\n",
    "        measures['pagerank'] = {node: 0.0 for node in graph.nodes()}\n",
    "    \n",
    "    try:\n",
    "        hub_dict, authority_dict = nx.hits(graph)\n",
    "        measures['hits_hub'] = hub_dict\n",
    "        measures['hits_authority'] = authority_dict\n",
    "    except:\n",
    "        measures['hits_hub'] = {node: 0.0 for node in graph.nodes()}\n",
    "        measures['hits_authority'] = {node: 0.0 for node in graph.nodes()}\n",
    "    \n",
    "    try:\n",
    "        measures['disruption'] = calculate_disruptions_new(graph)\n",
    "        # Check if disruption values make sense (between -1 and 1)\n",
    "        disruption_values = list(measures['disruption'].values())\n",
    "        if not all(-1 <= v <= 1 for v in disruption_values if not np.isnan(v)):\n",
    "            raise ValueError(\"Disruption values outside valid range [-1,1]\")\n",
    "        \n",
    "        # Check if all disruption values are identical (excluding NaN)\n",
    "        non_nan_values = [v for v in disruption_values if not np.isnan(v)]\n",
    "        if len(non_nan_values) > 0 and all(v == non_nan_values[0] for v in non_nan_values):\n",
    "            raise ValueError(\"All disruption values are identical\")\n",
    "    except Exception as e:\n",
    "        measures['disruption'] = {node: 0.0 for node in graph.nodes()}\n",
    "        \n",
    "    return measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composite Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script analyzes the relationship between various centrality measures and ground truth scores\n",
    "for legal cases. It aims to find the best centrality measures for predicting high and low relevance\n",
    "scores, create a composite ranking, and evaluate its performance against individual centrality measures.\n",
    "\n",
    "The main steps are:\n",
    "1. Plot error bars for centrality measures vs. ground truth scores\n",
    "2. Find the best centrality measures for predicting high and low scores\n",
    "3. Create a composite ranking using the best measures\n",
    "4. Calculate correlations between rankings and ground truth scores\n",
    "5. Visualize and save the results\n",
    "\"\"\"\n",
    "\n",
    "def plot_error_bars(df, centrality, ground_truth):\n",
    "    \"\"\"\n",
    "    Plot error bars for a given centrality measure against a ground truth score.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the data\n",
    "    centrality (str): The name of the centrality measure column\n",
    "    ground_truth (str): The name of the ground truth score column\n",
    "\n",
    "    This function visualizes the relationship between a centrality measure and a ground truth score,\n",
    "    showing the mean centrality value for each ground truth score category along with error bars\n",
    "    representing the standard deviation.\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    include = [ground_truth, centrality]\n",
    "    data = prep_data(df, include)\n",
    "\n",
    "    x_header = centrality\n",
    "    y_header = ground_truth\n",
    "    x, y = list(data[x_header]), list(data[y_header])\n",
    "    categories = list(set(y))\n",
    "    categories.sort()\n",
    "    num_categories, num_instances = len(categories), len(x)\n",
    "    y_instances = [[] for _ in range(num_categories)]\n",
    "    for category_no in range(num_categories):\n",
    "        for instance_no in range(num_instances):\n",
    "            if y[instance_no] == categories[category_no]:\n",
    "                y_instances[category_no].append(x[instance_no])\n",
    "    x = [statistics.mean(y_instances[category_no]) for category_no in range(num_categories)]\n",
    "    y = categories\n",
    "\n",
    "    # Draw graph\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    title = f\"{centrality.capitalize()} vs Average {y_header.capitalize()}\"\n",
    "    plt.suptitle(title, fontsize=22)\n",
    "    plt.xlabel(f\"{centrality.capitalize()}\", fontsize=22)\n",
    "    plt.ylabel(f\"{y_header.capitalize()}\", fontsize=22)\n",
    "    plt.yticks(categories, fontsize=16)\n",
    "\n",
    "    # Calculate error bars\n",
    "    stds = [statistics.stdev(y_instances[category_no]) for category_no in range(num_categories)]\n",
    "    plt.errorbar(x, y, xerr=stds, fmt='o')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def find_best_centralities(df, centralities, ground_truth):\n",
    "    \"\"\"\n",
    "    Find the best centrality measures for predicting high and low ground truth scores.\n",
    "    TODO: Include considerations for multiple ground truth scores\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the data\n",
    "    centralities (list): List of centrality measure column names\n",
    "    ground_truth (str): The name of the ground truth score column\n",
    "\n",
    "    Returns:\n",
    "    tuple: (best_high, best_low) - the names of the best centrality measures for high and low scores\n",
    "\n",
    "    This function calculates the Spearman correlation between each centrality measure and the ground truth,\n",
    "    using 1 - |correlation| as an error metric. The centrality with the lowest error is chosen as best_high,\n",
    "    and the second-lowest (excluding best_high) is chosen as best_low.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO For COURTBRANCH: When selecting the optimal metric for the lower class (less importance) we weight it against the middle class.\n",
    "\n",
    "    errors = {}\n",
    "    \n",
    "    for centrality in centralities:\n",
    "        # Calculate correlation across the full range\n",
    "        corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
    "        errors[centrality] = 1 - abs(corr)  # Use 1 - |correlation| as error\n",
    "    \n",
    "    best_high = min(errors, key=errors.get)\n",
    "    \n",
    "    # Remove the best_high centrality from consideration for best_low\n",
    "    errors.pop(best_high, None)\n",
    "    \n",
    "    best_low = min(errors, key=errors.get)\n",
    "    \n",
    "    return best_high, best_low\n",
    "\n",
    "\n",
    "def find_best_centralities_updated(df, centralities, ground_truth):\n",
    "    \"\"\"\n",
    "    Find the best centrality measures for predicting high and low ground truth scores.\n",
    "    TODO: Include considerations for multiple ground truth scores\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the data\n",
    "    centralities (list): List of centrality measure column names\n",
    "    ground_truth (str): The name of the ground truth score column\n",
    "\n",
    "    Returns:\n",
    "    tuple: (best_high, best_low) - the names of the best centrality measures for high and low scores\n",
    "\n",
    "    This function calculates the Spearman correlation between each centrality measure and the ground truth,\n",
    "    using 1 - |correlation| as an error metric. The centrality with the lowest error is chosen as best_high,\n",
    "    and the second-lowest (excluding best_high) is chosen as best_low.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO For COURTBRANCH: When selecting the optimal metric for the lower class (less importance) we weight it against the middle class.\n",
    "\n",
    "    errors = {}\n",
    "    \n",
    "    for centrality in centralities:\n",
    "        # Calculate correlation across the full range\n",
    "        corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
    "        errors[centrality] = 1 - abs(corr)  # Use 1 - |correlation| as error\n",
    "    \n",
    "    best_high = min(errors, key=errors.get)\n",
    "    \n",
    "    # Remove the best_high centrality from consideration for best_low\n",
    "    errors.pop(best_high, None)\n",
    "    \n",
    "    best_low = min(errors, key=errors.get)\n",
    "    \n",
    "    return best_high, best_low\n",
    "\n",
    "def rank_cases(df, centrality):\n",
    "    \"\"\"\n",
    "    Rank cases based on a given centrality measure.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the data\n",
    "    centrality (str): The name of the centrality measure column\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: A series of rankings for each case\n",
    "\n",
    "    This function ranks the cases in descending order of the centrality measure,\n",
    "    with the highest centrality receiving rank 1.\n",
    "    \"\"\"\n",
    "    return df[centrality].rank(ascending=False)\n",
    "\n",
    "def create_treashold_composite_ranking(df, high_centrality, low_centrality, ground_truth):\n",
    "    \"\"\"\n",
    "    Create a composite ranking based on a threshold approach using two centrality measures.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing the centrality measures\n",
    "        high_centrality: Centrality measure that performs best for high scores\n",
    "        low_centrality: Centrality measure that performs best for low scores\n",
    "        ground_truth: Name of the ground truth column\n",
    "        \n",
    "    Returns:\n",
    "        Series containing the composite ranking\n",
    "    \"\"\"\n",
    "    # Normalize both centrality measures to [0,1] range\n",
    "    high_normalized = (df[high_centrality] - df[high_centrality].min()) / (df[high_centrality].max() - df[high_centrality].min())\n",
    "    low_normalized = (df[low_centrality] - df[low_centrality].min()) / (df[low_centrality].max() - df[low_centrality].min())\n",
    "    \n",
    "    # Find optimal threshold by testing different values\n",
    "    thresholds = np.linspace(0, 1, 100)\n",
    "    best_correlation = -1\n",
    "    optimal_threshold = 0\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        # Create composite ranking using current threshold\n",
    "        composite = np.where(\n",
    "            high_normalized > threshold,\n",
    "            high_normalized,  # Use high centrality measure\n",
    "            low_normalized    # Use low centrality measure\n",
    "        )\n",
    "        \n",
    "        # Calculate correlation with ground truth\n",
    "        correlation = abs(spearmanr(composite, df[ground_truth])[0])\n",
    "        \n",
    "        # Update if better correlation found\n",
    "        if correlation > best_correlation:\n",
    "            best_correlation = correlation\n",
    "            optimal_threshold = threshold\n",
    "    \n",
    "    # Create final composite ranking using optimal threshold\n",
    "    final_composite = np.where(\n",
    "        high_normalized > optimal_threshold,\n",
    "        high_normalized,\n",
    "        low_normalized\n",
    "    )\n",
    "    \n",
    "    print(f\"Optimal threshold found: {optimal_threshold:.6f}\")\n",
    "    return final_composite, optimal_threshold\n",
    "\n",
    "def create_composite_ranking(df, high_centrality, low_centrality, weight):\n",
    "    \"\"\"\n",
    "    Create a composite ranking using two centrality measures.\n",
    "    The weight is the weight given to the high_centrality ranking (0-1), different from 0 and 1.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the data\n",
    "    high_centrality (str): The name of the centrality measure best for high scores\n",
    "    low_centrality (str): The name of the centrality measure best for low scores\n",
    "    weight (float): The weight given to the high_centrality ranking (0-1)\n",
    "\n",
    "    Returns:\n",
    "    pd.Series: A series of composite rankings for each case\n",
    "\n",
    "    This function creates a weighted average of the rankings from two centrality measures,\n",
    "    allowing for a balance between predicting high and low ground truth scores.\n",
    "    \"\"\"\n",
    "    high_ranks = rank_cases(df, high_centrality)\n",
    "    low_ranks = rank_cases(df, low_centrality)\n",
    "    return weight * high_ranks + (1 - weight) * low_ranks\n",
    "\n",
    "def find_optimal_weight(df, high_centrality, low_centrality, ground_truth):\n",
    "    \"\"\"\n",
    "    Find the optimal weight for creating a composite ranking. \n",
    "    The weight is the weight given to the high_centrality ranking (0-1), different from 0 and 1.\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the data\n",
    "    high_centrality (str): The name of the centrality measure best for high scores\n",
    "    low_centrality (str): The name of the centrality measure best for low scores\n",
    "    ground_truth (str): The name of the ground truth score column\n",
    "\n",
    "    Returns:\n",
    "    float: The optimal weight (0-1) for the high_centrality ranking\n",
    "\n",
    "    This function tests different weights to find the one that produces the composite ranking\n",
    "    with the highest correlation to the ground truth scores.\n",
    "    \"\"\"\n",
    "    best_corr = -1\n",
    "    best_weight = 0.5  # Initialize to middle value\n",
    "    for weight in np.arange(0.01, 1.00, 0.01):  # Exclude 0 and 1\n",
    "        composite = create_composite_ranking(df, high_centrality, low_centrality, weight)\n",
    "        corr, _ = stats.spearmanr(composite, df[ground_truth])\n",
    "        if abs(corr) > best_corr:\n",
    "            best_corr = abs(corr)\n",
    "            best_weight = weight\n",
    "    return best_weight\n",
    "\n",
    "def calculate_correlations(df, centralities, ground_truths, composite_ranking):\n",
    "    \"\"\"\n",
    "    Calculate correlations between rankings and ground truth scores.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the data\n",
    "    centralities (list): List of centrality measure column names\n",
    "    ground_truths (list): List of ground truth score column names\n",
    "    composite_ranking (str): The name of the composite ranking column\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary of correlation coefficients\n",
    "\n",
    "    This function calculates Spearman correlations between the rankings of each centrality measure\n",
    "    (including the composite ranking) and each ground truth score.\n",
    "    \"\"\"\n",
    "    correlations = {}\n",
    "    \n",
    "    for centrality in centralities:\n",
    "        centrality_ranking = rank_cases(df, centrality)\n",
    "        for ground_truth in ground_truths:\n",
    "            # Check if arrays have variation before calculating correlation\n",
    "            if df[centrality].nunique() > 1 and df[ground_truth].nunique() > 1:\n",
    "                corr, _ = stats.spearmanr(centrality_ranking, df[ground_truth])\n",
    "                correlations[(centrality, ground_truth)] = corr\n",
    "            else:\n",
    "                correlations[(centrality, ground_truth)] = np.nan\n",
    "    \n",
    "    for ground_truth in ground_truths:\n",
    "        if df[composite_ranking].nunique() > 1 and df[ground_truth].nunique() > 1:\n",
    "            corr, _ = stats.spearmanr(df[composite_ranking], df[ground_truth])\n",
    "            correlations[('composite', ground_truth)] = corr\n",
    "        else:\n",
    "            correlations[('composite', ground_truth)] = np.nan\n",
    "    \n",
    "    return correlations\n",
    "\n",
    "def plot_correlations(correlations, ground_truth, output_file, best_high, best_low, composite_param):\n",
    "    \"\"\"\n",
    "    Plot correlations between rankings and ground truth scores.\n",
    "\n",
    "    Args:\n",
    "    correlations (dict): Dictionary of correlation coefficients\n",
    "    ground_truth (str): The name of the current ground truth score\n",
    "    output_file (str): The name of the output file for the plot\n",
    "    best_high (str): The name of the best centrality for high scores\n",
    "    best_low (str): The name of the best centrality for low scores\n",
    "\n",
    "    This function creates a bar plot showing the correlations between each centrality measure\n",
    "    (including the composite ranking) and the ground truth scores.\n",
    "    \"\"\"\n",
    "    centralities = list(set([k[0] for k in correlations.keys() if k[0] != 'composite']))\n",
    "    ground_truths = list(set([k[1] for k in correlations.keys()]))\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    # Add text to show which centralities were used for the composite ranking\n",
    "    text = f\"Composite: {best_high} (high) + {best_low} (low)\"\n",
    "    if composite_param is not None:\n",
    "        text += f\"\\nComposite Param: {composite_param}\"\n",
    "    ax.text(0.02, 0.98, text,\n",
    "            transform=ax.transAxes, ha='left', va='top', \n",
    "            bbox=dict(facecolor='white', edgecolor='gray', alpha=0.6))\n",
    "    \n",
    "    x = np.arange(len(ground_truths))\n",
    "    width = 0.8 / (len(centralities) + 1)\n",
    "    \n",
    "    for i, centrality in enumerate(centralities + ['composite']):\n",
    "        offset = width * i - 0.4 + width/2\n",
    "        rects = ax.bar(x + offset, [correlations[(centrality, gt)] for gt in ground_truths], width, label=centrality)\n",
    "    \n",
    "    ax.set_ylabel('Correlation Coefficient')\n",
    "    ax.set_title(f'Correlations between Rankings and Ground Truths (optimized for {ground_truth})')\n",
    "    ax.set_xticks(x, ground_truths)\n",
    "    ax.legend(loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "\n",
    "def plot_centrality_vs_ground_truth(df, centrality, ground_truths, output_path):\n",
    "    \"\"\"\n",
    "    Plot centrality measure against ground truth metrics with error bars.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the data\n",
    "        centrality (str): Name of the centrality measure to plot\n",
    "        ground_truths (list): List of ground truth measures to compare against\n",
    "        output_path (str): Path to save the output plots\n",
    "    \"\"\"\n",
    "    for ground_truth in ground_truths:\n",
    "        # Prepare data\n",
    "        data = df[[ground_truth, centrality]].copy()\n",
    "        data = data[data[centrality] != -2]  # Remove uncomputed values\n",
    "        \n",
    "        # Group by ground truth value and calculate statistics\n",
    "        grouped_stats = data.groupby(ground_truth)[centrality].agg(['mean', 'std']).reset_index()\n",
    "        \n",
    "        # Create the plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Plot points and error bars\n",
    "        plt.errorbar(grouped_stats['mean'], \n",
    "                    grouped_stats[ground_truth],\n",
    "                    xerr=grouped_stats['std'],\n",
    "                    fmt='o',  # Changed from 'o-' to 'o' to remove connecting line\n",
    "                    capsize=5,\n",
    "                    capthick=1,\n",
    "                    elinewidth=1,\n",
    "                    markersize=8)\n",
    "        \n",
    "        # Customize the plot\n",
    "        plt.title(f'{centrality} vs. Average {ground_truth}', fontsize=16)\n",
    "        plt.xlabel(centrality.replace('_', ' ').title(), fontsize=16)\n",
    "        plt.ylabel(ground_truth.replace('_', ' ').title(), fontsize=16)\n",
    "        plt.yticks(grouped_stats[ground_truth], fontsize=16)\n",
    "        \n",
    "        # Add grid\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Adjust layout and save\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_path}/{centrality}_{ground_truth}_error_bars.png', \n",
    "                   bbox_inches='tight', \n",
    "                   dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "def save_correlations_to_csv(correlations, ground_truth, output_file, best_high, best_low):\n",
    "    \"\"\"\n",
    "    Save correlation results to a CSV file.\n",
    "\n",
    "    Args:\n",
    "    correlations (dict): Dictionary of correlation coefficients\n",
    "    ground_truth (str): The name of the current ground truth score\n",
    "    output_file (str): The name of the output CSV file\n",
    "    best_high (str): The name of the best centrality for high scores\n",
    "    best_low (str): The name of the best centrality for low scores\n",
    "\n",
    "    This function saves the correlation results to a CSV file for further analysis or reporting.\n",
    "    \"\"\"\n",
    "    df_correlations = pd.DataFrame(correlations.items(), columns=['Pair', 'Correlation'])\n",
    "    df_correlations[['Centrality', 'Ground Truth']] = pd.DataFrame(df_correlations['Pair'].tolist(), index=df_correlations.index)\n",
    "    df_correlations = df_correlations.drop('Pair', axis=1)\n",
    "    df_correlations.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Network Function\n",
    "> The `analyze_network()` function performs comprehensive network analysis using various centrality measures and composite rankings.\n",
    "\n",
    "## Input Parameters\n",
    "\n",
    "- `nodes_df`: Pandas DataFrame containing node information, including ground truth scores and node attributes\n",
    "- `edges_df`: Pandas DataFrame containing edge information (connections between nodes)  \n",
    "- `ground_truths`: List of column names in nodes_df that contain ground truth scores to analyze\n",
    "- `centralities`: List of centrality measures to calculate (e.g. degree, betweenness, etc.)\n",
    "- `composite_functions`: List of functions that combine multiple centrality measures into composite rankings\n",
    "- `output_path`: Directory path where analysis outputs will be saved\n",
    "\n",
    "## Processing Steps\n",
    "\n",
    "1. Creates output directory if it doesn't exist\n",
    "2. Makes a copy of the input nodes DataFrame\n",
    "3. For each ground truth measure:\n",
    "   - Calculates an inverted version (max value - original value)\n",
    "   - Stores inverted versions with \"_inverted\" suffix\n",
    "4. Cleans data by:\n",
    "   - Dropping rows with missing ECLI identifiers\n",
    "   - Converting doctypebranch to numeric values if present\n",
    "5. Calculates centrality measures specified\n",
    "6. Creates composite rankings using provided functions\n",
    "7. Computes correlations between:\n",
    "   - Individual centrality measures and ground truths\n",
    "   - Composite rankings and ground truths\n",
    "\n",
    "## Return Value\n",
    "\n",
    "Returns an `AnalysisResults` dictionary containing:\n",
    "- `network_stats`: Basic statistics about the network (nodes, edges, density etc.)\n",
    "- `correlations`: Correlation coefficients between rankings and ground truths\n",
    "- `best_centralities`: Best performing centrality measures for each ground truth\n",
    "- `composite_rankings`: Results of composite ranking calculations\n",
    "- `dataframe`: Final processed DataFrame with all measures included\n",
    "\n",
    "## Output Files\n",
    "\n",
    "Saves various analysis results to the specified output directory, including:\n",
    "- Correlation plots\n",
    "- CSV files with detailed results\n",
    "- Network statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_network(nodes_df: pd.DataFrame, \n",
    "                edges_df: pd.DataFrame, \n",
    "                ground_truths: list, \n",
    "                centralities: list,\n",
    "                composite_functions: list,\n",
    "                output_path: str, \n",
    "                merge_importance: bool = False) -> AnalysisResults:\n",
    "    \"\"\"\n",
    "    Analyze a network using various centrality measures and composite rankings.\n",
    "    \n",
    "    Args:\n",
    "        nodes_df: DataFrame containing node information\n",
    "        edges_df: DataFrame containing edge information\n",
    "        ground_truths: List of ground truth column names to analyze\n",
    "        centralities: List of centrality measures to calculate\n",
    "        composite_functions: List of composite ranking functions to use\n",
    "        output_path: Path where to save output files\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing:\n",
    "        - 'network_stats': Dict with network statistics (nodes, edges, density)\n",
    "        - 'correlations': Dict mapping ground truth names to correlation results\n",
    "        - 'best_centralities': Dict mapping ground truth names to their best centrality measures\n",
    "        - 'composite_rankings': Dict mapping composite function names to their results\n",
    "        - 'dataframe': pandas DataFrame with all calculated measures and rankings\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Make a copy of nodes dataframe\n",
    "    total_df = nodes_df.copy()\n",
    "\n",
    "    # Convert doctypebranch to numeric if it exists\n",
    "    if 'doctypebranch' in total_df.columns:\n",
    "        total_df['doctypebranch'] = categorise_total_branch_numerically(total_df['doctypebranch'])\n",
    "        # Remove rows with Nan doctypebranch\n",
    "        total_df = total_df.dropna(subset=['doctypebranch'])\n",
    "\n",
    "    # Convert ground truth columns to numeric\n",
    "    for truth in ground_truths:\n",
    "        total_df[truth] = pd.to_numeric(total_df[truth], errors='coerce')\n",
    "\n",
    "    # Merge importance levels of 1 and 2 together (assign value 1), transpose 3 to 2, and 4 to 3\n",
    "    if merge_importance:\n",
    "        total_df['importance'] = total_df['importance'].replace({1: 1, 2: 1, 3: 2, 4: 3})\n",
    "    \n",
    "    # Invert ground truth values\n",
    "    ground_truths_inverted = []\n",
    "    for truth in ground_truths:\n",
    "        max_value = total_df[truth].max()\n",
    "        inverted_col = f'{truth}_inverted'\n",
    "        total_df[inverted_col] = max_value - total_df[truth]\n",
    "        ground_truths_inverted.append(inverted_col)\n",
    "    \n",
    "    # Drop rows with missing ecli\n",
    "    total_df = total_df.dropna(subset=['ecli'])\n",
    "    \n",
    "    # Create graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes with attributes\n",
    "    for idx, row in total_df.iterrows():\n",
    "        node_attrs = {truth: row[truth] for truth in ground_truths if truth in row}\n",
    "        G.add_node(row['ecli'], **node_attrs)\n",
    "    \n",
    "    # Add edges between existing nodes\n",
    "    valid_nodes = set(total_df['ecli'].values)\n",
    "    for idx, row in edges_df.iterrows():\n",
    "        source = row['ecli']\n",
    "        targets = row['references']\n",
    "        if source in valid_nodes:\n",
    "            for target in targets:\n",
    "                if target and target in valid_nodes:\n",
    "                    G.add_edge(source, target)\n",
    "    \n",
    "    # Remove self-loops\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    \n",
    "    # Calculate centrality measures\n",
    "    centrality_measures = calculate_centrality_measures(G)\n",
    "    centrality_df = pd.DataFrame(centrality_measures)\n",
    "    \n",
    "    # Merge centrality measures with total_df\n",
    "    total_df = pd.merge(total_df, centrality_df, left_on='ecli', right_index=True, how='left')\n",
    "    \n",
    "    # Plot initial correlations\n",
    "    numeric_cols = total_df.select_dtypes(include=[float, int]).columns\n",
    "    for centrality in centralities:\n",
    "        if centrality in numeric_cols:\n",
    "            plot_centrality_vs_ground_truth(total_df, centrality, ground_truths, output_path)\n",
    "    \n",
    "    # Run composite rankings analysis and prepare results structure\n",
    "    results = {\n",
    "        'network_stats': {\n",
    "            'n_nodes': len(total_df),\n",
    "            'n_edges': len(edges_df)\n",
    "        },\n",
    "        'class_distribution': {\n",
    "            'total_cases': len(total_df),\n",
    "            'class_counts': {truth: total_df[truth].value_counts().to_dict() for truth in ground_truths},\n",
    "            'class_percentages': {truth: (total_df[truth].value_counts(normalize=True) * 100).to_dict() for truth in ground_truths}\n",
    "        },\n",
    "        'correlations': {},\n",
    "        'best_centralities': {},\n",
    "        'composite_rankings': {},\n",
    "        'dataframe': total_df\n",
    "    }\n",
    "\n",
    "    # Initialize result dictionaries for each ground truth\n",
    "    for ground_truth in ground_truths:\n",
    "        results['correlations'][ground_truth] = {}\n",
    "        results['best_centralities'][ground_truth] = {}\n",
    "        results['composite_rankings'][ground_truth] = {}\n",
    "        \n",
    "        # Find best centralities once per ground truth\n",
    "        best_high, best_low = find_best_centralities(total_df, centralities, ground_truth)\n",
    "        results['best_centralities'][ground_truth] = {\n",
    "            'high': best_high,\n",
    "            'low': best_low\n",
    "        }\n",
    "        # Log the best centralities found for this ground truth\n",
    "        print(f\"\\nBest centralities for {ground_truth}:\")\n",
    "        print(f\"Best high correlation: {best_high}\")\n",
    "        print(f\"Best low correlation: {best_low}\")\n",
    "        \n",
    "        # Process each composite function\n",
    "        for composite_function in composite_functions:\n",
    "            print(f\"\\nAnalyzing ground truth: {ground_truth} with {composite_function}\")\n",
    "            \n",
    "            # Create composite ranking based on function type\n",
    "            if composite_function == 'weight_composite_ranking':\n",
    "                optimal_weight = find_optimal_weight(total_df, best_high, best_low, ground_truth)\n",
    "                composite_ranking = create_composite_ranking(total_df, best_high, best_low, optimal_weight)\n",
    "                results['composite_rankings'][ground_truth][f'{composite_function}_param'] = optimal_weight\n",
    "            else:\n",
    "                composite_ranking, threshold = create_treashold_composite_ranking(total_df, best_high, best_low, ground_truth)\n",
    "                results['composite_rankings'][ground_truth][f'{composite_function}_param'] = threshold\n",
    "\n",
    "            # Add composite ranking to dataframe\n",
    "            ranking_col = f'composite_ranking_{ground_truth}_{composite_function}'\n",
    "            total_df[ranking_col] = composite_ranking\n",
    "            \n",
    "            # Calculate correlations once and store them\n",
    "            correlations = calculate_correlations(total_df, centralities, ground_truths, ranking_col)\n",
    "            results['correlations'][ground_truth][composite_function] = correlations\n",
    "            \n",
    "            # Store composite rankings\n",
    "            results['composite_rankings'][ground_truth][composite_function] = total_df[ranking_col].to_dict()\n",
    "            \n",
    "            # Save visualization outputs\n",
    "            plot_correlations(\n",
    "                correlations, \n",
    "                ground_truth, \n",
    "                f'{output_path}/correlations_plot_{ground_truth}_{composite_function}.png',\n",
    "                best_high, \n",
    "                best_low, \n",
    "                results['composite_rankings'][ground_truth][f'{composite_function}_param'],\n",
    "            )\n",
    "            \n",
    "            save_correlations_to_csv(\n",
    "                correlations,\n",
    "                ground_truth,\n",
    "                f'{output_path}/correlations_{ground_truth}_{composite_function}.csv',\n",
    "                best_high,\n",
    "                best_low\n",
    "            )\n",
    "\n",
    "    # Save results to JSON file\n",
    "    results_file = os.path.join(output_path, 'analysis_results.json')\n",
    "    with open(results_file, 'w') as f:\n",
    "        # Convert any non-serializable objects (like numpy arrays) to lists\n",
    "        json_results = {\n",
    "            'correlations': {\n",
    "                gt: {\n",
    "                    cf: {\n",
    "                        f\"{k[0]}_{k[1]}\": v  # Convert tuple key to string\n",
    "                        for k, v in cf_data.items()\n",
    "                    }\n",
    "                    for cf, cf_data in gt_data.items()\n",
    "                }\n",
    "                for gt, gt_data in results['correlations'].items()\n",
    "            },\n",
    "            'composite_rankings': {\n",
    "                gt: {\n",
    "                    cf: {\n",
    "                        k: (list(v.values()) if hasattr(v, 'values') else float(v))\n",
    "                        for k, v in cf_data.items()\n",
    "                    } if isinstance(cf_data, dict) else float(cf_data)\n",
    "                    for cf, cf_data in gt_data.items()\n",
    "                }\n",
    "                for gt, gt_data in results['composite_rankings'].items()\n",
    "            },\n",
    "            'best_centralities': results['best_centralities'],\n",
    "            'class_distribution': results['class_distribution'],\n",
    "            'network_stats': results['network_stats'],\n",
    "        }\n",
    "        json.dump(json_results, f, indent=4)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Function\n",
    "This section implements network comparison functionality to analyze and compare results across different networks.\n",
    "\n",
    "The main function `compare_networks()` takes results from multiple network analyses and performs the following comparisons:\n",
    "\n",
    "1. Correlation Comparisons:\n",
    "   - Compares how different centrality measures correlate with ground truth metrics across networks\n",
    "   - Creates comparison tables showing correlation values for each network\n",
    "   - Saves correlation comparisons to CSV files\n",
    "\n",
    "2. Ranking Comparisons: \n",
    "   - Analyzes how centrality measures rank relative to each other in different networks\n",
    "   - Converts absolute correlation values to rankings\n",
    "   - Shows which centrality measures perform consistently well across networks\n",
    "   - Saves ranking comparisons to CSV files\n",
    "\n",
    "The comparisons are performed for each combination of:\n",
    "- Ground truth metrics (e.g., PageRank, degree centrality)\n",
    "- Composite ranking functions (different ways of combining centrality measures)\n",
    "\n",
    "This allows us to:\n",
    "- Identify which centrality measures work best across different network types\n",
    "- Understand how network structure affects centrality measure performance\n",
    "- Compare the effectiveness of different composite ranking approaches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_networks(network_results: Dict[str, AnalysisResults], output_path: str, min_nodes: int = 50) -> Dict:\n",
    "    \"\"\"\n",
    "    Compare centrality measure performance across different networks.\n",
    "    \n",
    "    Args:\n",
    "        network_results: Dictionary mapping network names to their analysis results\n",
    "        output_path: Path to save comparison results\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing aggregated analysis results per ground truth\n",
    "    \"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Get ground truths from first network\n",
    "    first_network = list(network_results.values())[0]\n",
    "    ground_truths = list(first_network['correlations'].keys())\n",
    "    \n",
    "    analysis = {gt: {\n",
    "        'centrality_counts': {\n",
    "            'high': defaultdict(int),      # Times selected as best high\n",
    "            'low': defaultdict(int),       # Times selected as best low\n",
    "            'best_overall': defaultdict(int)  # Times had best correlation\n",
    "        },\n",
    "        'combination_counts': defaultdict(int),  # Times each high+low pair was selected\n",
    "        'composite_performance': {\n",
    "            'outperformed_count': 0,  # Times composite ranking beat individual centralities\n",
    "            'best_combinations': []    # Combinations that achieved best performance\n",
    "        }\n",
    "    } for gt in ground_truths}\n",
    "    \n",
    "    # Analyze each network's results\n",
    "    for network_name, results in network_results.items():\n",
    "        for ground_truth in ground_truths:\n",
    "            # Get best centralities selected for this network\n",
    "            best_centralities = results['best_centralities'][ground_truth]\n",
    "            best_high = best_centralities['high']\n",
    "            best_low = best_centralities['low']\n",
    "            \n",
    "            # Count individual centrality selections\n",
    "            analysis[ground_truth]['centrality_counts']['high'][best_high] += 1\n",
    "            analysis[ground_truth]['centrality_counts']['low'][best_low] += 1\n",
    "            \n",
    "            # Count combination selections\n",
    "            combination = f\"{best_high}+{best_low}\"\n",
    "            analysis[ground_truth]['combination_counts'][combination] += 1\n",
    "            \n",
    "            # Find best overall centrality (highest correlation)\n",
    "            correlations = results['correlations'][ground_truth]\n",
    "            for composite_func, corr_dict in correlations.items():\n",
    "                # Get correlation values for individual centralities\n",
    "                centrality_correlations = {\n",
    "                    cent: abs(corr) \n",
    "                    for (cent, gt), corr in corr_dict.items() \n",
    "                    if cent != 'composite'\n",
    "                }\n",
    "                \n",
    "                # Find best performing centrality\n",
    "                best_centrality = max(centrality_correlations.items(), key=lambda x: x[1])[0]\n",
    "                analysis[ground_truth]['centrality_counts']['best_overall'][best_centrality] += 1\n",
    "                \n",
    "                # Check if composite ranking outperformed individual centralities\n",
    "                composite_corr = abs(corr_dict[('composite', ground_truth)])\n",
    "                if composite_corr > max(centrality_correlations.values()):\n",
    "                    analysis[ground_truth]['composite_performance']['outperformed_count'] += 1\n",
    "                    analysis[ground_truth]['composite_performance']['best_combinations'].append({\n",
    "                        'network': network_name,\n",
    "                        'combination': combination,\n",
    "                        'correlation': composite_corr\n",
    "                    })\n",
    "    \n",
    "    # Save results\n",
    "    for ground_truth in ground_truths:\n",
    "        results_file = f'{output_path}/network_analysis_{ground_truth}.json'\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(analysis[ground_truth], f, indent=4)\n",
    "        \n",
    "        # Create summary DataFrames\n",
    "        centrality_summary = pd.DataFrame([{\n",
    "            'centrality': cent,\n",
    "            'times_best_high': analysis[ground_truth]['centrality_counts']['high'][cent],\n",
    "            'times_best_low': analysis[ground_truth]['centrality_counts']['low'][cent],\n",
    "            'times_best_overall': analysis[ground_truth]['centrality_counts']['best_overall'][cent]\n",
    "        } for cent in set(\n",
    "            list(analysis[ground_truth]['centrality_counts']['high'].keys()) +\n",
    "            list(analysis[ground_truth]['centrality_counts']['low'].keys()) +\n",
    "            list(analysis[ground_truth]['centrality_counts']['best_overall'].keys())\n",
    "        )])\n",
    "        \n",
    "        centrality_summary.to_csv(\n",
    "            f'{output_path}/centrality_summary_{ground_truth}.csv', \n",
    "            index=False\n",
    "        )\n",
    "        \n",
    "        # Combination summary\n",
    "        combination_summary = pd.DataFrame([{\n",
    "            'combination': comb,\n",
    "            'times_selected': count\n",
    "        } for comb, count in analysis[ground_truth]['combination_counts'].items()])\n",
    "        \n",
    "        combination_summary.to_csv(\n",
    "            f'{output_path}/combination_summary_{ground_truth}.csv',\n",
    "            index=False\n",
    "        )\n",
    "    \n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_network_commonalities(analysis_results: Dict, output_path: str, compare_all: bool = False):\n",
    "    \"\"\"\n",
    "    Visualize commonalities between networks focusing on centrality performance.\n",
    "    Each visualization is saved separately.\n",
    "    \n",
    "    Args:\n",
    "        analysis_results: Dictionary containing the analysis results from compare_networks()\n",
    "        output_path: Path to save visualization outputs\n",
    "    \"\"\"\n",
    "    # Set the aesthetic style\n",
    "    plt.style.use('default')\n",
    "    colors = {'importance': 'skyblue', 'doctypebranch': 'lightgreen'}\n",
    "    \n",
    "    # Helper function to add value labels\n",
    "    def add_value_labels(ax, rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.text(rect.get_x() + rect.get_width()/2., height,\n",
    "                    f'{int(height)}',\n",
    "                    ha='center', va='bottom')\n",
    "    \n",
    "    # 1. High Importance Performers Graph\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    for ground_truth in analysis_results:\n",
    "        high_counts = analysis_results[ground_truth]['centrality_counts']['high']\n",
    "        if high_counts:\n",
    "            centralities = list(high_counts.keys())\n",
    "            counts = list(high_counts.values())\n",
    "            bars = ax.bar(centralities, counts, label=ground_truth, alpha=0.7, color=colors[ground_truth])\n",
    "            add_value_labels(ax, bars)\n",
    "    \n",
    "    plt.ylabel('Times Selected as Best High Predictor')\n",
    "    plt.title('Best Performing Centralities for High Scores')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/high_performers.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Low Importance Performers Graph\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    for ground_truth in analysis_results:\n",
    "        low_counts = analysis_results[ground_truth]['centrality_counts']['low']\n",
    "        if low_counts:\n",
    "            centralities = list(low_counts.keys())\n",
    "            counts = list(low_counts.values())\n",
    "            bars = ax.bar(centralities, counts, label=ground_truth, alpha=0.7, color=colors[ground_truth])\n",
    "            add_value_labels(ax, bars)\n",
    "    \n",
    "    plt.ylabel('Times Selected as Best Low Predictor')\n",
    "    plt.title('Best Performing Centralities for Low Scores')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/low_performers.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Best Overall Performers Graph\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    for ground_truth in analysis_results:\n",
    "        best_overall = analysis_results[ground_truth]['centrality_counts']['best_overall']\n",
    "        if best_overall:\n",
    "            centralities = list(best_overall.keys())\n",
    "            counts = list(best_overall.values())\n",
    "            bars = ax.bar(centralities, counts, label=ground_truth, alpha=0.7, color=colors[ground_truth])\n",
    "            add_value_labels(ax, bars)\n",
    "    \n",
    "    plt.ylabel('Times Selected as Highest Predictor')\n",
    "    plt.title('Higest Overall Predicting Centralities')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/best_overall_performers.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Combination Performance Graph\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    for ground_truth in analysis_results:\n",
    "        combinations = analysis_results[ground_truth]['combination_counts']\n",
    "        if combinations:\n",
    "            combo_names = list(combinations.keys())\n",
    "            combo_counts = list(combinations.values())\n",
    "            bars = ax.bar(combo_names, combo_counts, label=ground_truth, alpha=0.7, color=colors[ground_truth])\n",
    "            add_value_labels(ax, bars)\n",
    "    \n",
    "    plt.ylabel('Times Selected as Highest Predictor')\n",
    "    plt.title('Best Performing Centrality Combinations')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/combination_performance.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Total Best Occurrences Graph\n",
    "    total_counts = {}\n",
    "    for ground_truth in analysis_results:\n",
    "        for category in ['high', 'low', 'best_overall']:\n",
    "            counts = analysis_results[ground_truth]['centrality_counts'][category]\n",
    "            for centrality, count in counts.items():\n",
    "                if centrality not in total_counts:\n",
    "                    total_counts[centrality] = 0\n",
    "                total_counts[centrality] += count\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    if total_counts:\n",
    "        centralities = list(total_counts.keys())\n",
    "        counts = list(total_counts.values())\n",
    "        bars = ax.bar(centralities, counts, color='lightcoral', alpha=0.7)\n",
    "        add_value_labels(ax, bars)\n",
    "    \n",
    "    plt.ylabel('Total Times Selected as Highest Predictor')\n",
    "    plt.title('Overall Best Performing Centralities (All Categories)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/total_best_occurrences.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 6. Compare across networks\n",
    "    \n",
    "    \n",
    "    # Generate performance summary\n",
    "    performance_summary = {}\n",
    "    for ground_truth in analysis_results:\n",
    "        performance_summary[ground_truth] = {\n",
    "            'best_performers': {},\n",
    "            'composite_performance': {},\n",
    "            'correlations': {}\n",
    "        }\n",
    "        \n",
    "        # Best high performer\n",
    "        high_counts = analysis_results[ground_truth]['centrality_counts']['high']\n",
    "        if high_counts:\n",
    "            best_high = max(high_counts.items(), key=lambda x: x[1])\n",
    "            performance_summary[ground_truth]['best_performers']['high'] = {\n",
    "                'centrality': best_high[0],\n",
    "                'times_selected': best_high[1]\n",
    "            }\n",
    "        \n",
    "        # Best low performer\n",
    "        low_counts = analysis_results[ground_truth]['centrality_counts']['low']\n",
    "        if low_counts:\n",
    "            best_low = max(low_counts.items(), key=lambda x: x[1])\n",
    "            performance_summary[ground_truth]['best_performers']['low'] = {\n",
    "                'centrality': best_low[0],\n",
    "                'times_selected': best_low[1]\n",
    "            }\n",
    "        \n",
    "        # Best combination\n",
    "        combinations = analysis_results[ground_truth]['combination_counts']\n",
    "        if combinations:\n",
    "            best_combo = max(combinations.items(), key=lambda x: x[1])\n",
    "            performance_summary[ground_truth]['best_performers']['combination'] = {\n",
    "                'combination': best_combo[0],\n",
    "                'times_selected': best_combo[1]\n",
    "            }\n",
    "        \n",
    "        # Composite performance\n",
    "        outperformed_count = analysis_results[ground_truth]['composite_performance']['outperformed_count']\n",
    "        best_combinations = analysis_results[ground_truth]['composite_performance']['best_combinations']\n",
    "        performance_summary[ground_truth]['composite_performance'] = {\n",
    "            'outperformed_count': outperformed_count,\n",
    "            'best_combinations': []\n",
    "        }\n",
    "        \n",
    "        if best_combinations:\n",
    "            combo_counts = {}\n",
    "            for entry in best_combinations:\n",
    "                combo = entry['combination']\n",
    "                combo_counts[combo] = combo_counts.get(combo, 0) + 1\n",
    "            \n",
    "            best_outperforming = max(combo_counts.items(), key=lambda x: x[1])\n",
    "            best_correlation = max(entry['correlation'] for entry in best_combinations)\n",
    "            \n",
    "            performance_summary[ground_truth]['composite_performance'].update({\n",
    "                'best_outperforming_combo': {\n",
    "                    'combination': best_outperforming[0],\n",
    "                    'times_outperformed': best_outperforming[1]\n",
    "                },\n",
    "                'highest_correlation': best_correlation,\n",
    "                'detailed_combinations': best_combinations\n",
    "            })\n",
    "    \n",
    "    # Add overall best performer\n",
    "    if total_counts:\n",
    "        best_overall = max(total_counts.items(), key=lambda x: x[1])\n",
    "        performance_summary['overall_best_performer'] = {\n",
    "            'centrality': best_overall[0],\n",
    "            'total_times_selected': best_overall[1]\n",
    "        }\n",
    "    \n",
    "    # Save performance summary as JSON\n",
    "    with open(f'{output_path}/performance_summary.json', 'w') as f:\n",
    "        json.dump(performance_summary, f, indent=4)\n",
    "    \n",
    "    # Save detailed numerical results\n",
    "    summary = {\n",
    "        ground_truth: {\n",
    "            'high_performers': dict(analysis_results[ground_truth]['centrality_counts']['high']),\n",
    "            'low_performers': dict(analysis_results[ground_truth]['centrality_counts']['low']),\n",
    "            'best_overall': dict(analysis_results[ground_truth]['centrality_counts']['best_overall']),\n",
    "            'combinations': dict(analysis_results[ground_truth]['combination_counts']),\n",
    "            'composite_performance': {\n",
    "                'outperformed_count': analysis_results[ground_truth]['composite_performance']['outperformed_count'],\n",
    "                'best_combinations': analysis_results[ground_truth]['composite_performance']['best_combinations']\n",
    "            },\n",
    "            'best_performers': {\n",
    "                'high': max(analysis_results[ground_truth]['centrality_counts']['high'].items(), \n",
    "                           key=lambda x: x[1])[0] if analysis_results[ground_truth]['centrality_counts']['high'] else None,\n",
    "                'low': max(analysis_results[ground_truth]['centrality_counts']['low'].items(), \n",
    "                          key=lambda x: x[1])[0] if analysis_results[ground_truth]['centrality_counts']['low'] else None,\n",
    "                'overall': max(analysis_results[ground_truth]['centrality_counts']['best_overall'].items(), \n",
    "                             key=lambda x: x[1])[0] if analysis_results[ground_truth]['centrality_counts']['best_overall'] else None,\n",
    "                'combination': max(analysis_results[ground_truth]['combination_counts'].items(), \n",
    "                                 key=lambda x: x[1])[0] if analysis_results[ground_truth]['combination_counts'] else None\n",
    "            }\n",
    "        }\n",
    "        for ground_truth in analysis_results\n",
    "    }\n",
    "    \n",
    "    # Add total counts to summary\n",
    "    summary['total_counts'] = total_counts\n",
    "    \n",
    "    # Save visualization summary\n",
    "    with open(f'{output_path}/visualization_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_networks(path, max=100, min_nodes=50):\n",
    "    \"\"\"\n",
    "    Load networks from a directory structure. Can handle both:\n",
    "    1. Direct network files (nodes.json and edges.json in the input path)\n",
    "    2. Networks in subdirectories\n",
    "    \n",
    "    Args:\n",
    "        path: Root directory to search for networks or direct path to a network\n",
    "        max: Maximum number of networks to load\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary of networks with structure {network_name: {'nodes': df, 'edges': df}}\n",
    "    \"\"\"\n",
    "    networks = {}\n",
    "    loaded_count = 0\n",
    "    \n",
    "    # Verify root directory exists and print absolute path\n",
    "    abs_root = os.path.abspath(path)\n",
    "    print(f\"Looking for networks in: {abs_root}\")\n",
    "    \n",
    "    if not os.path.exists(abs_root):\n",
    "        raise ValueError(f\"Directory {abs_root} does not exist\")\n",
    "        \n",
    "    def is_network_dir(dir_path):\n",
    "        \"\"\"Check if directory contains exactly nodes.json and edges.json\"\"\"\n",
    "        try:\n",
    "            contents = os.listdir(dir_path)\n",
    "            return ('nodes.json' in contents and 'edges.json' in contents)\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def load_network(dir_path, network_name, min_nodes=50):\n",
    "        \"\"\"Load a single network from a directory\"\"\"\n",
    "        print(f\"\\nChecking network: {network_name}\")\n",
    "        print(f\"  Path: {dir_path}\")\n",
    "        \n",
    "        nodes_file = os.path.join(dir_path, 'nodes.json')\n",
    "        edges_file = os.path.join(dir_path, 'edges.json')\n",
    "        \n",
    "        try:\n",
    "            # Load and validate data\n",
    "            print(\"  Loading data files...\")\n",
    "            nodes_df = pd.read_json(nodes_file)\n",
    "            edges_df = pd.read_json(edges_file)\n",
    "            \n",
    "            # Validate required columns\n",
    "            required_node_cols = ['ecli', 'importance', 'doctypebranch']\n",
    "            missing_cols = [col for col in required_node_cols if col not in nodes_df.columns]\n",
    "            if missing_cols:\n",
    "                print(f\"  Warning: Missing columns in nodes.json: {missing_cols}\")\n",
    "                print(f\"  Available columns: {nodes_df.columns.tolist()}\")\n",
    "                return False\n",
    "            \n",
    "            required_edge_cols = ['ecli', 'references']\n",
    "            missing_edge_cols = [col for col in required_edge_cols if col not in edges_df.columns]\n",
    "            if missing_edge_cols:\n",
    "                print(f\"  Warning: Missing columns in edges.json: {missing_edge_cols}\")\n",
    "                print(f\"  Available columns: {edges_df.columns.tolist()}\")\n",
    "                return False\n",
    "            \n",
    "            if len(nodes_df) < min_nodes:\n",
    "                print(f\"  Warning: Network {network_name} has fewer than {min_nodes} nodes\")\n",
    "                return False\n",
    "            \n",
    "            networks[network_name] = {\n",
    "                'nodes': nodes_df,\n",
    "                'edges': edges_df\n",
    "            }\n",
    "            print(f\"  Successfully loaded network with {len(nodes_df)} nodes and {len(edges_df)} edges\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading network: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def process_directory(current_path, parent_prefix=\"\"):\n",
    "        \"\"\"Recursively process directories looking for networks\"\"\"\n",
    "        nonlocal loaded_count\n",
    "        if loaded_count >= max:\n",
    "            return\n",
    "            \n",
    "        # First check if current directory is a network directory\n",
    "        if is_network_dir(current_path):\n",
    "            # Generate network name based on path\n",
    "            rel_path = os.path.relpath(current_path, abs_root)\n",
    "            network_name = rel_path.replace(os.sep, '-')\n",
    "            if network_name == '.':  # Handle case where path is direct to network\n",
    "                network_name = os.path.basename(current_path)\n",
    "            \n",
    "            if load_network(current_path, network_name, min_nodes):\n",
    "                loaded_count += 1\n",
    "            return\n",
    "        \n",
    "        # If not a network directory, search subdirectories\n",
    "        try:\n",
    "            for item in os.listdir(current_path):\n",
    "                if loaded_count >= max:\n",
    "                    break\n",
    "                    \n",
    "                item_path = os.path.join(current_path, item)\n",
    "                if not os.path.isdir(item_path):\n",
    "                    continue\n",
    "                    \n",
    "                process_directory(item_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error accessing directory {current_path}: {str(e)}\")\n",
    "    \n",
    "    # Start processing from root directory\n",
    "    process_directory(abs_root)\n",
    "    print(f\"\\nSuccessfully loaded {len(networks)} networks\")\n",
    "    return networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centralities of interest\n",
    "CENTRALITIES = ['degree_centrality', 'in_degree_centrality', 'out_degree_centrality', \n",
    "                'betweenness_centrality', 'closeness_centrality', 'core_number', \n",
    "                'relative_in_degree_centrality', 'eigenvector_centrality', \n",
    "                'pagerank', 'hits_hub', 'hits_authority', 'harmonic_centrality', 'disruption']\n",
    "\n",
    "# Ground truths of interest\n",
    "GROUND_TRUTHS = ['importance', 'doctypebranch']\n",
    "GROUND_TRUTHS_INVERTED = ['importance_inverted',  'doctypebranch_inverted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load all networks from data/split directory\n",
    "# network_results = {}\n",
    "\n",
    "# networks = load_networks('networks')\n",
    "\n",
    "# # Analyze Networks\n",
    "# for network_name, data in networks.items():\n",
    "#     print(f\"\\nAnalyzing network: {network_name}\")\n",
    "#     results = analyze_network(\n",
    "#         nodes_df=data['nodes'],\n",
    "#         edges_df=data['edges'],\n",
    "#         ground_truths=GROUND_TRUTHS,\n",
    "#         centralities=CENTRALITIES,\n",
    "#         composite_functions=['weight_composite_ranking',],\n",
    "#         output_path=f'results/{network_name}'\n",
    "#     )\n",
    "#     network_results[network_name] = results\n",
    "\n",
    "\n",
    "# # Before comparison\n",
    "# if not network_results:\n",
    "#     raise ValueError(\"No networks were successfully analyzed. Check if data/split directory contains valid network data.\")\n",
    "\n",
    "\n",
    "# # Compare results across networks\n",
    "# analysis = compare_networks(network_results, 'results/comparisons')\n",
    "\n",
    "# # Visualize results\n",
    "# visualize_network_commonalities(analysis, 'results/comparisons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "# UNBALANCED\n",
    "# network_results = {}\n",
    "# networks = load_networks('networks/balanced-importance')\n",
    "\n",
    "# # Analyze Networks\n",
    "# for network_name, data in networks.items():\n",
    "#     print(f\"\\nAnalyzing network: {network_name}\")\n",
    "#     results = analyze_network(\n",
    "#         nodes_df=data['nodes'],\n",
    "#         edges_df=data['edges'],\n",
    "#         ground_truths=GROUND_TRUTHS,\n",
    "#         centralities=CENTRALITIES,\n",
    "#         composite_functions=['weight_composite_ranking'],\n",
    "#         output_path=f'results/test/{network_name}'\n",
    "#     )\n",
    "#     network_results[network_name] = results\n",
    "\n",
    "# # Before comparison\n",
    "# if not network_results:\n",
    "#     raise ValueError(\"No networks were successfully analyzed. Check if data/split directory contains valid network data.\")\n",
    "\n",
    "\n",
    "# # Compare results across networks\n",
    "# analysis = compare_networks(network_results, 'results/test/comparisons')\n",
    "\n",
    "# # Visualize results\n",
    "# visualize_network_commonalities(analysis, 'results/test/comparisons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for networks in: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/full-balanced-importance\n",
      "\n",
      "Checking network: full-balanced-importance\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/full-balanced-importance\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 4268 nodes and 668 edges\n",
      "\n",
      "Successfully loaded 1 networks\n",
      "Looking for networks in: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/full-unbalanced\n",
      "\n",
      "Checking network: full-unbalanced\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/full-unbalanced\n",
      "  Loading data files...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successfully loaded network with 27801 nodes and 3979 edges\n",
      "\n",
      "Successfully loaded 1 networks\n",
      "Looking for networks in: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/full-balanced-doctypebranch\n",
      "\n",
      "Checking network: full-balanced-doctypebranch\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/full-balanced-doctypebranch\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1542 nodes and 142 edges\n",
      "\n",
      "Successfully loaded 1 networks\n",
      "\n",
      "Analyzing network: full-balanced-importance\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: full-unbalanced\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: full-balanced-doctypebranch\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: eigenvector_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:35: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax1.set_xticklabels(ax1.get_xticklabels(), ha='right')\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:49: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax2.set_xticklabels(ax2.get_xticklabels(), ha='right')\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:63: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax3.set_xticklabels(ax3.get_xticklabels(), ha='right')\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:77: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax4.set_xticklabels(ax4.get_xticklabels(), ha='right')\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:100: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax5.set_xticklabels(ax5.get_xticklabels(), ha='right')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for networks in: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced\n",
      "\n",
      "Checking network: article_2-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_2-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1222 nodes and 194 edges\n",
      "\n",
      "Checking network: article_8-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_8-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 3161 nodes and 417 edges\n",
      "\n",
      "Checking network: article_P4-2-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_P4-2-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 99 nodes and 29 edges\n",
      "\n",
      "Checking network: article_38-1-b\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_38-1-b\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 481 nodes and 11 edges\n",
      "\n",
      "Checking network: article_4-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_4-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 180 nodes and 36 edges\n",
      "\n",
      "Checking network: article_6-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_6-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 13018 nodes and 2436 edges\n",
      "\n",
      "Checking network: article_17\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_17\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 67 nodes and 12 edges\n",
      "\n",
      "Checking network: article_5-1-b\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_5-1-b\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 51 nodes and 5 edges\n",
      "\n",
      "Checking network: article_10\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_10\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1691 nodes and 314 edges\n",
      "\n",
      "Checking network: article_5-1-e\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_5-1-e\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 144 nodes and 19 edges\n",
      "\n",
      "Checking network: article_11-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_11-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 225 nodes and 59 edges\n",
      "\n",
      "Checking network: article_18\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_18\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 118 nodes and 10 edges\n",
      "\n",
      "Checking network: article_11\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_11\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 854 nodes and 74 edges\n",
      "\n",
      "Checking network: article_6-3-a\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_6-3-a\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 72 nodes and 16 edges\n",
      "\n",
      "Checking network: article_29\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_29\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 2521 nodes and 1040 edges\n",
      "\n",
      "Checking network: article_5-1-c\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_5-1-c\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 335 nodes and 46 edges\n",
      "\n",
      "Checking network: article_46-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_46-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 313 nodes and 88 edges\n",
      "\n",
      "Checking network: article_34\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_34\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1181 nodes and 239 edges\n",
      "\n",
      "Checking network: article_9-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_9-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 93 nodes and 21 edges\n",
      "\n",
      "Checking network: article_29-3\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_29-3\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 2514 nodes and 1037 edges\n",
      "\n",
      "Checking network: article_7-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_7-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 238 nodes and 12 edges\n",
      "\n",
      "Checking network: article_3+8\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_3+8\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 594 nodes and 16 edges\n",
      "\n",
      "Checking network: article_5-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_5-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 4238 nodes and 850 edges\n",
      "\n",
      "Checking network: article_35\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_35\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 3632 nodes and 998 edges\n",
      "\n",
      "Checking network: article_P1-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_P1-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 70 nodes and 4 edges\n",
      "\n",
      "Checking network: article_3\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_3\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 13795 nodes and 2240 edges\n",
      "\n",
      "Checking network: article_35-3-b\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_35-3-b\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 69 nodes and 13 edges\n",
      "\n",
      "Checking network: article_4\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_4\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 11943 nodes and 3453 edges\n",
      "\n",
      "Checking network: article_5\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_5\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 7376 nodes and 1219 edges\n",
      "\n",
      "Checking network: article_2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 7044 nodes and 1854 edges\n",
      "\n",
      "Checking network: article_P1-3\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_P1-3\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 186 nodes and 33 edges\n",
      "\n",
      "Checking network: article_P1-1-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_P1-1-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 3196 nodes and 585 edges\n",
      "\n",
      "Checking network: article_35-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_35-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 2289 nodes and 700 edges\n",
      "\n",
      "Checking network: article_37-1-a\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_37-1-a\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 92 nodes and 7 edges\n",
      "\n",
      "Checking network: article_10-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_10-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1501 nodes and 298 edges\n",
      "\n",
      "Checking network: article_6-3\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_6-3\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1282 nodes and 256 edges\n",
      "\n",
      "Checking network: article_2-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_2-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 186 nodes and 42 edges\n",
      "\n",
      "Checking network: article_8-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_8-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1009 nodes and 220 edges\n",
      "\n",
      "Checking network: article_P4-2-3\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_P4-2-3\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 52 nodes and 10 edges\n",
      "\n",
      "Checking network: article_6-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_6-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 704 nodes and 171 edges\n",
      "\n",
      "Checking network: article_6-3-c\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_6-3-c\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 664 nodes and 121 edges\n",
      "\n",
      "Checking network: article_13\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_13\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 3991 nodes and 500 edges\n",
      "\n",
      "Checking network: article_5-1-f\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_5-1-f\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 222 nodes and 55 edges\n",
      "\n",
      "Checking network: article_14\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_14\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1030 nodes and 155 edges\n",
      "\n",
      "Checking network: article_5-1-a\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_5-1-a\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 96 nodes and 10 edges\n",
      "\n",
      "Checking network: article_6-3-d\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_6-3-d\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 444 nodes and 69 edges\n",
      "\n",
      "Checking network: article_46\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_46\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 368 nodes and 103 edges\n",
      "\n",
      "Checking network: article_41\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_41\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 10100 nodes and 3342 edges\n",
      "\n",
      "Checking network: article_P4-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_P4-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 159 nodes and 34 edges\n",
      "\n",
      "Checking network: article_11-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_11-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 781 nodes and 69 edges\n",
      "\n",
      "Checking network: article_12\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_12\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 55 nodes and 4 edges\n",
      "\n",
      "Checking network: article_6-3-b\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_6-3-b\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 232 nodes and 86 edges\n",
      "\n",
      "Checking network: article_37\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_37\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1254 nodes and 76 edges\n",
      "\n",
      "Checking network: article_9-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_9-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 217 nodes and 44 edges\n",
      "\n",
      "Checking network: article_39\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_39\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 852 nodes and 29 edges\n",
      "\n",
      "Checking network: article_5-3\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_5-3\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 2755 nodes and 373 edges\n",
      "\n",
      "Checking network: article_5-4\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_5-4\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1439 nodes and 165 edges\n",
      "\n",
      "Checking network: article_38\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_38\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 594 nodes and 16 edges\n",
      "\n",
      "Checking network: article_7-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_7-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1404 nodes and 101 edges\n",
      "\n",
      "Checking network: article_3+5\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_3+5\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 3632 nodes and 998 edges\n",
      "\n",
      "Checking network: article_5-5\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_5-5\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 461 nodes and 53 edges\n",
      "\n",
      "Checking network: article_5-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_5-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 141 nodes and 29 edges\n",
      "\n",
      "Checking network: article_37-1-c\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_37-1-c\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 169 nodes and 23 edges\n",
      "\n",
      "Checking network: article_P7-4\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_P7-4\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 134 nodes and 11 edges\n",
      "\n",
      "Checking network: article_9\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_9\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 3579 nodes and 1107 edges\n",
      "\n",
      "Checking network: article_P1-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_P1-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 4514 nodes and 679 edges\n",
      "\n",
      "Checking network: article_35-3\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_35-3\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 992 nodes and 214 edges\n",
      "\n",
      "Checking network: article_35-3-a\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_35-3-a\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 489 nodes and 107 edges\n",
      "\n",
      "Checking network: article_7\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_7\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1872 nodes and 143 edges\n",
      "\n",
      "Checking network: article_P7-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_P7-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 230 nodes and 11 edges\n",
      "\n",
      "Checking network: article_37-1-b\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_37-1-b\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 123 nodes and 11 edges\n",
      "\n",
      "Checking network: article_10-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_10-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 886 nodes and 278 edges\n",
      "\n",
      "Checking network: article_37-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_37-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1241 nodes and 74 edges\n",
      "\n",
      "Checking network: article_1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 23768 nodes and 3938 edges\n",
      "\n",
      "Checking network: article_6\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_6\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 15091 nodes and 2556 edges\n",
      "\n",
      "Checking network: article_8\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_8\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 3677 nodes and 448 edges\n",
      "\n",
      "Checking network: article_P1-1-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/unbalanced/article_P1-1-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 340 nodes and 63 edges\n",
      "\n",
      "Successfully loaded 77 networks\n",
      "\n",
      "Analyzing network: article_2-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_8-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_P4-2-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: harmonic_centrality\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_38-1-b\n",
      "Warning: All disruption values are 0\n",
      "Warning: All disruption values are identical: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/env/lib/python3.12/site-packages/networkx/algorithms/link_analysis/hits_alg.py:92: RuntimeWarning: invalid value encountered in divide\n",
      "  h /= h.sum()\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:200: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(composite, df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:200: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(composite, df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_4-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: closeness_centrality\n",
      "Best low correlation: harmonic_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-1-b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: hits_authority\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: hits_authority\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_10\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-1-e\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_11-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: hits_hub\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_11\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6-3-a\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_29\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-1-c\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_46-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_34\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_9-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_29-3\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: hits_authority\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_7-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_3+8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_35\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_P1-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: out_degree_centrality\n",
      "Best low correlation: hits_hub\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: hits_authority\n",
      "Best low correlation: out_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_3\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_35-3-b\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_4\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_P1-3\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: eigenvector_centrality\n",
      "Best low correlation: harmonic_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_P1-1-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_35-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_37-1-a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: hits_authority\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_10-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6-3\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_2-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: closeness_centrality\n",
      "Best low correlation: harmonic_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: hits_authority\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_8-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: disruption\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_P4-2-3\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: eigenvector_centrality\n",
      "Best low correlation: harmonic_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6-3-c\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_13\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-1-f\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_14\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-1-a\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6-3-d\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_46\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_41\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_P4-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: closeness_centrality\n",
      "Best low correlation: harmonic_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_11-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: hits_authority\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6-3-b\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: hits_hub\n",
      "Best low correlation: out_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_37\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_9-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-3\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-4\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_7-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_3+5\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-5\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_37-1-c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_P7-4\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_9\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: eigenvector_centrality\n",
      "Best low correlation: harmonic_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: harmonic_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_P1-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_35-3\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_35-3-a\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_7\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_P7-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_37-1-b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_10-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: hits_hub\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_37-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_8\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_P1-1-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:35: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax1.set_xticklabels(ax1.get_xticklabels(), ha='right')\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:49: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax2.set_xticklabels(ax2.get_xticklabels(), ha='right')\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:63: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax3.set_xticklabels(ax3.get_xticklabels(), ha='right')\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:77: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax4.set_xticklabels(ax4.get_xticklabels(), ha='right')\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:100: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax5.set_xticklabels(ax5.get_xticklabels(), ha='right')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for networks in: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance\n",
      "\n",
      "Checking network: article_2-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_2-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 296 nodes and 43 edges\n",
      "\n",
      "Checking network: article_8-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_8-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 816 nodes and 112 edges\n",
      "\n",
      "Checking network: article_4-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_4-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 61 nodes and 9 edges\n",
      "\n",
      "Checking network: article_6-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_6-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1748 nodes and 308 edges\n",
      "\n",
      "Checking network: article_10\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_10\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 434 nodes and 59 edges\n",
      "\n",
      "Checking network: article_11-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_11-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 94 nodes and 12 edges\n",
      "\n",
      "Checking network: article_18\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_18\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 50 nodes and 3 edges\n",
      "\n",
      "Checking network: article_11\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_11\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 154 nodes and 14 edges\n",
      "\n",
      "Checking network: article_29\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_29\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 357 nodes and 129 edges\n",
      "\n",
      "Checking network: article_5-1-c\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_5-1-c\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 85 nodes and 9 edges\n",
      "\n",
      "Checking network: article_46-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_46-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 137 nodes and 31 edges\n",
      "\n",
      "Checking network: article_34\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_34\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 404 nodes and 73 edges\n",
      "\n",
      "Checking network: article_9-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_9-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 54 nodes and 9 edges\n",
      "\n",
      "Checking network: article_29-3\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_29-3\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 357 nodes and 129 edges\n",
      "\n",
      "Checking network: article_3+8\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_3+8\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 83 nodes and 2 edges\n",
      "\n",
      "Checking network: article_5-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_5-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1038 nodes and 184 edges\n",
      "\n",
      "Checking network: article_35\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_35\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1118 nodes and 215 edges\n",
      "\n",
      "Checking network: article_3\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_3\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 2496 nodes and 412 edges\n",
      "\n",
      "Checking network: article_4\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_4\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 2875 nodes and 557 edges\n",
      "\n",
      "Checking network: article_5\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_5\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1598 nodes and 260 edges\n",
      "\n",
      "Checking network: article_2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1792 nodes and 336 edges\n",
      "\n",
      "Checking network: article_P1-3\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_P1-3\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 60 nodes and 6 edges\n",
      "\n",
      "Checking network: article_P1-1-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_P1-1-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 470 nodes and 95 edges\n",
      "\n",
      "Checking network: article_35-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_35-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 724 nodes and 147 edges\n",
      "\n",
      "Checking network: article_10-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_10-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 376 nodes and 56 edges\n",
      "\n",
      "Checking network: article_6-3\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_6-3\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 264 nodes and 50 edges\n",
      "\n",
      "Checking network: article_2-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_2-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 59 nodes and 10 edges\n",
      "\n",
      "Checking network: article_8-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_8-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 427 nodes and 67 edges\n",
      "\n",
      "Checking network: article_6-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_6-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 277 nodes and 51 edges\n",
      "\n",
      "Checking network: article_6-3-c\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_6-3-c\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 135 nodes and 23 edges\n",
      "\n",
      "Checking network: article_13\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_13\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 651 nodes and 105 edges\n",
      "\n",
      "Checking network: article_5-1-f\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_5-1-f\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 56 nodes and 15 edges\n",
      "\n",
      "Checking network: article_14\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_14\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 431 nodes and 48 edges\n",
      "\n",
      "Checking network: article_6-3-d\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_6-3-d\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 89 nodes and 9 edges\n",
      "\n",
      "Checking network: article_46\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_46\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 166 nodes and 36 edges\n",
      "\n",
      "Checking network: article_41\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_41\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 2533 nodes and 521 edges\n",
      "\n",
      "Checking network: article_11-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_11-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 131 nodes and 13 edges\n",
      "\n",
      "Checking network: article_6-3-b\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_6-3-b\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 61 nodes and 15 edges\n",
      "\n",
      "Checking network: article_37\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_37\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 161 nodes and 19 edges\n",
      "\n",
      "Checking network: article_9-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_9-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 92 nodes and 12 edges\n",
      "\n",
      "Checking network: article_39\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_39\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 67 nodes and 6 edges\n",
      "\n",
      "Checking network: article_5-3\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_5-3\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 550 nodes and 82 edges\n",
      "\n",
      "Checking network: article_5-4\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_5-4\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 259 nodes and 37 edges\n",
      "\n",
      "Checking network: article_38\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_38\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 83 nodes and 2 edges\n",
      "\n",
      "Checking network: article_7-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_7-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 229 nodes and 27 edges\n",
      "\n",
      "Checking network: article_5-5\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_5-5\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 61 nodes and 10 edges\n",
      "\n",
      "Checking network: article_5-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_5-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 50 nodes and 8 edges\n",
      "\n",
      "Checking network: article_9\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_9\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 536 nodes and 147 edges\n",
      "\n",
      "Checking network: article_P1-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_P1-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 596 nodes and 115 edges\n",
      "\n",
      "Checking network: article_35-3\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_35-3\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 314 nodes and 56 edges\n",
      "\n",
      "Checking network: article_35-3-a\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_35-3-a\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 156 nodes and 27 edges\n",
      "\n",
      "Checking network: article_7\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_7\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 326 nodes and 36 edges\n",
      "\n",
      "Checking network: article_10-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_10-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 317 nodes and 54 edges\n",
      "\n",
      "Checking network: article_37-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_37-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 158 nodes and 17 edges\n",
      "\n",
      "Checking network: article_1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 3987 nodes and 659 edges\n",
      "\n",
      "Checking network: article_6\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_6\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 2022 nodes and 347 edges\n",
      "\n",
      "Checking network: article_8\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_8\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 942 nodes and 115 edges\n",
      "\n",
      "Checking network: article_P1-1-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-importance/article_P1-1-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 92 nodes and 15 edges\n",
      "\n",
      "Successfully loaded 58 networks\n",
      "\n",
      "Analyzing network: article_2-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_8-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_4-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: hits_authority\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_10\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: harmonic_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_11-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_18\n",
      "Warning: All disruption values are 0\n",
      "Warning: All disruption values are identical: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/env/lib/python3.12/site-packages/networkx/algorithms/link_analysis/hits_alg.py:92: RuntimeWarning: invalid value encountered in divide\n",
      "  h /= h.sum()\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:200: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(composite, df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:200: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(composite, df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_29\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-1-c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_46-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_34\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_9-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: hits_authority\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_29-3\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_3+8\n",
      "Warning: All disruption values are 0\n",
      "Warning: All disruption values are identical: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/env/lib/python3.12/site-packages/networkx/algorithms/link_analysis/hits_alg.py:92: RuntimeWarning: invalid value encountered in divide\n",
      "  h /= h.sum()\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:200: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(composite, df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:200: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(composite, df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_35\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_3\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_4\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_P1-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_P1-1-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_35-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: harmonic_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_10-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: harmonic_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6-3\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_2-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: hits_authority\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_8-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: hits_authority\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: out_degree_centrality\n",
      "Best low correlation: disruption\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: out_degree_centrality\n",
      "Best low correlation: disruption\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6-3-c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_13\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-1-f\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: eigenvector_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: betweenness_centrality\n",
      "Best low correlation: hits_authority\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_14\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: eigenvector_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6-3-d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_46\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: hits_authority\n",
      "Best low correlation: disruption\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: hits_authority\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_41\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_11-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6-3-b\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: hits_hub\n",
      "Best low correlation: out_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_9-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-3\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-4\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: harmonic_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_38\n",
      "Warning: All disruption values are 0\n",
      "Warning: All disruption values are identical: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/env/lib/python3.12/site-packages/networkx/algorithms/link_analysis/hits_alg.py:92: RuntimeWarning: invalid value encountered in divide\n",
      "  h /= h.sum()\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:200: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(composite, df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:200: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(composite, df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_7-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: hits_authority\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_9\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_P1-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_35-3\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: harmonic_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: harmonic_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_35-3-a\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: disruption\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: closeness_centrality\n",
      "Best low correlation: eigenvector_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: eigenvector_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_10-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: hits_hub\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_37-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: hits_hub\n",
      "Best low correlation: hits_authority\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_8\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_P1-1-2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: harmonic_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:35: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax1.set_xticklabels(ax1.get_xticklabels(), ha='right')\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:49: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax2.set_xticklabels(ax2.get_xticklabels(), ha='right')\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:63: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax3.set_xticklabels(ax3.get_xticklabels(), ha='right')\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:77: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax4.set_xticklabels(ax4.get_xticklabels(), ha='right')\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:100: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax5.set_xticklabels(ax5.get_xticklabels(), ha='right')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for networks in: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch\n",
      "\n",
      "Checking network: article_2-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_2-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 79 nodes and 5 edges\n",
      "\n",
      "Checking network: article_8-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_8-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 224 nodes and 20 edges\n",
      "\n",
      "Checking network: article_6-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_6-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 676 nodes and 75 edges\n",
      "\n",
      "Checking network: article_10\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_10\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 142 nodes and 14 edges\n",
      "\n",
      "Checking network: article_11\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_11\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 66 nodes and 6 edges\n",
      "\n",
      "Checking network: article_29\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_29\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 74 nodes and 29 edges\n",
      "\n",
      "Checking network: article_34\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_34\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 104 nodes and 19 edges\n",
      "\n",
      "Checking network: article_29-3\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_29-3\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 74 nodes and 29 edges\n",
      "\n",
      "Checking network: article_5-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_5-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 311 nodes and 38 edges\n",
      "\n",
      "Checking network: article_35\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_35\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 268 nodes and 43 edges\n",
      "\n",
      "Checking network: article_3\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_3\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 833 nodes and 77 edges\n",
      "\n",
      "Checking network: article_4\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_4\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 705 nodes and 116 edges\n",
      "\n",
      "Checking network: article_5\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_5\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 485 nodes and 48 edges\n",
      "\n",
      "Checking network: article_2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 469 nodes and 71 edges\n",
      "\n",
      "Checking network: article_P1-1-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_P1-1-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 203 nodes and 15 edges\n",
      "\n",
      "Checking network: article_35-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_35-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 183 nodes and 34 edges\n",
      "\n",
      "Checking network: article_10-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_10-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 132 nodes and 14 edges\n",
      "\n",
      "Checking network: article_6-3\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_6-3\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 67 nodes and 4 edges\n",
      "\n",
      "Checking network: article_8-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_8-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 88 nodes and 8 edges\n",
      "\n",
      "Checking network: article_6-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_6-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 89 nodes and 11 edges\n",
      "\n",
      "Checking network: article_13\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_13\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 229 nodes and 18 edges\n",
      "\n",
      "Checking network: article_14\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_14\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 105 nodes and 8 edges\n",
      "\n",
      "Checking network: article_46\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_46\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 51 nodes and 8 edges\n",
      "\n",
      "Checking network: article_41\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_41\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 544 nodes and 110 edges\n",
      "\n",
      "Checking network: article_11-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_11-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 60 nodes and 5 edges\n",
      "\n",
      "Checking network: article_37\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_37\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 78 nodes and 7 edges\n",
      "\n",
      "Checking network: article_5-3\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_5-3\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 201 nodes and 14 edges\n",
      "\n",
      "Checking network: article_5-4\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_5-4\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 95 nodes and 7 edges\n",
      "\n",
      "Checking network: article_7-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_7-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 100 nodes and 6 edges\n",
      "\n",
      "Checking network: article_9\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_9\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 136 nodes and 31 edges\n",
      "\n",
      "Checking network: article_P1-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_P1-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 262 nodes and 22 edges\n",
      "\n",
      "Checking network: article_35-3\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_35-3\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 98 nodes and 11 edges\n",
      "\n",
      "Checking network: article_7\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_7\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 139 nodes and 12 edges\n",
      "\n",
      "Checking network: article_10-2\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_10-2\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 94 nodes and 10 edges\n",
      "\n",
      "Checking network: article_37-1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_37-1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 76 nodes and 5 edges\n",
      "\n",
      "Checking network: article_1\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_1\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 1369 nodes and 141 edges\n",
      "\n",
      "Checking network: article_6\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_6\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 772 nodes and 81 edges\n",
      "\n",
      "Checking network: article_8\n",
      "  Path: /Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/networks/balanced-doctypebranch/article_8\n",
      "  Loading data files...\n",
      "  Successfully loaded network with 254 nodes and 21 edges\n",
      "\n",
      "Successfully loaded 38 networks\n",
      "\n",
      "Analyzing network: article_2-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: hits_authority\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_8-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6-1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: eigenvector_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: disruption\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: hits_authority\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: hits_authority\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_29\n",
      "Warning: All disruption values are 0\n",
      "Warning: All disruption values are identical: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/env/lib/python3.12/site-packages/networkx/algorithms/link_analysis/hits_alg.py:92: RuntimeWarning: invalid value encountered in divide\n",
      "  h /= h.sum()\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:200: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(composite, df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:200: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(composite, df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: out_degree_centrality\n",
      "Best low correlation: hits_hub\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_29-3\n",
      "Warning: All disruption values are 0\n",
      "Warning: All disruption values are identical: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/env/lib/python3.12/site-packages/networkx/algorithms/link_analysis/hits_alg.py:92: RuntimeWarning: invalid value encountered in divide\n",
      "  h /= h.sum()\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:200: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(composite, df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:200: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(composite, df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: out_degree_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: out_degree_centrality\n",
      "Best low correlation: disruption\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_3\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_4\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: eigenvector_centrality\n",
      "Best low correlation: harmonic_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_2\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_P1-1-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_35-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: out_degree_centrality\n",
      "Best low correlation: hits_hub\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: out_degree_centrality\n",
      "Best low correlation: hits_hub\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_10-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: disruption\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_8-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: out_degree_centrality\n",
      "Best low correlation: hits_hub\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_14\n",
      "Warning: All disruption values are 0\n",
      "Warning: All disruption values are identical: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidwickerhf/Projects/work/maastrichtuniversity/rankings/env/lib/python3.12/site-packages/networkx/algorithms/link_analysis/hits_alg.py:92: RuntimeWarning: invalid value encountered in divide\n",
      "  h /= h.sum()\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:200: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(composite, df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:200: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(composite, df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: out_degree_centrality\n",
      "Best low correlation: hits_hub\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_41\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: out_degree_centrality\n",
      "Best low correlation: hits_hub\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: eigenvector_centrality\n",
      "Best low correlation: harmonic_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_11-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: degree_centrality\n",
      "Best low correlation: core_number\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: hits_hub\n",
      "Best low correlation: hits_authority\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_5-4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: core_number\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_7-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: hits_authority\n",
      "Best low correlation: hits_hub\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: hits_authority\n",
      "Best low correlation: hits_hub\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: out_degree_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_P1-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_35-3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: hits_hub\n",
      "Best low correlation: disruption\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: hits_hub\n",
      "Best low correlation: disruption\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: hits_authority\n",
      "Best low correlation: degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_10-2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: out_degree_centrality\n",
      "Best low correlation: pagerank\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: out_degree_centrality\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_37-1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: out_degree_centrality\n",
      "Best low correlation: hits_hub\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: hits_authority\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_1\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: pagerank\n",
      "Best low correlation: eigenvector_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_6\n",
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: eigenvector_centrality\n",
      "Best low correlation: closeness_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n",
      "\n",
      "Analyzing network: article_8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/2472766247.py:83: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best centralities for importance:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: importance with weight_composite_ranking\n",
      "\n",
      "Best centralities for doctypebranch:\n",
      "Best high correlation: disruption\n",
      "Best low correlation: in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch with weight_composite_ranking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:35: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax1.set_xticklabels(ax1.get_xticklabels(), ha='right')\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:49: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax2.set_xticklabels(ax2.get_xticklabels(), ha='right')\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:63: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax3.set_xticklabels(ax3.get_xticklabels(), ha='right')\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:77: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax4.set_xticklabels(ax4.get_xticklabels(), ha='right')\n",
      "/var/folders/26/0sr3rdx53314n7l3fzj55k6r0000gn/T/ipykernel_67202/1978272260.py:100: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax5.set_xticklabels(ax5.get_xticklabels(), ha='right')\n"
     ]
    }
   ],
   "source": [
    "# Analyse whole networks (balanced and unbalanced)\n",
    "network_results = {}\n",
    "\n",
    "networks = load_networks('networks/full-balanced-importance')\n",
    "networks.update(load_networks('networks/full-unbalanced'))\n",
    "networks.update(load_networks('networks/full-balanced-doctypebranch'))\n",
    "\n",
    "# Analyze Networks\n",
    "for network_name, data in networks.items():\n",
    "    print(f\"\\nAnalyzing network: {network_name}\")\n",
    "    results = analyze_network(\n",
    "        nodes_df=data['nodes'],\n",
    "        edges_df=data['edges'],\n",
    "        ground_truths=GROUND_TRUTHS,\n",
    "        centralities=CENTRALITIES,\n",
    "        composite_functions=['weight_composite_ranking',],\n",
    "        output_path=f'results/full/{network_name}'\n",
    "    )\n",
    "    network_results[network_name] = results\n",
    "\n",
    "\n",
    "\n",
    "# Before comparison\n",
    "if not network_results:\n",
    "    raise ValueError(\"No networks were successfully analyzed. Check if data/split directory contains valid network data.\")\n",
    "\n",
    "\n",
    "# Compare results across networks\n",
    "analysis = compare_networks(network_results, 'results/full/comparisons')\n",
    "\n",
    "# Visualize results\n",
    "visualize_network_commonalities(analysis, 'results/full/comparisons')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ANALYSE SPLIT NETWORKS\n",
    "# UNBALANCED\n",
    "network_results = {}\n",
    "networks = load_networks('networks/unbalanced')\n",
    "\n",
    "# Analyze Networks\n",
    "for network_name, data in networks.items():\n",
    "    print(f\"\\nAnalyzing network: {network_name}\")\n",
    "    results = analyze_network(\n",
    "        nodes_df=data['nodes'],\n",
    "        edges_df=data['edges'],\n",
    "        ground_truths=GROUND_TRUTHS,\n",
    "        centralities=CENTRALITIES,\n",
    "        composite_functions=['weight_composite_ranking',],\n",
    "        output_path=f'results/unbalanced/{network_name}'\n",
    "    )\n",
    "    network_results[network_name] = results\n",
    "\n",
    "# Before comparison\n",
    "if not network_results:\n",
    "    raise ValueError(\"No networks were successfully analyzed. Check if data/split directory contains valid network data.\")\n",
    "\n",
    "\n",
    "# Compare results across networks\n",
    "analysis = compare_networks(network_results, 'results/unbalanced/comparisons')\n",
    "\n",
    "# Visualize results\n",
    "visualize_network_commonalities(analysis, 'results/unbalanced/comparisons')\n",
    "\n",
    "\n",
    "\n",
    "# BALANCED BY IMPORRTANCE \n",
    "network_results = {}\n",
    "networks = load_networks('networks/balanced-importance')\n",
    "\n",
    "# Analyze Networks\n",
    "for network_name, data in networks.items():\n",
    "    print(f\"\\nAnalyzing network: {network_name}\")\n",
    "    results = analyze_network(\n",
    "        nodes_df=data['nodes'],\n",
    "        edges_df=data['edges'],\n",
    "        ground_truths=GROUND_TRUTHS,\n",
    "        centralities=CENTRALITIES,\n",
    "        composite_functions=['weight_composite_ranking',],\n",
    "        output_path=f'results/balanced-importance/{network_name}'\n",
    "    )\n",
    "    network_results[network_name] = results\n",
    "\n",
    "# Before comparison\n",
    "if not network_results:\n",
    "    raise ValueError(\"No networks were successfully analyzed. Check if data/split directory contains valid network data.\")\n",
    "\n",
    "\n",
    "# Compare results across networks\n",
    "analysis = compare_networks(network_results, 'results/balanced-importance/comparisons')\n",
    "\n",
    "# Visualize results\n",
    "visualize_network_commonalities(analysis, 'results/balanced-importance/comparisons')\n",
    "\n",
    "\n",
    "\n",
    "# BALANCED BY DOCTYPEBRANCH\n",
    "network_results = {}\n",
    "networks = load_networks('networks/balanced-doctypebranch')\n",
    "\n",
    "# Analyze Networks\n",
    "for network_name, data in networks.items():\n",
    "    print(f\"\\nAnalyzing network: {network_name}\")\n",
    "    results = analyze_network(\n",
    "        nodes_df=data['nodes'],\n",
    "        edges_df=data['edges'],\n",
    "        ground_truths=GROUND_TRUTHS,\n",
    "        centralities=CENTRALITIES,\n",
    "        composite_functions=['weight_composite_ranking',],\n",
    "        output_path=f'results/balanced-doctypebranch/{network_name}'\n",
    "    )\n",
    "    network_results[network_name] = results\n",
    "\n",
    "# Before comparison\n",
    "if not network_results:\n",
    "    raise ValueError(\"No networks were successfully analyzed. Check if data/split directory contains valid network data.\")\n",
    "\n",
    "\n",
    "# Compare results across networks\n",
    "analysis = compare_networks(network_results, 'results/balanced-doctypebranch/comparisons')\n",
    "\n",
    "# Visualize results\n",
    "visualize_network_commonalities(analysis, 'results/balanced-doctypebranch/comparisons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse whole networks (balanced and unbalanced)\n",
    "network_results = {}\n",
    "\n",
    "networks = load_networks('networks/full-balanced-importance')\n",
    "networks.update(load_networks('networks/full-unbalanced'))\n",
    "networks.update(load_networks('networks/full-balanced-doctypebranch'))\n",
    "\n",
    "# Analyze Networks\n",
    "for network_name, data in networks.items():\n",
    "    print(f\"\\nAnalyzing network: {network_name}\")\n",
    "    results = analyze_network(\n",
    "        nodes_df=data['nodes'],\n",
    "        edges_df=data['edges'],\n",
    "        ground_truths=GROUND_TRUTHS,\n",
    "        centralities=CENTRALITIES,\n",
    "        composite_functions=['weight_composite_ranking',],\n",
    "        output_path=f'results/branch-update/full/{network_name}'\n",
    "    )\n",
    "    network_results[network_name] = results\n",
    "\n",
    "\n",
    "\n",
    "# Before comparison\n",
    "if not network_results:\n",
    "    raise ValueError(\"No networks were successfully analyzed. Check if data/split directory contains valid network data.\")\n",
    "\n",
    "\n",
    "# Compare results across networks\n",
    "analysis = compare_networks(network_results, 'results/branch-update/full/comparisons')\n",
    "\n",
    "# Visualize results\n",
    "visualize_network_commonalities(analysis, 'results/branch-update/full/comparisons')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ANALYSE SPLIT NETWORKS\n",
    "# UNBALANCED\n",
    "network_results = {}\n",
    "networks = load_networks('networks/unbalanced')\n",
    "\n",
    "# Analyze Networks\n",
    "for network_name, data in networks.items():\n",
    "    print(f\"\\nAnalyzing network: {network_name}\")\n",
    "    results = analyze_network(\n",
    "        nodes_df=data['nodes'],\n",
    "        edges_df=data['edges'],\n",
    "        ground_truths=GROUND_TRUTHS,\n",
    "        centralities=CENTRALITIES,\n",
    "        composite_functions=['weight_composite_ranking',],\n",
    "        output_path=f'results/branch-update/unbalanced/{network_name}'\n",
    "    )\n",
    "    network_results[network_name] = results\n",
    "\n",
    "# Before comparison\n",
    "if not network_results:\n",
    "    raise ValueError(\"No networks were successfully analyzed. Check if data/split directory contains valid network data.\")\n",
    "\n",
    "\n",
    "# Compare results across networks\n",
    "analysis = compare_networks(network_results, 'results/branch-update/unbalanced/comparisons')\n",
    "\n",
    "# Visualize results\n",
    "visualize_network_commonalities(analysis, 'results/branch-update/unbalanced/comparisons')\n",
    "\n",
    "\n",
    "\n",
    "# BALANCED BY IMPORRTANCE \n",
    "network_results = {}\n",
    "networks = load_networks('networks/balanced-importance')\n",
    "\n",
    "# Analyze Networks\n",
    "for network_name, data in networks.items():\n",
    "    print(f\"\\nAnalyzing network: {network_name}\")\n",
    "    results = analyze_network(\n",
    "        nodes_df=data['nodes'],\n",
    "        edges_df=data['edges'],\n",
    "        ground_truths=GROUND_TRUTHS,\n",
    "        centralities=CENTRALITIES,\n",
    "        composite_functions=['weight_composite_ranking',],\n",
    "        output_path=f'results/branch-update/balanced-importance/{network_name}'\n",
    "    )\n",
    "    network_results[network_name] = results\n",
    "\n",
    "# Before comparison\n",
    "if not network_results:\n",
    "    raise ValueError(\"No networks were successfully analyzed. Check if data/split directory contains valid network data.\")\n",
    "\n",
    "\n",
    "# Compare results across networks\n",
    "analysis = compare_networks(network_results, 'results/branch-update/balanced-importance/comparisons')\n",
    "\n",
    "# Visualize results\n",
    "visualize_network_commonalities(analysis, 'results/branch-update/balanced-importance/comparisons')\n",
    "\n",
    "\n",
    "\n",
    "# BALANCED BY DOCTYPEBRANCH\n",
    "network_results = {}\n",
    "networks = load_networks('networks/balanced-doctypebranch')\n",
    "\n",
    "# Analyze Networks\n",
    "for network_name, data in networks.items():\n",
    "    print(f\"\\nAnalyzing network: {network_name}\")\n",
    "    results = analyze_network(\n",
    "        nodes_df=data['nodes'],\n",
    "        edges_df=data['edges'],\n",
    "        ground_truths=GROUND_TRUTHS,\n",
    "        centralities=CENTRALITIES,\n",
    "        composite_functions=['weight_composite_ranking',],\n",
    "        output_path=f'results/balanced-doctypebranch/{network_name}'\n",
    "    )\n",
    "    network_results[network_name] = results\n",
    "\n",
    "# Before comparison\n",
    "if not network_results:\n",
    "    raise ValueError(\"No networks were successfully analyzed. Check if data/split directory contains valid network data.\")\n",
    "\n",
    "\n",
    "# Compare results across networks\n",
    "analysis = compare_networks(network_results, 'results/balanced-doctypebranch/comparisons')\n",
    "\n",
    "# Visualize results\n",
    "visualize_network_commonalities(analysis, 'results/balanced-doctypebranch/comparisons')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
