{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Centrality Metrics\n",
    "\n",
    "This notebook analyzes and compares different centrality metrics for a citation network.\n",
    "\n",
    "It loads node and edge data from JSON files, calculates various centrality metrics (like degree, betweenness, closeness etc.), and compares them against ground truth measures like importance and document type.\n",
    "\n",
    "The notebook defines constants for:\n",
    "- Input data file paths\n",
    "- Centrality metrics to analyze \n",
    "- Ground truth measures to compare against\n",
    "\n",
    "It also defines TypedDict classes to type the network statistics and results.\n",
    "\n",
    "**Note:** This is an analysis notebook. To modify the code that generates the network and calculates centralities, please refer to the Main section.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import statistics\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec \n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr\n",
    "import seaborn as sns\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List, TypedDict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkStats(TypedDict):\n",
    "    n_nodes: int\n",
    "    n_edges: int\n",
    "\n",
    "class BestCentralities(TypedDict):\n",
    "    high: str\n",
    "    low: str\n",
    "\n",
    "class AnalysisResults(TypedDict):\n",
    "    network_stats: NetworkStats\n",
    "    correlations: Dict[str, Dict[str, Dict[tuple[str, str], float]]]  # ground_truth -> composite_function -> (centrality, ground_truth) -> correlation\n",
    "    best_centralities: Dict[str, BestCentralities]  # ground_truth -> best centralities\n",
    "    composite_rankings: Dict[str, Dict[str, Dict[str, float]]]  # ground_truth -> composite_function -> ecli -> rank\n",
    "    dataframe: pd.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert doctypebranch to a numeric value\n",
    "def categorise_total_branch_numerically(branches: pd.Series) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Convert branch categorisation from strings into numbers.\n",
    "    \n",
    "    :param branches: The column containing branch data, categorized with strings.\n",
    "    :return: A pandas Series with numerical categorization.\n",
    "    \"\"\"\n",
    "    mapping = {\n",
    "        \"GRANDCHAMBER\": 1,\n",
    "        \"CHAMBER\": 2,\n",
    "        \"COMMITTEE\": 3,\n",
    "    }\n",
    "    \n",
    "    # Convert to uppercase to ensure consistent matching\n",
    "    branches = branches.str.upper()\n",
    "    \n",
    "    # Print any values that don't match our mapping\n",
    "    unmapped = set(branches.unique()) - set(mapping.keys())\n",
    "    if unmapped:\n",
    "        print(f\"Warning: Found unmapped values: {unmapped}\")\n",
    "    \n",
    "    return branches.map(mapping)\n",
    "\n",
    "def prep_data(df: pd.DataFrame, include: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prepare the dataset by selecting the appropriate columns and filtering out rows with uncomputed metric values.\n",
    "    \n",
    "    :param df: The DataFrame to process.\n",
    "    :param include: Columns to include.\n",
    "    :return: The processed DataFrame.\n",
    "    \"\"\"\n",
    "    headers = include + ['ecli']  # Ensure essential columns are included\n",
    "    headers = list(set(headers))  # Removing duplicates\n",
    "\n",
    "    data = df[headers]\n",
    "\n",
    "    # Filter out rows with uncomputed metric values (-2)\n",
    "    metric_column = include[-1]\n",
    "    data = data[data[metric_column] >= -1]\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centrality Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_disruptions_new(graph: nx.Graph) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate the disruption score for each node in the graph.\n",
    "\n",
    "    Args:\n",
    "        graph (nx.Graph): The input directed graph.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with nodes as keys and their disruption scores as values.\n",
    "    \"\"\"\n",
    "    disruptions = {}\n",
    "    for node in graph.nodes:\n",
    "        i, j, k = 0, 0, 0\n",
    "\n",
    "        # count j - papers that cite both the current paper and its references\n",
    "        for in_node in graph.predecessors(node):\n",
    "            for out_node in graph.successors(node):\n",
    "                if graph.has_edge(in_node, out_node):\n",
    "                    j += 1\n",
    "                    break\n",
    "\n",
    "        # count i - papers that only cite the current paper\n",
    "        i = graph.in_degree(node) - j\n",
    "\n",
    "        # count k - papers that only cite papers cited by the current paper\n",
    "        for out_node in graph.successors(node):\n",
    "            for in_out_node in graph.predecessors(out_node):\n",
    "                if in_out_node != node and not graph.has_edge(in_out_node, node):\n",
    "                    k += 1\n",
    "\n",
    "        # Calculate disruption index with better edge case handling\n",
    "        denominator = i + j + k\n",
    "        if denominator == 0:\n",
    "            # If paper has no citations and cites no one, assign neutral disruption\n",
    "            disruptions[node] = 0.0\n",
    "        else:\n",
    "            disruptions[node] = (i - j) / denominator\n",
    "\n",
    "    # Verify we have at least some non-zero values\n",
    "    values = list(disruptions.values())\n",
    "    if all(v == 0 for v in values):\n",
    "        print(\"Warning: All disruption values are 0\")\n",
    "    if len(set(values)) == 1:\n",
    "        print(f\"Warning: All disruption values are identical: {values[0]}\")\n",
    "\n",
    "    return disruptions\n",
    "\n",
    "\n",
    "# Function to calculate centrality measures\n",
    "def calculate_centrality_measures(graph):\n",
    "    \"\"\"\n",
    "    Calculate various centrality measures for the graph.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (measures dict, list of failed centrality names)\n",
    "    \"\"\"\n",
    "    measures = {\n",
    "        # Basic degree measures\n",
    "        'degree_centrality': nx.degree_centrality(graph),\n",
    "        'in_degree_centrality': nx.in_degree_centrality(graph),\n",
    "        'out_degree_centrality': nx.out_degree_centrality(graph),\n",
    "        'relative_in_degree_centrality': {node: degree/len(graph) \n",
    "                                        for node, degree in graph.in_degree()},\n",
    "        \n",
    "        # Core decomposition\n",
    "        'core_number': nx.core_number(graph),\n",
    "        \n",
    "        # Basic path-based measures\n",
    "        'betweenness_centrality': nx.betweenness_centrality(graph),\n",
    "        'closeness_centrality': nx.closeness_centrality(graph),\n",
    "        'harmonic_centrality': nx.harmonic_centrality(graph)\n",
    "    }\n",
    "    \n",
    "    failed_centralities = []\n",
    "    \n",
    "    # Flow-based measures - convert to undirected for these\n",
    "    try:\n",
    "        undirected_graph = graph.to_undirected()\n",
    "        measures['current_flow_betweenness'] = nx.current_flow_betweenness_centrality(undirected_graph)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate current_flow_betweenness: {str(e)}\")\n",
    "        measures['current_flow_betweenness'] = {node: 0.0 for node in graph.nodes()}\n",
    "        failed_centralities.append('current_flow_betweenness')\n",
    "    \n",
    "    try:\n",
    "        undirected_graph = graph.to_undirected()\n",
    "        measures['current_flow_closeness'] = nx.current_flow_closeness_centrality(undirected_graph)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate current_flow_closeness: {str(e)}\")\n",
    "        measures['current_flow_closeness'] = {node: 0.0 for node in graph.nodes()}\n",
    "        failed_centralities.append('current_flow_closeness')\n",
    "    \n",
    "    # Eigenvector-based measures\n",
    "    try:\n",
    "        measures['eigenvector_centrality'] = nx.eigenvector_centrality(\n",
    "            graph, \n",
    "            max_iter=1000,\n",
    "            tol=1e-6\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate eigenvector_centrality: {str(e)}\")\n",
    "        measures['eigenvector_centrality'] = {node: 0.0 for node in graph.nodes()}\n",
    "        failed_centralities.append('eigenvector_centrality')\n",
    "    \n",
    "    try:\n",
    "        measures['pagerank'] = nx.pagerank(\n",
    "            graph,\n",
    "            alpha=0.95,  # damping factor\n",
    "            tol=1e-9,\n",
    "            max_iter=10000  # significantly increased for better convergence\n",
    "        )\n",
    "    except nx.PowerIterationFailedConvergence as e:\n",
    "        print(f\"PageRank failed to converge with 10000 iterations, trying with more iterations...\")\n",
    "        try:\n",
    "            # Try again with even more iterations\n",
    "            measures['pagerank'] = nx.pagerank(\n",
    "                graph,\n",
    "                alpha=0.95,\n",
    "                tol=1e-9,\n",
    "                max_iter=100000\n",
    "            )\n",
    "        except Exception as e2:\n",
    "            print(f\"PageRank failed to converge even with 100000 iterations: {str(e2)}\")\n",
    "            measures['pagerank'] = {node: 0.0 for node in graph.nodes()}\n",
    "            failed_centralities.append('pagerank')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate pagerank: {str(e)}\")\n",
    "        measures['pagerank'] = {node: 0.0 for node in graph.nodes()}\n",
    "        failed_centralities.append('pagerank')\n",
    "    \n",
    "    # HITS-based measures\n",
    "    try:\n",
    "        hub_dict, authority_dict = nx.hits(\n",
    "            graph,\n",
    "            max_iter=100,\n",
    "            tol=1e-8\n",
    "        )\n",
    "        measures['hits_hub'] = hub_dict\n",
    "        measures['hits_authority'] = authority_dict\n",
    "        measures['hits_combined'] = {\n",
    "            node: hub_dict[node] + authority_dict[node] \n",
    "            for node in graph.nodes()\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate HITS measures: {str(e)}\")\n",
    "        measures['hits_hub'] = {node: 0.0 for node in graph.nodes()}\n",
    "        measures['hits_authority'] = {node: 0.0 for node in graph.nodes()}\n",
    "        measures['hits_combined'] = {node: 0.0 for node in graph.nodes()}\n",
    "        failed_centralities.extend(['hits_hub', 'hits_authority', 'hits_combined'])\n",
    "    \n",
    "    # Trophic level - only calculate if graph has proper structure\n",
    "    try:\n",
    "        # Check if graph has basal nodes and all nodes are reachable\n",
    "        basal_nodes = [n for n in graph.nodes() if graph.in_degree(n) == 0]\n",
    "        if basal_nodes:\n",
    "            measures['trophic_level'] = nx.trophic_levels(graph)\n",
    "        else:\n",
    "            raise ValueError(\"No basal nodes found in graph\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate trophic_level: {str(e)}\")\n",
    "        measures['trophic_level'] = {node: 0.0 for node in graph.nodes()}\n",
    "        failed_centralities.append('trophic_level')\n",
    "    \n",
    "    # Forest closeness - removed since it's not available in networkx\n",
    "    # If you need this measure, you'll need to implement it separately\n",
    "    \n",
    "    # Disruption index\n",
    "    try:\n",
    "        measures['disruption'] = calculate_disruptions_new(graph)\n",
    "        disruption_values = list(measures['disruption'].values())\n",
    "        if not all(-1 <= v <= 1 for v in disruption_values if not np.isnan(v)):\n",
    "            raise ValueError(\"Disruption values outside valid range [-1,1]\")\n",
    "        \n",
    "        non_nan_values = [v for v in disruption_values if not np.isnan(v)]\n",
    "        if len(non_nan_values) > 0 and all(v == non_nan_values[0] for v in non_nan_values):\n",
    "            raise ValueError(\"All disruption values are identical\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to calculate disruption: {str(e)}\")\n",
    "        measures['disruption'] = {node: 0.0 for node in graph.nodes()}\n",
    "        failed_centralities.append('disruption')\n",
    "    \n",
    "    return measures, failed_centralities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Composite Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script analyzes the relationship between various centrality measures and ground truth scores\n",
    "for legal cases. It aims to find the best centrality measures for predicting high and low relevance\n",
    "scores, create a composite ranking, and evaluate its performance against individual centrality measures.\n",
    "\n",
    "The main steps are:\n",
    "1. Plot error bars for centrality measures vs. ground truth scores\n",
    "2. Find the best centrality measures for predicting high and low scores\n",
    "3. Create a composite ranking using the best measures\n",
    "4. Calculate correlations between rankings and ground truth scores\n",
    "5. Visualize and save the results\n",
    "\"\"\"\n",
    "\n",
    "def plot_error_bars(df, centrality, ground_truth):\n",
    "    \"\"\"\n",
    "    Plot error bars for a given centrality measure against a ground truth score.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the data\n",
    "    centrality (str): The name of the centrality measure column\n",
    "    ground_truth (str): The name of the ground truth score column\n",
    "\n",
    "    This function visualizes the relationship between a centrality measure and a ground truth score,\n",
    "    showing the mean centrality value for each ground truth score category along with error bars\n",
    "    representing the standard deviation.\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    include = [ground_truth, centrality]\n",
    "    data = prep_data(df, include)\n",
    "\n",
    "    x_header = centrality\n",
    "    y_header = ground_truth\n",
    "    x, y = list(data[x_header]), list(data[y_header])\n",
    "    categories = list(set(y))\n",
    "    categories.sort()\n",
    "    num_categories, num_instances = len(categories), len(x)\n",
    "    y_instances = [[] for _ in range(num_categories)]\n",
    "    for category_no in range(num_categories):\n",
    "        for instance_no in range(num_instances):\n",
    "            if y[instance_no] == categories[category_no]:\n",
    "                y_instances[category_no].append(x[instance_no])\n",
    "    x = [statistics.mean(y_instances[category_no]) for category_no in range(num_categories)]\n",
    "    y = categories\n",
    "\n",
    "    # Draw graph\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    title = f\"{centrality.capitalize()} vs Average {y_header.capitalize()}\"\n",
    "    plt.suptitle(title, fontsize=22)\n",
    "    plt.xlabel(f\"{centrality.capitalize()}\", fontsize=22)\n",
    "    plt.ylabel(f\"{y_header.capitalize()}\", fontsize=22)\n",
    "    plt.yticks(categories, fontsize=16)\n",
    "\n",
    "    # Calculate error bars\n",
    "    stds = [statistics.stdev(y_instances[category_no]) for category_no in range(num_categories)]\n",
    "    plt.errorbar(x, y, xerr=stds, fmt='o')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def find_best_centralities(df, centralities, ground_truth):\n",
    "    \"\"\"\n",
    "    Find the best centrality measures for predicting high and low ground truth scores.\n",
    "\n",
    "    For court branch (doctypebranch) values:\n",
    "    - 1 = GRANDCHAMBER (highest/most important)\n",
    "    - 2 = CHAMBER\n",
    "    - 3 = COMMITTEE (lowest/least important)\n",
    "\n",
    "    For importance scores:\n",
    "    - 1 = Most important\n",
    "    - 2 = Important\n",
    "    - 3 = Less important\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the data\n",
    "    centralities (list): List of centrality measure column names\n",
    "    ground_truth (str): The name of the ground truth score column (either 'importance' or 'doctypebranch')\n",
    "\n",
    "    Returns:\n",
    "    tuple: (best_high, best_low) - the names of the best centrality measures for predicting:\n",
    "           - high scores (1 = highest importance/GRANDCHAMBER)\n",
    "           - low scores (3 = lowest importance/COMMITTEE)\n",
    "\n",
    "    This function calculates the Spearman correlation between each centrality measure and the ground truth,\n",
    "    using 1 - |correlation| as an error metric. The centrality with the lowest error is chosen as best_high,\n",
    "    and the second-lowest (excluding best_high) is chosen as best_low.\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO For COURTBRANCH: When selecting the optimal metric for the lower class (less importance) we weight it against the middle class.\n",
    "\n",
    "    errors = {}\n",
    "    \n",
    "    for centrality in centralities:\n",
    "        # Calculate correlation across the full range\n",
    "        corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
    "        errors[centrality] = 1 - abs(corr)  # Use 1 - |correlation| as error\n",
    "    \n",
    "    best_high = min(errors, key=errors.get)\n",
    "    \n",
    "    # Remove the best_high centrality from consideration for best_low\n",
    "    errors.pop(best_high, None)\n",
    "    \n",
    "    best_low = min(errors, key=errors.get)\n",
    "    \n",
    "    return best_high, best_low\n",
    "\n",
    "\n",
    "def find_best_centralities_updated(df, centralities, ground_truth):\n",
    "    \"\"\"\n",
    "    Find the best centrality measures for predicting high and low ground truth scores.\n",
    "\n",
    "    For court branch (doctypebranch) values:\n",
    "    - 1 = GRANDCHAMBER (highest/most important)\n",
    "    - 2 = CHAMBER (middle)\n",
    "    - 3 = COMMITTEE (lowest/least important)\n",
    "    For doctypebranch, we select centralities that best predict:\n",
    "    - GRANDCHAMBER (1) for high scores\n",
    "    - CHAMBER (2) for low scores\n",
    "\n",
    "    For importance scores:\n",
    "    - 1 = Most important\n",
    "    - 2 = Important \n",
    "    - 3 = Less important\n",
    "    For importance, we select centralities that best predict:\n",
    "    - Most important (1) for high scores\n",
    "    - Less important (3) for low scores\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the data\n",
    "    centralities (list): List of centrality measure column names\n",
    "    ground_truth (str): The name of the ground truth score column (either 'importance' or 'doctypebranch')\n",
    "\n",
    "    Returns:\n",
    "    tuple: (best_high, best_low) - the names of the best centrality measures for predicting:\n",
    "           - high scores (1 = highest importance/GRANDCHAMBER)\n",
    "           - low scores (2 = CHAMBER for doctypebranch, 3 = lowest for importance)\n",
    "    \"\"\"\n",
    "    errors = {}\n",
    "    \n",
    "    if ground_truth == 'doctypebranch':\n",
    "        # For doctypebranch, calculate correlations focusing on GRANDCHAMBER (1) vs CHAMBER (2)\n",
    "        for centrality in centralities:\n",
    "            # Filter for just GRANDCHAMBER and CHAMBER cases\n",
    "            mask = df[ground_truth].isin([1, 2])\n",
    "            corr, _ = stats.spearmanr(df[centrality][mask], df[ground_truth][mask])\n",
    "            errors[centrality] = 1 - abs(corr)\n",
    "    else:\n",
    "        # For other ground truths (importance), use full range\n",
    "        for centrality in centralities:\n",
    "            corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
    "            errors[centrality] = 1 - abs(corr)\n",
    "    \n",
    "    best_high = min(errors, key=errors.get)\n",
    "    \n",
    "    # Remove the best_high centrality from consideration for best_low\n",
    "    errors.pop(best_high, None)\n",
    "    \n",
    "    best_low = min(errors, key=errors.get)\n",
    "    \n",
    "    return best_high, best_low\n",
    "\n",
    "def rank_cases(values):\n",
    "    \"\"\"\n",
    "    Normalize centrality values while preserving relative differences.\n",
    "    Uses percentile ranking for non-zero values scaled to [1, 1000].\n",
    "    Values are inverted so that lower numbers indicate higher importance,\n",
    "    matching the ground truth direction where 0 is most important.\n",
    "    \"\"\"\n",
    "    non_zero = values[values != 0]\n",
    "    if len(non_zero) == 0:\n",
    "        return values\n",
    "    \n",
    "    # Create percentile ranks for non-zero values (0-1 scale)\n",
    "    # Use ascending=False to invert the direction\n",
    "    ranks = pd.Series(index=non_zero.index)\n",
    "    ranks.loc[non_zero.index] = non_zero.rank(pct=True, ascending=False)\n",
    "    \n",
    "    # Scale to 1-1000 range\n",
    "    ranks = ranks * 999 + 1\n",
    "    \n",
    "    # Fill zeros\n",
    "    ranks = ranks.reindex(values.index, fill_value=1000)  # Zeros get lowest importance\n",
    "    return ranks\n",
    "\n",
    "def normalize_centrality(values):\n",
    "    \"\"\"\n",
    "    Normalize centrality values while preserving relative differences.\n",
    "    Uses percentile ranking for non-zero values scaled to [1, 1000].\n",
    "    Values are inverted so that lower numbers indicate higher importance,\n",
    "    matching the ground truth direction where 0 is most important.\n",
    "    \"\"\"\n",
    "    non_zero = values[values != 0]\n",
    "    if len(non_zero) == 0:\n",
    "        return values\n",
    "    \n",
    "    # Create percentile ranks for non-zero values (0-1 scale)\n",
    "    # Use ascending=False to invert the direction\n",
    "    ranks = pd.Series(index=non_zero.index)\n",
    "    ranks.loc[non_zero.index] = non_zero.rank(pct=True, ascending=False)\n",
    "    \n",
    "    # Scale to 1-1000 range\n",
    "    ranks = ranks * 999 + 1\n",
    "    \n",
    "    # Fill zeros\n",
    "    ranks = ranks.reindex(values.index, fill_value=1000)  # Zeros get lowest importance\n",
    "    return ranks\n",
    "\n",
    "def weighted_combine(high, low, weight):\n",
    "    \"\"\"\n",
    "    Combine normalized values using weighted geometric mean.\n",
    "    Higher values indicate higher importance.\n",
    "    \"\"\"\n",
    "    # Add small epsilon to avoid zero values in geometric mean\n",
    "    epsilon = 1e-10\n",
    "    return np.power(high + epsilon, weight) * np.power(low + epsilon, (1-weight))\n",
    "\n",
    "def threshold_combine(high, low, threshold_pct):\n",
    "    \"\"\"\n",
    "    Combine using threshold on non-zero values.\n",
    "    Uses high values above threshold, low values otherwise.\n",
    "    Higher values indicate higher importance.\n",
    "    \"\"\"\n",
    "    if len(high[high != 0]) == 0:\n",
    "        return low\n",
    "    \n",
    "    # Get threshold value\n",
    "    threshold = np.percentile(high[high != 0], 100 - threshold_pct)  # Invert percentile to get top values\n",
    "    \n",
    "    # Create composite where high values above threshold get full weight\n",
    "    result = high.copy()\n",
    "    mask = high <= threshold\n",
    "    result[mask] = low[mask]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_weighted_composite_ranking(df, high_centrality, low_centrality, ground_truth):\n",
    "    \"\"\"\n",
    "    Create composite using weighted combination of normalized centrality values.\n",
    "    Preserves minimal differences through percentile-based normalization.\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    assert high_centrality in df.columns, f\"High centrality '{high_centrality}' not found in DataFrame\"\n",
    "    assert low_centrality in df.columns, f\"Low centrality '{low_centrality}' not found in DataFrame\"\n",
    "    \n",
    "    # Get raw centrality values\n",
    "    high_values = df[high_centrality]\n",
    "    low_values = df[low_centrality]\n",
    "    \n",
    "    high_norm = normalize_centrality(high_values)\n",
    "    low_norm = normalize_centrality(low_values)\n",
    "    \n",
    "    print(\"\\nDebug values:\")\n",
    "    print(f\"Original high centrality range: [{high_values.min()}, {high_values.max()}]\")\n",
    "    print(f\"Original low centrality range: [{low_values.min()}, {low_values.max()}]\")\n",
    "    print(f\"Normalized high centrality range: [{high_norm.min()}, {high_norm.max()}]\")\n",
    "    print(f\"Normalized low centrality range: [{low_norm.min()}, {low_norm.max()}]\")\n",
    "    \n",
    "    # Initialize best results\n",
    "    best_weight = None\n",
    "    best_corr = float('-inf')\n",
    "    best_composite = None\n",
    "    \n",
    "    # Try different weights\n",
    "    for weight in np.arange(0.01, 1.00, 0.01):\n",
    "        composite = weighted_combine(high_norm, low_norm, weight)\n",
    "        \n",
    "        # Calculate correlation with ground truth\n",
    "        corr = spearmanr(composite, df[ground_truth])[0]\n",
    "        \n",
    "        if corr > best_corr:\n",
    "            best_corr = corr\n",
    "            best_weight = weight\n",
    "            best_composite = composite\n",
    "    \n",
    "    print(\"\\nBest results:\")\n",
    "    print(f\"Best weight: {best_weight}\")\n",
    "    print(f\"Best correlation: {best_corr}\")\n",
    "    print(f\"Composite range: [{best_composite.min()}, {best_composite.max()}]\")\n",
    "    \n",
    "    # Assert that the composite has variation and correlates with ground truth\n",
    "    assert best_composite.nunique() > 1, \"Composite has no variation\"\n",
    "    assert not np.isnan(best_corr), \"Correlation is NaN\"\n",
    "    \n",
    "    return best_composite, best_weight\n",
    "\n",
    "def create_threshold_composite_ranking(df, high_centrality, low_centrality, ground_truth):\n",
    "    \"\"\"\n",
    "    Create composite using threshold on normalized centrality values.\n",
    "    Uses percentile-based normalization and threshold selection.\n",
    "    \"\"\"\n",
    "    # Input validation\n",
    "    assert high_centrality in df.columns, f\"High centrality '{high_centrality}' not found in DataFrame\"\n",
    "    assert low_centrality in df.columns, f\"Low centrality '{low_centrality}' not found in DataFrame\"\n",
    "    \n",
    "    # Get raw centrality values\n",
    "    high_values = df[high_centrality]\n",
    "    low_values = df[low_centrality]\n",
    "    \n",
    "    high_norm = normalize_centrality(high_values)\n",
    "    low_norm = normalize_centrality(low_values)\n",
    "    \n",
    "    print(\"\\nDebug values:\")\n",
    "    print(f\"Original high centrality range: [{high_values.min()}, {high_values.max()}]\")\n",
    "    print(f\"Original low centrality range: [{low_values.min()}, {low_values.max()}]\")\n",
    "    print(f\"Normalized high centrality range: [{high_norm.min()}, {high_norm.max()}]\")\n",
    "    print(f\"Normalized low centrality range: [{low_norm.min()}, {low_norm.max()}]\")\n",
    "    \n",
    "    # Initialize best results\n",
    "    best_threshold = None\n",
    "    best_corr = float('-inf')\n",
    "    best_composite = None\n",
    "    \n",
    "    # Try different thresholds\n",
    "    for threshold_pct in range(1, 100):\n",
    "        composite = threshold_combine(high_norm, low_norm, threshold_pct)\n",
    "        \n",
    "        # Calculate correlation with ground truth\n",
    "        corr = spearmanr(composite, df[ground_truth])[0]\n",
    "        \n",
    "        if corr > best_corr:\n",
    "            best_corr = corr\n",
    "            best_threshold = threshold_pct\n",
    "            best_composite = pd.Series(composite)\n",
    "    \n",
    "    print(\"\\nBest results:\")\n",
    "    print(f\"Best threshold percentile: {best_threshold}\")\n",
    "    print(f\"Best correlation: {best_corr}\")\n",
    "    print(f\"Composite range: [{best_composite.min()}, {best_composite.max()}]\")\n",
    "    \n",
    "    # Assert that the composite has variation and correlates with ground truth\n",
    "    assert best_composite.nunique() > 1, \"Composite has no variation\"\n",
    "    assert not np.isnan(best_corr), \"Correlation is NaN\"\n",
    "    \n",
    "    return best_composite, best_threshold\n",
    "\n",
    "\n",
    "def calculate_correlations(df, centralities, ground_truths, composite_functions=None):\n",
    "    \"\"\"\n",
    "    Calculate correlations between rankings and ground truth scores.\n",
    "\n",
    "    Args:\n",
    "    df (pd.DataFrame): The dataframe containing the data\n",
    "    centralities (list): List of centrality measure column names\n",
    "    ground_truths (list): List of ground truth score column names\n",
    "    composite_functions (list): List of composite function types ('weight_composite_ranking', 'threshold_composite_ranking')\n",
    "    \"\"\"\n",
    "    correlations = {}\n",
    "    \n",
    "    # Calculate correlations for centrality measures\n",
    "    for centrality in centralities:\n",
    "        centrality_ranking = rank_cases(df[centrality])\n",
    "        for ground_truth in ground_truths:\n",
    "            if df[centrality].nunique() > 1 and df[ground_truth].nunique() > 1:\n",
    "                corr, _ = stats.spearmanr(centrality_ranking, df[ground_truth])\n",
    "                correlations[(centrality, ground_truth)] = corr\n",
    "            else:\n",
    "                correlations[(centrality, ground_truth)] = np.nan\n",
    "    \n",
    "    # Calculate correlations for all composite rankings\n",
    "    if composite_functions:\n",
    "        # Get all composite ranking columns that exist in the dataframe\n",
    "        composite_cols = [col for col in df.columns \n",
    "                        if col.startswith('composite_ranking_') and \n",
    "                        any(f in col for f in composite_functions)]\n",
    "        \n",
    "        print(f\"Found composite columns: {composite_cols}\")  # Debug print\n",
    "        \n",
    "        # Calculate correlations for each composite ranking with each ground truth\n",
    "        for composite_col in composite_cols:\n",
    "            for ground_truth in ground_truths:\n",
    "                if df[composite_col].nunique() > 1 and df[ground_truth].nunique() > 1:\n",
    "                    corr, _ = stats.spearmanr(df[composite_col], df[ground_truth])\n",
    "                    correlations[(composite_col, ground_truth)] = corr\n",
    "                    print(f\"Correlation between {composite_col} and {ground_truth}: {corr}\")  # Debug print\n",
    "                else:\n",
    "                    correlations[(composite_col, ground_truth)] = np.nan\n",
    "    \n",
    "    print(\"Generated correlations: \", correlations.keys())\n",
    "    # Assert that correlations between composite functions are different\n",
    "    if composite_functions and len(composite_functions) >= 2:\n",
    "        # Get correlations for each composite function type\n",
    "        composite_corrs = {f: [] for f in composite_functions}\n",
    "        for (metric, gt), corr in correlations.items():\n",
    "            for f in composite_functions:\n",
    "                if f in metric:\n",
    "                    composite_corrs[f].append(corr)\n",
    "        \n",
    "        # Compare correlations between different composite functions\n",
    "        for i, f1 in enumerate(composite_functions[:-1]):\n",
    "            for f2 in composite_functions[i+1:]:\n",
    "                if composite_corrs[f1] and composite_corrs[f2]:  # Check if lists are non-empty\n",
    "                    # assert not np.allclose(composite_corrs[f1], composite_corrs[f2], rtol=1e-5), f\"Correlations for {f1} and {f2} are too similar - they should produce different results\"\n",
    "                    print(f\"WARNING: Correlations for {f1} and {f2} are too similar - they should produce different results\")\n",
    "    return correlations\n",
    "\n",
    "def calculate_centrality_correlations(df, centralities, ground_truths):\n",
    "    \"\"\"\n",
    "    Calculate correlations between rankings and ground truth scores.\n",
    "    \"\"\"\n",
    "    correlations = {}\n",
    "    for centrality in centralities:\n",
    "        for ground_truth in ground_truths:\n",
    "            # Check if arrays have variation before calculating correlation\n",
    "            if df[centrality].nunique() > 1 and df[ground_truth].nunique() > 1:\n",
    "                corr, _ = stats.spearmanr(df[centrality], df[ground_truth])\n",
    "                correlations[(centrality, ground_truth)] = corr\n",
    "            else:\n",
    "                correlations[(centrality, ground_truth)] = np.nan\n",
    "    return correlations\n",
    "\n",
    "# Generate distinct colors with better visibility\n",
    "def generate_distinct_colors(n):\n",
    "    \"\"\"Generate n distinct colors with good visibility\"\"\"\n",
    "    # Use both Pastel1 and Pastel2 as base, but increase saturation and decrease brightness\n",
    "    colors1 = plt.cm.Pastel1(np.linspace(0, 1, 9))  # Pastel1 has 9 colors\n",
    "    colors2 = plt.cm.Pastel2(np.linspace(0, 1, 8))  # Pastel2 has 8 colors\n",
    "    \n",
    "    # Combine and adjust colors\n",
    "    base_colors = np.vstack((colors1, colors2))\n",
    "    \n",
    "    # Make colors more vibrant by adjusting saturation and brightness\n",
    "    import colorsys\n",
    "    adjusted_colors = []\n",
    "    for color in base_colors:\n",
    "        # Convert RGB to HSV\n",
    "        h, s, v = colorsys.rgb_to_hsv(color[0], color[1], color[2])\n",
    "        # Increase saturation by 20% and decrease brightness by 10%\n",
    "        s = min(1.0, s * 1.2)  # Increase saturation\n",
    "        v = max(0.0, v * 0.9)  # Decrease brightness slightly\n",
    "        # Convert back to RGB\n",
    "        r, g, b = colorsys.hsv_to_rgb(h, s, v)\n",
    "        adjusted_colors.append([r, g, b, color[3]])  # Keep original alpha\n",
    "        \n",
    "    # If we need more colors, create variations\n",
    "    while len(adjusted_colors) < n:\n",
    "        idx = len(adjusted_colors) % len(base_colors)\n",
    "        base_color = adjusted_colors[idx]\n",
    "        h, s, v = colorsys.rgb_to_hsv(base_color[0], base_color[1], base_color[2])\n",
    "        # Create variation by rotating hue\n",
    "        h = (h + 0.1) % 1.0\n",
    "        r, g, b = colorsys.hsv_to_rgb(h, s, v)\n",
    "        adjusted_colors.append([r, g, b, base_color[3]])\n",
    "        \n",
    "    return np.array(adjusted_colors[:n])\n",
    "\n",
    "def plot_correlations(correlations, output_file, analysis):\n",
    "    \"\"\"\n",
    "    Plot correlations between rankings and ground truth scores with optimization info below.\n",
    "    \n",
    "    Args:\n",
    "        correlations (dict): Dictionary of (measure, ground_truth) -> correlation value\n",
    "        output_file (str): Path to save the plot\n",
    "        analysis (dict): Dictionary containing best centralities and parameters for each ground truth\n",
    "    \"\"\"\n",
    "    print(\"Plotting for correlations: \", correlations.keys())\n",
    "    \n",
    "    # Get all measures and split them\n",
    "    all_measures = list(set([k[0] for k in correlations.keys()]))\n",
    "    regular_measures = [m for m in all_measures if 'composite' not in m]\n",
    "    composite_measures = [m for m in all_measures if 'composite' in m]\n",
    "    ordered_measures = regular_measures + composite_measures\n",
    "    \n",
    "    ground_truths = list(set([k[1] for k in correlations.keys()]))\n",
    "    \n",
    "    # Generate colors\n",
    "    pastel_colors = generate_distinct_colors(len(regular_measures))\n",
    "    composite_colors = plt.cm.Paired(np.linspace(0, 1, len(composite_measures)))\n",
    "    \n",
    "    # Create color mapping and labels\n",
    "    color_map = {measure: pastel_colors[i] for i, measure in enumerate(regular_measures)}\n",
    "    composite_labels = {}\n",
    "    for measure in composite_measures:\n",
    "        ground_truth = next(gt for gt in ground_truths if gt in measure)\n",
    "        method = 'Weight' if 'weight' in measure else 'Threshold'\n",
    "        param = analysis[ground_truth][method.lower()]\n",
    "        param_str = f\"{param:.2f}\" if isinstance(param, float) else str(param)\n",
    "        label = f\"{method} composite, opt. for {ground_truth} ({param_str})\"\n",
    "        composite_labels[measure] = label\n",
    "    \n",
    "    color_map.update({measure: composite_colors[i] for i, measure in enumerate(composite_measures)})\n",
    "    \n",
    "    # Create figure with better proportions\n",
    "    fig = plt.figure(figsize=(12, 8))  # Reduced overall size\n",
    "    \n",
    "    # Create grid with better proportions\n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[5, 1], figure=fig)\n",
    "    \n",
    "    # Create main plot area that will include the legend\n",
    "    ax = fig.add_subplot(gs[0])\n",
    "    # Info box area\n",
    "    info_ax = fig.add_subplot(gs[1])\n",
    "    \n",
    "    # Turn off axes for info area\n",
    "    info_ax.axis('off')\n",
    "    \n",
    "    # Plot bars\n",
    "    x = np.arange(len(ground_truths))\n",
    "    width = 0.8 / len(all_measures)\n",
    "    \n",
    "    for i, measure in enumerate(ordered_measures):\n",
    "        offset = width * i - 0.4 + width/2\n",
    "        label = composite_labels.get(measure, measure)\n",
    "        rects = ax.bar(x + offset, \n",
    "                      [correlations[(measure, gt)] for gt in ground_truths], \n",
    "                      width, \n",
    "                      label=label,\n",
    "                      color=color_map[measure])\n",
    "    \n",
    "    # Main plot formatting\n",
    "    ax.set_ylabel('Correlation Coefficient')\n",
    "    ax.set_title('Correlations between Rankings and Ground Truths')\n",
    "    ax.set_xticks(x, ground_truths)\n",
    "    \n",
    "    # Create main legend with better positioning\n",
    "    main_legend = ax.legend(\n",
    "        bbox_to_anchor=(1.01, 1),\n",
    "        loc='upper left',\n",
    "        borderaxespad=0,\n",
    "        frameon=True\n",
    "    )\n",
    "    \n",
    "    # Create optimization info text more compactly\n",
    "    opt_info = []\n",
    "    for gt in ground_truths:\n",
    "        gt_correlations = {k[0]: v for k, v in correlations.items() if k[1] == gt}\n",
    "        best_measure = max(gt_correlations.items(), key=lambda x: x[1])[0]\n",
    "        best_corr = gt_correlations[best_measure]\n",
    "        best_low = analysis[gt]['best_centralities']['low']\n",
    "        best_high = analysis[gt]['best_centralities']['high']\n",
    "        \n",
    "        opt_info.append(\n",
    "            f\"When opt. for {gt}: {best_low} (low) + {best_high} (high) | \"\n",
    "            f\"Highest corr. to {gt}: {best_measure} ({best_corr:.3f})\"\n",
    "        )\n",
    "    \n",
    "    # Add optimization info with better positioning\n",
    "    info_text = '\\n'.join(opt_info)\n",
    "    info_ax.text(\n",
    "        0.5, 0.5,\n",
    "        info_text,\n",
    "        ha='center',\n",
    "        va='center',\n",
    "        bbox=dict(facecolor='white', edgecolor='gray', alpha=0.8),\n",
    "        transform=info_ax.transAxes\n",
    "    )\n",
    "    \n",
    "    # Adjust layout with specific spacing\n",
    "    plt.subplots_adjust(\n",
    "        right=0.85,  # Make room for legend\n",
    "        bottom=0.2,  # Make room for info box\n",
    "        hspace=0.1   # Reduce space between plot and info box\n",
    "    )\n",
    "    \n",
    "    # Save figure with tight bbox but specific padding\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight', pad_inches=0.1)\n",
    "    plt.close()\n",
    "\n",
    "def plot_centrality_vs_ground_truth(df, centrality, ground_truth, output_path):\n",
    "    \"\"\"\n",
    "    Plot centrality measure against ground truth metrics with error bars.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the data\n",
    "        centrality (str): Name of the centrality measure to plot\n",
    "        ground_truths (list): List of ground truth measures to compare against\n",
    "        output_path (str): Path to save the output plots\n",
    "    \"\"\"\n",
    "    # Prepare data\n",
    "    data = df[[ground_truth, centrality]].copy()\n",
    "    data = data[data[centrality] != -2]  # Remove uncomputed values\n",
    "    \n",
    "    # Group by ground truth value and calculate statistics\n",
    "    grouped_stats = data.groupby(ground_truth)[centrality].agg(['mean', 'std']).reset_index()\n",
    "    \n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot points and error bars\n",
    "    plt.errorbar(grouped_stats['mean'], \n",
    "                grouped_stats[ground_truth],\n",
    "                xerr=grouped_stats['std'],\n",
    "                fmt='o',  # Changed from 'o-' to 'o' to remove connecting line\n",
    "                capsize=5,\n",
    "                capthick=1,\n",
    "                elinewidth=1,\n",
    "                markersize=8)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title(f'{centrality} vs. Average {ground_truth}', fontsize=16)\n",
    "    plt.xlabel(centrality.replace('_', ' ').title(), fontsize=16)\n",
    "    plt.ylabel(ground_truth.replace('_', ' ').title(), fontsize=16)\n",
    "    plt.yticks(grouped_stats[ground_truth], fontsize=16)\n",
    "    \n",
    "    # Add grid\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/{centrality}_{ground_truth}_error_bars.png', \n",
    "                bbox_inches='tight', \n",
    "                dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "def save_correlations_to_csv(correlations, output_file):\n",
    "    \"\"\"\n",
    "    Save correlation results to a CSV file.\n",
    "\n",
    "    Args:\n",
    "    correlations (dict): Dictionary of correlation coefficients\n",
    "    ground_truth (str): The name of the current ground truth score\n",
    "    output_file (str): The name of the output CSV file\n",
    "    best_high (str): The name of the best centrality for high scores\n",
    "    best_low (str): The name of the best centrality for low scores\n",
    "\n",
    "    This function saves the correlation results to a CSV file for further analysis or reporting.\n",
    "    \"\"\"\n",
    "    df_correlations = pd.DataFrame(correlations.items(), columns=['Pair', 'Correlation'])\n",
    "    df_correlations[['Centrality', 'Ground Truth']] = pd.DataFrame(df_correlations['Pair'].tolist(), index=df_correlations.index)\n",
    "    df_correlations = df_correlations.drop('Pair', axis=1)\n",
    "    df_correlations.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Network Function\n",
    "> The `analyze_network()` function performs comprehensive network analysis using various centrality measures and composite rankings.\n",
    "\n",
    "## Input Parameters\n",
    "\n",
    "- `nodes_df`: Pandas DataFrame containing node information, including ground truth scores and node attributes\n",
    "- `edges_df`: Pandas DataFrame containing edge information (connections between nodes)  \n",
    "- `ground_truths`: List of column names in nodes_df that contain ground truth scores to analyze\n",
    "- `centralities`: List of centrality measures to calculate (e.g. degree, betweenness, etc.)\n",
    "- `composite_functions`: List of functions that combine multiple centrality measures into composite rankings\n",
    "- `output_path`: Directory path where analysis outputs will be saved\n",
    "\n",
    "## Processing Steps\n",
    "\n",
    "1. Creates output directory if it doesn't exist\n",
    "2. Makes a copy of the input nodes DataFrame\n",
    "3. For each ground truth measure:\n",
    "   - Calculates an inverted version (max value - original value)\n",
    "   - Stores inverted versions with \"_inverted\" suffix\n",
    "4. Cleans data by:\n",
    "   - Dropping rows with missing ECLI identifiers\n",
    "   - Converting doctypebranch to numeric values if present\n",
    "5. Calculates centrality measures specified\n",
    "6. Creates composite rankings using provided functions\n",
    "7. Computes correlations between:\n",
    "   - Individual centrality measures and ground truths\n",
    "   - Composite rankings and ground truths\n",
    "\n",
    "## Return Value\n",
    "\n",
    "Returns an `AnalysisResults` dictionary containing:\n",
    "- `network_stats`: Basic statistics about the network (nodes, edges, density etc.)\n",
    "- `correlations`: Correlation coefficients between rankings and ground truths\n",
    "- `best_centralities`: Best performing centrality measures for each ground truth\n",
    "- `composite_rankings`: Results of composite ranking calculations\n",
    "- `dataframe`: Final processed DataFrame with all measures included\n",
    "\n",
    "## Output Files\n",
    "\n",
    "Saves various analysis results to the specified output directory, including:\n",
    "- Correlation plots\n",
    "- CSV files with detailed results\n",
    "- Network statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_network(nodes_df: pd.DataFrame, \n",
    "                   edges_df: pd.DataFrame, \n",
    "                   ground_truths: List[str],\n",
    "                   centralities: List[str],\n",
    "                   composite_functions: List[str],\n",
    "                   output_path: str,\n",
    "                   network_name: str = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Analyze network using various centrality measures and composite rankings.\n",
    "    \n",
    "    Args:\n",
    "        nodes_df: DataFrame containing node information\n",
    "        edges_df: DataFrame containing edge information\n",
    "        ground_truths: List of ground truth scores to analyze\n",
    "        centralities: List of centrality measures to calculate\n",
    "        composite_functions: List of functions for composite rankings\n",
    "        output_path: Directory path for saving outputs\n",
    "        network_name: Name of the network being analyzed (for tracking performance)\n",
    "    \n",
    "    Returns:\n",
    "        Dict containing analysis results\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "    # Make a copy of nodes dataframe\n",
    "    total_df = nodes_df.copy()\n",
    "\n",
    "    # Convert doctypebranch to numeric if it exists\n",
    "    if 'doctypebranch' in total_df.columns:\n",
    "        total_df['doctypebranch'] = categorise_total_branch_numerically(total_df['doctypebranch'])\n",
    "        # Remove rows with Nan doctypebranch\n",
    "        total_df = total_df.dropna(subset=['doctypebranch'])\n",
    "\n",
    "    # Convert ground truth columns to numeric\n",
    "    for truth in ground_truths:\n",
    "        total_df[truth] = pd.to_numeric(total_df[truth], errors='coerce')\n",
    "    \n",
    "    # Invert ground truth values\n",
    "    ground_truths_inverted = []\n",
    "    for truth in ground_truths:\n",
    "        max_value = total_df[truth].max()\n",
    "        inverted_col = f'{truth}_inverted'\n",
    "        total_df[inverted_col] = max_value - total_df[truth]\n",
    "        ground_truths_inverted.append(inverted_col)\n",
    "    \n",
    "    # Drop rows with missing ecli\n",
    "    total_df = total_df.dropna(subset=['ecli'])\n",
    "    \n",
    "    # Create graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes with attributes\n",
    "    for idx, row in total_df.iterrows():\n",
    "        node_attrs = {truth: row[truth] for truth in ground_truths if truth in row}\n",
    "        G.add_node(row['ecli'], **node_attrs)\n",
    "    \n",
    "    # Add edges between existing nodes\n",
    "    valid_nodes = set(total_df['ecli'].values)\n",
    "    for idx, row in edges_df.iterrows():\n",
    "        source = row['ecli']\n",
    "        targets = row['references']\n",
    "        if source in valid_nodes:\n",
    "            for target in targets:\n",
    "                if target and target in valid_nodes:\n",
    "                    G.add_edge(source, target)\n",
    "    \n",
    "    # Remove self-loops\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "    # Calculate network statistics\n",
    "    network_stats = {\n",
    "        'num_nodes': len(nodes_df),\n",
    "        'num_edges': len(edges_df),\n",
    "        'density': nx.density(G),\n",
    "        'average_degree': sum(dict(G.degree()).values()) / G.number_of_nodes(),\n",
    "    }\n",
    "    \n",
    "    # Initialize analysis dictionary\n",
    "    analysis = {\n",
    "        gt: {\n",
    "            'centrality_counts': {\n",
    "                'high': defaultdict(int),\n",
    "                'low': defaultdict(int),\n",
    "                'best_overall': defaultdict(int)\n",
    "            },\n",
    "            'combination_counts': defaultdict(int),\n",
    "            'composite_performance': {\n",
    "                'outperformed_count': 0,\n",
    "                'best_combinations': []\n",
    "            },\n",
    "            'network_performance': {},  # Track performance by network\n",
    "            'correlations': defaultdict(dict),  # Store all correlations\n",
    "            'optimal_weights': defaultdict(float),  # Store optimal weights\n",
    "            'class_distribution': {},  # Store class distribution\n",
    "            'composite_rankings': {},  # Store composite rankings\n",
    "            'best_centralities': {}  # Store best centralities\n",
    "        } for gt in ground_truths\n",
    "    }\n",
    "    \n",
    "    # Calculate centrality measures\n",
    "    centrality_measures, failed_centralities = calculate_centrality_measures(G)\n",
    "    centrality_df = pd.DataFrame(centrality_measures)\n",
    "    \n",
    "    # Merge centrality measures with total_df\n",
    "    total_df = pd.merge(total_df, centrality_df, left_on='ecli', right_index=True, how='left')\n",
    "    \n",
    "    # Plot initial correlations\n",
    "    numeric_cols = total_df.select_dtypes(include=[float, int]).columns\n",
    "\n",
    "    # FIND BEST CENTRALITIES\n",
    "    for ground_truth in ground_truths:\n",
    "        print(f\"\\nAnalyzing ground truth: {ground_truth}\")\n",
    "\n",
    "        for centrality in centralities:\n",
    "            if centrality in numeric_cols:\n",
    "                plot_centrality_vs_ground_truth(total_df, centrality, ground_truth, output_path)\n",
    "        print(f\"Plotted {len(centralities)} centrality vs ground truth plots\")\n",
    "        \n",
    "        # Calculate class distribution\n",
    "        class_distribution = nodes_df[ground_truth].value_counts().to_dict()\n",
    "        analysis[ground_truth]['class_distribution'] = class_distribution\n",
    "        \n",
    "        # Calculate correlations for all centrality measures\n",
    "        centrality_correlations = {}\n",
    "        for centrality in centralities:\n",
    "            corr, p_value = stats.spearmanr(total_df[centrality], total_df[ground_truth])\n",
    "            centrality_correlations[centrality] = abs(corr)\n",
    "            analysis[ground_truth]['correlations'][centrality] = {\n",
    "                'correlation': corr,\n",
    "                'p_value': p_value,\n",
    "                'abs_correlation': abs(corr)\n",
    "            }\n",
    "        \n",
    "        # Find best centralities\n",
    "        best_high = max(centrality_correlations.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        # Remove best_high from consideration for best_low\n",
    "        low_correlations = {k: v for k, v in centrality_correlations.items() if k != best_high}\n",
    "        best_low = max(low_correlations.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        # Find best overall centrality\n",
    "        best_centrality = max(centrality_correlations.items(), key=lambda x: x[1])[0]\n",
    "        \n",
    "        # Store best centralities\n",
    "        analysis[ground_truth]['best_centralities'] = {\n",
    "            'high': best_high,\n",
    "            'low': best_low,\n",
    "            'overall': best_centrality\n",
    "        }\n",
    "        \n",
    "        print(f\"Best high correlation: {best_high}\")\n",
    "        print(f\"Best low correlation: {best_low}\")\n",
    "        \n",
    "        # Update centrality counts\n",
    "        analysis[ground_truth]['centrality_counts']['high'][best_high] += 1\n",
    "        analysis[ground_truth]['centrality_counts']['low'][best_low] += 1\n",
    "        analysis[ground_truth]['centrality_counts']['best_overall'][best_centrality] += 1\n",
    "        \n",
    "        # Record network-specific performance if network_name is provided\n",
    "        if network_name:\n",
    "            analysis[ground_truth]['network_performance'][network_name] = {\n",
    "                'high': best_high,\n",
    "                'low': best_low,\n",
    "                'best_overall': best_centrality,\n",
    "                'correlations': centrality_correlations.copy()\n",
    "            }\n",
    "\n",
    "    # FIND BEST COMPOSITE RANKINGS\n",
    "    # Create composite rankings for EACH ground truth first\n",
    "\n",
    "    for ground_truth in ground_truths:\n",
    "        best_high, best_low = find_best_centralities_updated(total_df, centralities, ground_truth)\n",
    "        print(f'best_high and best_low for {ground_truth}')\n",
    "        print(total_df[[best_high, best_low]].describe())\n",
    "        \n",
    "        # Debug print before creating any rankings\n",
    "        print(f\"\\nBefore creating rankings for {ground_truth}:\")\n",
    "        for col in total_df.columns:\n",
    "            if 'composite_ranking' in col:\n",
    "                print(f\"Column {col} exists with first value: {total_df[col].iloc[0]}\")\n",
    "\n",
    "        \n",
    "        for composite_function in composite_functions:\n",
    "            if composite_function == 'weight_composite_ranking':\n",
    "                composite_ranking, optimal_weight = create_weighted_composite_ranking(total_df, best_high, best_low, ground_truth)\n",
    "                analysis[ground_truth]['weight'] = optimal_weight\n",
    "                ranking_col = f'composite_ranking_{ground_truth}_weight_composite_ranking'\n",
    "                \n",
    "                # Debug print the actual values\n",
    "                print(f\"\\nCreated {ranking_col}\")\n",
    "                print(\"Composite ranking statistics:\")\n",
    "                print(composite_ranking.describe())\n",
    "                total_df[ranking_col] = composite_ranking\n",
    "                print(\"Values in DataFrame:\", total_df[ranking_col].head())\n",
    "                \n",
    "            elif composite_function == 'threshold_composite_ranking':\n",
    "                composite_ranking, threshold = create_threshold_composite_ranking(total_df, best_high, best_low, ground_truth)\n",
    "                analysis[ground_truth]['threshold'] = threshold\n",
    "                ranking_col = f'composite_ranking_{ground_truth}_threshold_composite_ranking'\n",
    "                \n",
    "                # Debug print the actual values\n",
    "                print(f\"\\nCreated {ranking_col}\")\n",
    "                print(composite_ranking.describe())\n",
    "                total_df[ranking_col] = composite_ranking\n",
    "                print(\"Values in DataFrame:\", total_df[ranking_col].head())\n",
    "        \n",
    "        # Debug print after creating rankings\n",
    "        print(f\"\\nAfter creating rankings for {ground_truth}:\")\n",
    "        for col in total_df.columns:\n",
    "            if 'composite_ranking' in col:\n",
    "                print(f\"Column {col} exists with first value: {total_df[col].iloc[0]}\")\n",
    "    \n",
    "    # Calculate ALL correlations ONCE after all rankings are created for CORRELATION MATRIX\n",
    "    correlations = calculate_correlations(total_df, centralities, ground_truths, composite_functions)\n",
    "    \n",
    "    \n",
    "    # Store correlations in analysis\n",
    "    for ground_truth in ground_truths:\n",
    "        analysis[ground_truth]['correlations'] = correlations\n",
    "\n",
    "    plot_correlations(\n",
    "        correlations, \n",
    "        f'{output_path}/correlations_plot.png',\n",
    "        analysis\n",
    "    )\n",
    "\n",
    "    # Add correlation values to total_df for analysis\n",
    "    for (metric, gt), corr_value in correlations.items():\n",
    "        total_df[f'correlation_{metric}_{gt}'] = corr_value\n",
    "\n",
    "    # Store correlations and analyze performance\n",
    "    analysis[ground_truth]['correlations'] = correlations\n",
    "\n",
    "    # SAVE CORRELATIONS TO CSV\n",
    "    save_correlations_to_csv(\n",
    "        correlations,\n",
    "        f'{output_path}/correlations_{ground_truth}.csv',\n",
    "    )\n",
    "        \n",
    "    # For standard correlation matrix\n",
    "    correlations = calculate_centrality_correlations(total_df, centralities, ground_truths)\n",
    "\n",
    "\n",
    "    # Save complete analysis results\n",
    "    analysis_results = {\n",
    "        'failed_centralities': failed_centralities,\n",
    "        'network_stats': network_stats,\n",
    "        'ground_truths': ground_truths,\n",
    "        'centralities': centralities,\n",
    "        'composite_functions': composite_functions,\n",
    "        'centrality_correlations': correlations,\n",
    "        'ground_truth_analysis': {\n",
    "            gt: {\n",
    "                'threshold': analysis[gt]['threshold'],\n",
    "                'weight': analysis[gt]['weight'],\n",
    "                'correlations': analysis[gt]['correlations'],\n",
    "                'best_centralities': analysis[gt]['best_centralities'],\n",
    "                'composite_rankings': analysis[gt].get('composite_rankings', {}),\n",
    "                'composite_performance': analysis[gt]['composite_performance'],\n",
    "                'optimal_weights': analysis[gt].get('optimal_weights', {}),\n",
    "                'class_distribution': analysis[gt]['class_distribution'],\n",
    "                'centrality_counts': analysis[gt]['centrality_counts'],\n",
    "                'combination_counts': analysis[gt]['combination_counts'],\n",
    "                'network_performance': analysis[gt].get('network_performance', {})\n",
    "            } for gt in ground_truths\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Save total_df to CSV for further analysis\n",
    "    try:\n",
    "        total_df.to_csv(f'{output_path}/total_df.csv', index=True)\n",
    "        print(f\"Successfully saved total_df to {output_path}/total_df.csv\")\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to save total_df to CSV: {str(e)}\")\n",
    "\n",
    "    # Save analysis results to JSON file\n",
    "    def convert_keys_to_str(obj):\n",
    "        \"\"\"Convert dictionary keys to strings, handling tuples and other non-serializable types\"\"\"\n",
    "        if isinstance(obj, dict):\n",
    "            return {\n",
    "                str(key): convert_keys_to_str(value)\n",
    "                for key, value in obj.items()\n",
    "            }\n",
    "        elif isinstance(obj, (list, tuple)):\n",
    "            return [convert_keys_to_str(item) for item in obj]  # Fixed: was using 'item' instead of 'obj'\n",
    "        elif isinstance(obj, (int, float, str, bool)) or obj is None:\n",
    "            return obj\n",
    "        else:\n",
    "            return str(obj)  # Convert any other types to string\n",
    "\n",
    "    try:\n",
    "        # Convert analysis results to JSON-serializable format\n",
    "        json_safe_results = convert_keys_to_str(analysis_results)\n",
    "        \n",
    "        # Ensure output directory exists\n",
    "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "        \n",
    "        # Write to file with error handling\n",
    "        with open(f'{output_path}/analysis_results.json', 'w') as f:\n",
    "            json.dump(json_safe_results, f, indent=4)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Failed to save analysis results to JSON: {str(e)}\")\n",
    "    \n",
    "    assert 1==2\n",
    "    return analysis_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Function\n",
    "This section implements network comparison functionality to analyze and compare results across different networks.\n",
    "\n",
    "The main function `compare_networks()` takes results from multiple network analyses and performs the following comparisons:\n",
    "\n",
    "1. Correlation Comparisons:\n",
    "   - Compares how different centrality measures correlate with ground truth metrics across networks\n",
    "   - Creates comparison tables showing correlation values for each network\n",
    "   - Saves correlation comparisons to CSV files\n",
    "\n",
    "2. Ranking Comparisons: \n",
    "   - Analyzes how centrality measures rank relative to each other in different networks\n",
    "   - Converts absolute correlation values to rankings\n",
    "   - Shows which centrality measures perform consistently well across networks\n",
    "   - Saves ranking comparisons to CSV files\n",
    "\n",
    "The comparisons are performed for each combination of:\n",
    "- Ground truth metrics (e.g., PageRank, degree centrality)\n",
    "- Composite ranking functions (different ways of combining centrality measures)\n",
    "\n",
    "This allows us to:\n",
    "- Identify which centrality measures work best across different network types\n",
    "- Understand how network structure affects centrality measure performance\n",
    "- Compare the effectiveness of different composite ranking approaches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_networks(network_results: Dict[str, Dict], output_path: str) -> Dict:\n",
    "    \"\"\"\n",
    "    Compare centrality measure performance across different networks.\n",
    "    \n",
    "    Args:\n",
    "        network_results: Dictionary mapping network names to their analysis results\n",
    "        output_path: Path to save comparison results\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing aggregated analysis results per ground truth\n",
    "    \"\"\"\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Get ground truths from first network\n",
    "    first_network = list(network_results.values())[0]\n",
    "    ground_truths = list(first_network['ground_truth_analysis'].keys())\n",
    "    \n",
    "    analysis = {gt: {\n",
    "        'centrality_counts': {\n",
    "            'high': defaultdict(int),      # Times selected as best high\n",
    "            'low': defaultdict(int),       # Times selected as best low\n",
    "            'best_overall': defaultdict(int)  # Times had best correlation\n",
    "        },\n",
    "        'combination_counts': defaultdict(int),  # Times each high+low pair was selected\n",
    "        'composite_performance': {\n",
    "            'outperformed_count': 0,  # Times composite ranking beat individual centralities\n",
    "            'best_combinations': []    # Combinations that achieved best performance\n",
    "        }\n",
    "    } for gt in ground_truths}\n",
    "\n",
    "    # Add centrality correlations to analysis\n",
    "    analysis['centrality_correlations'] = {network_name: results['centrality_correlations'] for network_name, results in network_results.items()}\n",
    "    \n",
    "    # Analyze each network's results\n",
    "    for network_name, results in network_results.items():\n",
    "        for ground_truth in ground_truths:\n",
    "            gt_analysis = results['ground_truth_analysis'][ground_truth]\n",
    "            \n",
    "            # Get best centralities\n",
    "            best_high = gt_analysis['best_centralities']['high']\n",
    "            best_low = gt_analysis['best_centralities']['low']\n",
    "            best_overall = gt_analysis['best_centralities']['overall']\n",
    "            \n",
    "            # Count individual centrality selections\n",
    "            analysis[ground_truth]['centrality_counts']['high'][best_high] += 1\n",
    "            analysis[ground_truth]['centrality_counts']['low'][best_low] += 1\n",
    "            analysis[ground_truth]['centrality_counts']['best_overall'][best_overall] += 1\n",
    "            \n",
    "            # Count combination selections\n",
    "            combination = f\"{best_high}+{best_low}\"\n",
    "            analysis[ground_truth]['combination_counts'][combination] += 1\n",
    "            \n",
    "            # Track composite performance if available\n",
    "            composite_perf = gt_analysis['composite_performance']\n",
    "            if composite_perf['outperformed_count'] > 0:\n",
    "                analysis[ground_truth]['composite_performance']['outperformed_count'] += 1\n",
    "                for combo in composite_perf['best_combinations']:\n",
    "                    combo['network'] = network_name\n",
    "                    analysis[ground_truth]['composite_performance']['best_combinations'].append(combo)\n",
    "    \n",
    "    # Save results\n",
    "    for ground_truth in ground_truths:\n",
    "        # Save analysis results\n",
    "        results_file = f'{output_path}/network_analysis_{ground_truth}.json'\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(analysis[ground_truth], f, indent=4)\n",
    "        \n",
    "        # Create centrality summary DataFrame\n",
    "        centrality_summary = pd.DataFrame([{\n",
    "            'centrality': cent,\n",
    "            'times_best_high': analysis[ground_truth]['centrality_counts']['high'][cent],\n",
    "            'times_best_low': analysis[ground_truth]['centrality_counts']['low'][cent],\n",
    "            'times_best_overall': analysis[ground_truth]['centrality_counts']['best_overall'][cent]\n",
    "        } for cent in set(\n",
    "            list(analysis[ground_truth]['centrality_counts']['high'].keys()) +\n",
    "            list(analysis[ground_truth]['centrality_counts']['low'].keys()) +\n",
    "            list(analysis[ground_truth]['centrality_counts']['best_overall'].keys())\n",
    "        )])\n",
    "        \n",
    "        centrality_summary.to_csv(\n",
    "            f'{output_path}/centrality_summary_{ground_truth}.csv', \n",
    "            index=False\n",
    "        )\n",
    "        \n",
    "        # Create combination summary DataFrame\n",
    "        combination_summary = pd.DataFrame([{\n",
    "            'combination': comb,\n",
    "            'times_selected': count\n",
    "        } for comb, count in analysis[ground_truth]['combination_counts'].items()])\n",
    "        \n",
    "        combination_summary.to_csv(\n",
    "            f'{output_path}/combination_summary_{ground_truth}.csv',\n",
    "            index=False\n",
    "        )\n",
    "    \n",
    "    return analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_network_centrality_comparison(analysis: Dict, output_path: str):\n",
    "    # Get all unique centralities and networks\n",
    "    all_centralities = set()\n",
    "    all_networks = set()\n",
    "    \n",
    "    # Count occurrences for each centrality in each network and ground truth\n",
    "    network_counts = {}\n",
    "    \n",
    "    # Extract networks from centrality_correlations\n",
    "    if 'centrality_correlations' in analysis:\n",
    "        all_networks.update(analysis['centrality_correlations'].keys())\n",
    "        \n",
    "        # Generate colors dynamically based on number of networks\n",
    "        import colorsys\n",
    "        \n",
    "        def get_colors(n):\n",
    "            colors = {}\n",
    "            for i, network in enumerate(sorted(all_networks)):\n",
    "                # Generate evenly spaced hues\n",
    "                hue = i / n\n",
    "                # Create saturated color for importance\n",
    "                rgb = colorsys.hsv_to_rgb(hue, 0.8, 0.9)\n",
    "                main_color = f'#{int(rgb[0]*255):02x}{int(rgb[1]*255):02x}{int(rgb[2]*255):02x}'\n",
    "                # Create lighter version for doctypebranch\n",
    "                rgb_light = colorsys.hsv_to_rgb(hue, 0.5, 0.9)\n",
    "                light_color = f'#{int(rgb_light[0]*255):02x}{int(rgb_light[1]*255):02x}{int(rgb_light[2]*255):02x}'\n",
    "                colors[network] = (main_color, light_color)\n",
    "            return colors\n",
    "        \n",
    "        network_colors = get_colors(len(all_networks))\n",
    "        \n",
    "        # Initialize network_counts for each network\n",
    "        for network_name in all_networks:\n",
    "            network_counts[network_name] = {\n",
    "                'importance': defaultdict(int),\n",
    "                'doctypebranch': defaultdict(int)\n",
    "            }\n",
    "    \n",
    "    # For each ground truth, get the network performance data\n",
    "    for key in analysis:\n",
    "        if key != 'centrality_correlations':\n",
    "            network_performance = analysis[key].get('centrality_counts', {})\n",
    "            \n",
    "            # Process high performers\n",
    "            high_performers = network_performance.get('high', {})\n",
    "            for centrality, count in high_performers.items():\n",
    "                all_centralities.add(centrality)\n",
    "                for network in all_networks:\n",
    "                    network_counts[network][key][centrality] += count\n",
    "            \n",
    "            # Process low performers\n",
    "            low_performers = network_performance.get('low', {})\n",
    "            for centrality, count in low_performers.items():\n",
    "                all_centralities.add(centrality)\n",
    "                for network in all_networks:\n",
    "                    network_counts[network][key][centrality] += count\n",
    "    \n",
    "    if not all_networks or not all_centralities:\n",
    "        print(\"No data to plot: empty networks or centralities\")\n",
    "        return\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    centralities = sorted(list(all_centralities))\n",
    "    x = np.arange(len(centralities))\n",
    "    \n",
    "    # Plot bars for each network and ground truth\n",
    "    bar_width = 0.8 / (len(all_networks) * 2)  # 2 for two ground truths\n",
    "    \n",
    "    for i, network in enumerate(sorted(all_networks)):\n",
    "        for j, gt in enumerate(['importance', 'doctypebranch']):\n",
    "            counts = [network_counts[network][gt][c] for c in centralities] # TODO Check this\n",
    "            offset = bar_width * (i * 2 + j) - (len(all_networks) * bar_width)\n",
    "            \n",
    "            # Get appropriate color based on ground truth\n",
    "            color = network_colors[network][1] if gt == 'doctypebranch' else network_colors[network][0]\n",
    "            \n",
    "            bars = ax.bar(x + offset, counts, bar_width, \n",
    "                         label=f'{network} ({gt})',\n",
    "                         color=color,\n",
    "                         alpha=0.9)\n",
    "            \n",
    "            # Add value labels on top of each bar\n",
    "            for bar in bars:\n",
    "                height = bar.get_height()\n",
    "                if height > 0:  # Only add label if bar has height\n",
    "                    ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                           f'{int(height)}',\n",
    "                           ha='center', va='bottom')\n",
    "    \n",
    "    # Customize the plot\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Centrality Performance by Network and Ground Truth')\n",
    "    plt.suptitle('Total number of times each centrality has been selected as highest predictor for either low or high scores.', fontsize=10, y=0.95)\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(centralities, rotation=45, ha='right')\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    \n",
    "    # Adjust layout and save\n",
    "    plt.tight_layout()\n",
    "    output_file = os.path.join(output_path, 'network_centrality_comparison.png')\n",
    "    plt.savefig(output_file, bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def create_centrality_correlation_matrix(analysis_results: Dict, output_path: str):\n",
    "    \"\"\"\n",
    "    Create a CSV file showing correlations between centralities and ground truths across networks.\n",
    "    \n",
    "    Args:\n",
    "        analysis_results: Dictionary containing the analysis results with structure:\n",
    "            {'centrality_correlations': {\n",
    "                'network_name': {\n",
    "                    'ground_truth': {\n",
    "                        'centrality_ground_truth': correlation_value,\n",
    "                        ...\n",
    "                    },\n",
    "                    ...\n",
    "                },\n",
    "                ...\n",
    "            }}\n",
    "        output_path: Path to save the CSV file\n",
    "    \n",
    "    The CSV will have:\n",
    "    - Column 1: Centrality measures\n",
    "    - Remaining columns: One column per network\n",
    "    - Values: Ground truth correlations formatted as \"GT1: value | GT2: value\"\n",
    "    \"\"\"\n",
    "    # Get centrality correlations dictionary\n",
    "    network_correlations = analysis_results['centrality_correlations']\n",
    "    print(f\"Found networks: {list(network_correlations.keys())}\")\n",
    "    \n",
    "    # Extract all centralities from the data\n",
    "    all_centralities = set()\n",
    "    for network_data in network_correlations.values():\n",
    "        for centrality, _ in network_data.keys():\n",
    "            all_centralities.add(centrality)\n",
    "    print(f\"\\nFound centralities: {sorted(list(all_centralities))}\")\n",
    "    \n",
    "    # Extract ground truths from the first network (assuming all networks have same ground truths)\n",
    "    ground_truths = set()\n",
    "    for (_, gt) in network_correlations[list(network_correlations.keys())[0]].keys():\n",
    "        ground_truths.add(gt)\n",
    "    print(f\"\\nFound ground truths: {sorted(list(ground_truths))}\")\n",
    "    \n",
    "    # Create DataFrame with just centralities and networks\n",
    "    networks = sorted(network_correlations.keys())\n",
    "    df = pd.DataFrame(index=sorted(list(all_centralities)), \n",
    "                     columns=['Centrality'] + networks)\n",
    "    \n",
    "    # Fill in centrality names\n",
    "    df['Centrality'] = df.index\n",
    "    print(\"\\nInitial DataFrame:\")\n",
    "    print(df)\n",
    "    \n",
    "    # Fill in the correlation values for each network\n",
    "    for network in networks:\n",
    "        print(f\"\\nFilling data for network: {network}\")\n",
    "        network_data = network_correlations[network]\n",
    "        \n",
    "        for centrality in all_centralities:\n",
    "            # Collect all ground truth correlations for this centrality\n",
    "            correlations = []\n",
    "            for gt in sorted(ground_truths):\n",
    "                key = (centrality, gt)\n",
    "                if key in network_data:\n",
    "                    value = network_data[key]\n",
    "                    # Capitalize first letter of ground truth and format value\n",
    "                    gt_display = gt.capitalize()\n",
    "                    correlations.append(f\"{gt_display}: {value:.4f}\")\n",
    "            \n",
    "            # Join all ground truth correlations with \" | \"\n",
    "            if correlations:\n",
    "                df.loc[centrality, network] = \" | \".join(correlations)\n",
    "            else:\n",
    "                df.loc[centrality, network] = \"N/A\"\n",
    "    \n",
    "    print(\"\\nFinal DataFrame:\")\n",
    "    print(df)\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = os.path.join(output_path, 'centrality_correlations_matrix.csv')\n",
    "    df.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"\\nCorrelation matrix saved to {output_file}\")\n",
    "\n",
    "def visualize_network_commonalities(analysis_results: Dict, output_path: str, compare_all: bool = False, print_correlations: bool = False):\n",
    "    \"\"\"\n",
    "    Visualize commonalities between networks focusing on centrality performance.\n",
    "    Each visualization is saved separately.\n",
    "    \n",
    "    Args:\n",
    "        analysis_results: Dictionary containing the analysis results from compare_networks()\n",
    "        output_path: Path to save visualization outputs\n",
    "    \"\"\"\n",
    "    # Set the aesthetic style\n",
    "    plt.style.use('default')\n",
    "    colors = {'importance': 'skyblue', 'doctypebranch': 'lightgreen'}\n",
    "    \n",
    "    # Helper function to add value labels\n",
    "    def add_value_labels(ax, rects):\n",
    "        for rect in rects:\n",
    "            height = rect.get_height()\n",
    "            ax.text(rect.get_x() + rect.get_width()/2., height,\n",
    "                    f'{int(height)}',\n",
    "                    ha='center', va='bottom')\n",
    "    \n",
    "    # 1. High Importance Performers Graph\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    for key in analysis_results:\n",
    "        if key != 'centrality_correlations':  # This is a ground truth\n",
    "            high_counts = analysis_results[key]['centrality_counts']['high']\n",
    "            if high_counts:\n",
    "                centralities = list(high_counts.keys())\n",
    "                counts = list(high_counts.values())\n",
    "                bars = ax.bar(centralities, counts, label=key, alpha=0.7, color=colors[key])\n",
    "                add_value_labels(ax, bars)\n",
    "    \n",
    "    plt.ylabel('Times Selected as Best High Predictor')\n",
    "    plt.title('Best Performing Centralities for High Scores')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/high_performers.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Low Importance Performers Graph\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    for key in analysis_results:\n",
    "        if key != 'centrality_correlations':  # This is a ground truth\n",
    "            low_counts = analysis_results[key]['centrality_counts']['low']\n",
    "            if low_counts:\n",
    "                centralities = list(low_counts.keys())\n",
    "                counts = list(low_counts.values())\n",
    "                bars = ax.bar(centralities, counts, alpha=0.5, label=key, color=colors[key])\n",
    "                add_value_labels(ax, bars)\n",
    "    \n",
    "    plt.ylabel('Times Selected as Best Low Predictor')\n",
    "    plt.title('Best Performing Centralities for Low Scores')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/low_performers.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Best Overall Performers Graph\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    for ground_truth in analysis_results:\n",
    "        if ground_truth != 'centrality_correlations':\n",
    "            best_overall = analysis_results[ground_truth]['centrality_counts']['best_overall']\n",
    "            if best_overall:\n",
    "                centralities = list(best_overall.keys())\n",
    "                counts = list(best_overall.values())\n",
    "                bars = ax.bar(centralities, counts, label=ground_truth, alpha=0.7, color=colors[ground_truth])\n",
    "                add_value_labels(ax, bars)\n",
    "    \n",
    "    plt.ylabel('Times Selected as Highest Predictor')\n",
    "    plt.title('Higest Overall Predicting Centralities')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/best_overall_performers.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Combination Performance Graph\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    for key in analysis_results:\n",
    "        if key != 'centrality_correlations':\n",
    "            combinations = analysis_results[key]['combination_counts']\n",
    "            if combinations:\n",
    "                combo_names = list(combinations.keys())\n",
    "                combo_counts = list(combinations.values())\n",
    "                bars = ax.bar(combo_names, combo_counts, label=key, alpha=0.7, color=colors[key])\n",
    "                add_value_labels(ax, bars)\n",
    "\n",
    "    plt.ylabel('Times Selected as Highest Predictor')\n",
    "    plt.title('Best Performing Centrality Combinations')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/combination_performance.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Total Best Occurrences Graph\n",
    "    total_counts = {}\n",
    "    for key in analysis_results:\n",
    "        if key != 'centrality_correlations':\n",
    "            for category in ['high', 'low', 'best_overall']:\n",
    "                counts = analysis_results[key]['centrality_counts'][category]\n",
    "                for centrality, count in counts.items():\n",
    "                    if centrality not in total_counts:\n",
    "                        total_counts[centrality] = 0\n",
    "                    total_counts[centrality] += count\n",
    "    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    if total_counts:\n",
    "        centralities = list(total_counts.keys())\n",
    "        counts = list(total_counts.values())\n",
    "        bars = ax.bar(centralities, counts, color='lightcoral', alpha=0.7)\n",
    "        add_value_labels(ax, bars)\n",
    "    \n",
    "    plt.ylabel('Total Times Selected as Highest Predictor')\n",
    "    plt.title('Overall Best Performing Centralities (All Categories)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{output_path}/total_best_occurrences.png', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # 6. Compare across networks\n",
    "    if compare_all:\n",
    "        plot_network_centrality_comparison(analysis_results, output_path) # TODO\n",
    "        \n",
    "    if print_correlations:\n",
    "        create_centrality_correlation_matrix(analysis_results, output_path)\n",
    "        \n",
    "        # Create performance summary\n",
    "    performance_summary = {}\n",
    "    for key in analysis_results:\n",
    "        if key != 'centrality_correlations':\n",
    "            performance_summary[key] = {\n",
    "                'best_performers': {\n",
    "                    'high': None,\n",
    "                    'low': None,\n",
    "                    'combination': None\n",
    "                },\n",
    "                'composite_performance': {}\n",
    "            }\n",
    "            \n",
    "            # Best high performer\n",
    "            high_counts = analysis_results[key]['centrality_counts']['high']\n",
    "            if high_counts:\n",
    "                best_high = max(high_counts.items(), key=lambda x: x[1])\n",
    "                performance_summary[key]['best_performers']['high'] = {\n",
    "                    'centrality': best_high[0],\n",
    "                    'times_selected': best_high[1]\n",
    "                }\n",
    "            \n",
    "            # Best low performer\n",
    "            low_counts = analysis_results[key]['centrality_counts']['low']\n",
    "            if low_counts:\n",
    "                best_low = max(low_counts.items(), key=lambda x: x[1])\n",
    "                performance_summary[key]['best_performers']['low'] = {\n",
    "                    'centrality': best_low[0],\n",
    "                    'times_selected': best_low[1]\n",
    "                }\n",
    "            \n",
    "            # Best combination\n",
    "            combinations = analysis_results[key]['combination_counts']\n",
    "            if combinations:\n",
    "                best_combo = max(combinations.items(), key=lambda x: x[1])\n",
    "                performance_summary[key]['best_performers']['combination'] = {\n",
    "                    'combination': best_combo[0],\n",
    "                    'times_selected': best_combo[1]\n",
    "                }\n",
    "            \n",
    "            # Composite performance\n",
    "            outperformed_count = analysis_results[key]['composite_performance']['outperformed_count']\n",
    "            best_combinations = analysis_results[key]['composite_performance']['best_combinations']\n",
    "            performance_summary[key]['composite_performance'] = {\n",
    "                'outperformed_count': outperformed_count,\n",
    "                'best_combinations': []\n",
    "            }\n",
    "            \n",
    "            if best_combinations:\n",
    "                combo_counts = {}\n",
    "                for entry in best_combinations:\n",
    "                    combo = entry['combination']\n",
    "                    combo_counts[combo] = combo_counts.get(combo, 0) + 1\n",
    "                \n",
    "                best_outperforming = max(combo_counts.items(), key=lambda x: x[1])\n",
    "                best_correlation = max(entry['correlation'] for entry in best_combinations)\n",
    "                \n",
    "                performance_summary[key]['composite_performance'].update({\n",
    "                    'best_outperforming_combo': {\n",
    "                        'combination': best_outperforming[0],\n",
    "                        'times_outperformed': best_outperforming[1]\n",
    "                    },\n",
    "                    'highest_correlation': best_correlation,\n",
    "                    'detailed_combinations': best_combinations\n",
    "                })\n",
    "    \n",
    "        # Add overall best performer\n",
    "    if total_counts:\n",
    "        best_overall = max(total_counts.items(), key=lambda x: x[1])\n",
    "        performance_summary['overall_best_performer'] = {\n",
    "            'centrality': best_overall[0],\n",
    "            'total_times_selected': best_overall[1]\n",
    "        }\n",
    "    \n",
    "    # Save performance summary as JSON\n",
    "    with open(f'{output_path}/performance_summary.json', 'w') as f:\n",
    "        json.dump(performance_summary, f, indent=4)\n",
    "    \n",
    "    # Save detailed numerical results\n",
    "    summary = {\n",
    "        key: {\n",
    "            'high_performers': dict(analysis_results[key]['centrality_counts']['high']),\n",
    "            'low_performers': dict(analysis_results[key]['centrality_counts']['low']),\n",
    "            'best_overall': dict(analysis_results[key]['centrality_counts']['best_overall']),\n",
    "            'combinations': dict(analysis_results[key]['combination_counts']),\n",
    "            'composite_performance': {\n",
    "                'outperformed_count': analysis_results[key]['composite_performance']['outperformed_count'],\n",
    "                'best_combinations': analysis_results[key]['composite_performance']['best_combinations']\n",
    "            },\n",
    "            'best_performers': {\n",
    "                'high': max(analysis_results[key]['centrality_counts']['high'].items(), \n",
    "                           key=lambda x: x[1])[0] if analysis_results[key]['centrality_counts']['high'] else None,\n",
    "                'low': max(analysis_results[key]['centrality_counts']['low'].items(), \n",
    "                          key=lambda x: x[1])[0] if analysis_results[key]['centrality_counts']['low'] else None,\n",
    "                'overall': max(analysis_results[key]['centrality_counts']['best_overall'].items(), \n",
    "                             key=lambda x: x[1])[0] if analysis_results[key]['centrality_counts']['best_overall'] else None,\n",
    "                'combination': max(analysis_results[key]['combination_counts'].items(), \n",
    "                                 key=lambda x: x[1])[0] if analysis_results[key]['combination_counts'] else None\n",
    "            }\n",
    "        }\n",
    "        for key in analysis_results if key != 'centrality_correlations'\n",
    "    }\n",
    "    \n",
    "    # Add total counts to summary\n",
    "    summary['total_counts'] = total_counts\n",
    "    \n",
    "    # Save visualization summary\n",
    "    with open(f'{output_path}/visualization_summary.json', 'w') as f:\n",
    "        json.dump(summary, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_networks(path, max=100, min_nodes=50):\n",
    "    \"\"\"\n",
    "    Load networks from a directory structure. Can handle both:\n",
    "    1. Direct network files (nodes.json and edges.json in the input path)\n",
    "    2. Networks in subdirectories\n",
    "    \n",
    "    Args:\n",
    "        path: Root directory to search for networks or direct path to a network\n",
    "        max: Maximum number of networks to load\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dictionary of networks with structure {network_name: {'nodes': df, 'edges': df}}\n",
    "    \"\"\"\n",
    "    networks = {}\n",
    "    loaded_count = 0\n",
    "    \n",
    "    # Verify root directory exists and print absolute path\n",
    "    abs_root = os.path.abspath(path)\n",
    "    \n",
    "    if not os.path.exists(abs_root):\n",
    "        raise ValueError(f\"Directory {abs_root} does not exist\")\n",
    "        \n",
    "    def is_network_dir(dir_path):\n",
    "        \"\"\"Check if directory contains exactly nodes.json and edges.json\"\"\"\n",
    "        try:\n",
    "            contents = os.listdir(dir_path)\n",
    "            return ('nodes.json' in contents and 'edges.json' in contents)\n",
    "        except:\n",
    "            return False\n",
    "    \n",
    "    def load_network(dir_path, network_name, min_nodes=50):\n",
    "        \"\"\"Load a single network from a directory\"\"\"\n",
    "        \n",
    "        nodes_file = os.path.join(dir_path, 'nodes.json')\n",
    "        edges_file = os.path.join(dir_path, 'edges.json')\n",
    "        \n",
    "        try:\n",
    "            # Load and validate data\n",
    "            nodes_df = pd.read_json(nodes_file)\n",
    "            edges_df = pd.read_json(edges_file)\n",
    "            \n",
    "            # Validate required columns\n",
    "            required_node_cols = ['ecli', 'importance', 'doctypebranch']\n",
    "            missing_cols = [col for col in required_node_cols if col not in nodes_df.columns]\n",
    "            if missing_cols:\n",
    "                print(f\"  Warning: Missing columns in nodes.json: {missing_cols}\")\n",
    "                print(f\"  Available columns: {nodes_df.columns.tolist()}\")\n",
    "                return False\n",
    "            \n",
    "            required_edge_cols = ['ecli', 'references']\n",
    "            missing_edge_cols = [col for col in required_edge_cols if col not in edges_df.columns]\n",
    "            if missing_edge_cols:\n",
    "                print(f\"  Warning: Missing columns in edges.json: {missing_edge_cols}\")\n",
    "                print(f\"  Available columns: {edges_df.columns.tolist()}\")\n",
    "                return False\n",
    "            \n",
    "            if len(nodes_df) < min_nodes:\n",
    "                print(f\"  Warning: Network {network_name} has fewer than {min_nodes} nodes\")\n",
    "                return False\n",
    "            \n",
    "            networks[network_name] = {\n",
    "                'nodes': nodes_df,\n",
    "                'edges': edges_df\n",
    "            }\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  Error loading network: {str(e)}\")\n",
    "            return False\n",
    "    \n",
    "    def process_directory(current_path, parent_prefix=\"\"):\n",
    "        \"\"\"Recursively process directories looking for networks\"\"\"\n",
    "        nonlocal loaded_count\n",
    "        if loaded_count >= max:\n",
    "            return\n",
    "            \n",
    "        # First check if current directory is a network directory\n",
    "        if is_network_dir(current_path):\n",
    "            # Generate network name based on path\n",
    "            rel_path = os.path.relpath(current_path, abs_root)\n",
    "            network_name = rel_path.replace(os.sep, '-')\n",
    "            if network_name == '.':  # Handle case where path is direct to network\n",
    "                network_name = os.path.basename(current_path)\n",
    "            \n",
    "            if load_network(current_path, network_name, min_nodes):\n",
    "                loaded_count += 1\n",
    "            return\n",
    "        \n",
    "        # If not a network directory, search subdirectories\n",
    "        try:\n",
    "            for item in os.listdir(current_path):\n",
    "                if loaded_count >= max:\n",
    "                    break\n",
    "                    \n",
    "                item_path = os.path.join(current_path, item)\n",
    "                if not os.path.isdir(item_path):\n",
    "                    continue\n",
    "                    \n",
    "                process_directory(item_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error accessing directory {current_path}: {str(e)}\")\n",
    "    \n",
    "    # Start processing from root directory\n",
    "    process_directory(abs_root)\n",
    "    print(f\"\\nSuccessfully loaded {len(networks)} networks\")\n",
    "    return networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centralities of interest\n",
    "CENTRALITIES = ['degree_centrality', 'in_degree_centrality', 'out_degree_centrality', \n",
    "                'betweenness_centrality', 'closeness_centrality', 'core_number', \n",
    "                'relative_in_degree_centrality', 'eigenvector_centrality', \n",
    "                'pagerank', 'hits_hub', 'hits_authority', 'harmonic_centrality', 'disruption']\n",
    "\n",
    "# Ground truths of interest\n",
    "GROUND_TRUTHS = ['importance', 'doctypebranch']\n",
    "GROUND_TRUTHS_INVERTED = ['importance_inverted',  'doctypebranch_inverted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully loaded 62 networks\n",
      "\n",
      "Analyzing network: article_1\n",
      "Failed to calculate current_flow_betweenness: Graph not connected.\n",
      "Failed to calculate current_flow_closeness: Graph not connected.\n",
      "Failed to calculate trophic_level: Trophic levels are only defined for graphs where every node has a path from a basal node (basal nodes are nodes with no incoming edges).\n",
      "\n",
      "Analyzing ground truth: importance\n",
      "Plotted 13 centrality vs ground truth plots\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "\n",
      "Analyzing ground truth: doctypebranch\n",
      "Plotted 13 centrality vs ground truth plots\n",
      "Best high correlation: in_degree_centrality\n",
      "Best low correlation: relative_in_degree_centrality\n",
      "best_high and best_low for importance\n",
      "       in_degree_centrality  relative_in_degree_centrality\n",
      "count           5938.000000                    5938.000000\n",
      "mean               0.000187                       0.000187\n",
      "std                0.000679                       0.000679\n",
      "min                0.000000                       0.000000\n",
      "25%                0.000000                       0.000000\n",
      "50%                0.000000                       0.000000\n",
      "75%                0.000168                       0.000168\n",
      "max                0.019033                       0.019030\n",
      "\n",
      "Before creating rankings for importance:\n",
      "\n",
      "Debug values:\n",
      "Original high centrality range: [0.0, 0.019033181741620348]\n",
      "Original low centrality range: [0.0, 0.01902997642303806]\n",
      "Normalized high centrality range: [1.600360576923077, 1000.0]\n",
      "Normalized low centrality range: [1.600360576923077, 1000.0]\n",
      "\n",
      "Best results:\n",
      "Best weight: 0.01\n",
      "Best correlation: 0.42233110999129997\n",
      "Composite range: [1.6003605770230773, 1000.0000000000999]\n",
      "\n",
      "Created composite_ranking_importance_weight_composite_ranking\n",
      "Composite ranking statistics:\n",
      "count    5938.000000\n",
      "mean      860.109717\n",
      "std       267.705169\n",
      "min         1.600361\n",
      "25%       789.573618\n",
      "50%      1000.000000\n",
      "75%      1000.000000\n",
      "max      1000.000000\n",
      "dtype: float64\n",
      "Values in DataFrame: 0    1000.0\n",
      "1    1000.0\n",
      "2    1000.0\n",
      "3    1000.0\n",
      "4    1000.0\n",
      "Name: composite_ranking_importance_weight_composite_ranking, dtype: float64\n",
      "\n",
      "Debug values:\n",
      "Original high centrality range: [0.0, 0.019033181741620348]\n",
      "Original low centrality range: [0.0, 0.01902997642303806]\n",
      "Normalized high centrality range: [1.600360576923077, 1000.0]\n",
      "Normalized low centrality range: [1.600360576923077, 1000.0]\n",
      "\n",
      "Best results:\n",
      "Best threshold percentile: 1\n",
      "Best correlation: 0.42233110999129997\n",
      "Composite range: [1.600360576923077, 1000.0]\n",
      "\n",
      "Created composite_ranking_importance_threshold_composite_ranking\n",
      "count    5938.000000\n",
      "mean      860.109717\n",
      "std       267.705169\n",
      "min         1.600361\n",
      "25%       789.573618\n",
      "50%      1000.000000\n",
      "75%      1000.000000\n",
      "max      1000.000000\n",
      "dtype: float64\n",
      "Values in DataFrame: 0    1000.0\n",
      "1    1000.0\n",
      "2    1000.0\n",
      "3    1000.0\n",
      "4    1000.0\n",
      "Name: composite_ranking_importance_threshold_composite_ranking, dtype: float64\n",
      "\n",
      "After creating rankings for importance:\n",
      "Column composite_ranking_importance_weight_composite_ranking exists with first value: 1000.0000000000999\n",
      "Column composite_ranking_importance_threshold_composite_ranking exists with first value: 1000.0\n",
      "best_high and best_low for doctypebranch\n",
      "       in_degree_centrality  relative_in_degree_centrality\n",
      "count           5938.000000                    5938.000000\n",
      "mean               0.000187                       0.000187\n",
      "std                0.000679                       0.000679\n",
      "min                0.000000                       0.000000\n",
      "25%                0.000000                       0.000000\n",
      "50%                0.000000                       0.000000\n",
      "75%                0.000168                       0.000168\n",
      "max                0.019033                       0.019030\n",
      "\n",
      "Before creating rankings for doctypebranch:\n",
      "Column composite_ranking_importance_weight_composite_ranking exists with first value: 1000.0000000000999\n",
      "Column composite_ranking_importance_threshold_composite_ranking exists with first value: 1000.0\n",
      "\n",
      "Debug values:\n",
      "Original high centrality range: [0.0, 0.019033181741620348]\n",
      "Original low centrality range: [0.0, 0.01902997642303806]\n",
      "Normalized high centrality range: [1.600360576923077, 1000.0]\n",
      "Normalized low centrality range: [1.600360576923077, 1000.0]\n",
      "\n",
      "Best results:\n",
      "Best weight: 0.01\n",
      "Best correlation: 0.3700728872230385\n",
      "Composite range: [1.6003605770230773, 1000.0000000000999]\n",
      "\n",
      "Created composite_ranking_doctypebranch_weight_composite_ranking\n",
      "Composite ranking statistics:\n",
      "count    5938.000000\n",
      "mean      860.109717\n",
      "std       267.705169\n",
      "min         1.600361\n",
      "25%       789.573618\n",
      "50%      1000.000000\n",
      "75%      1000.000000\n",
      "max      1000.000000\n",
      "dtype: float64\n",
      "Values in DataFrame: 0    1000.0\n",
      "1    1000.0\n",
      "2    1000.0\n",
      "3    1000.0\n",
      "4    1000.0\n",
      "Name: composite_ranking_doctypebranch_weight_composite_ranking, dtype: float64\n",
      "\n",
      "Debug values:\n",
      "Original high centrality range: [0.0, 0.019033181741620348]\n",
      "Original low centrality range: [0.0, 0.01902997642303806]\n",
      "Normalized high centrality range: [1.600360576923077, 1000.0]\n",
      "Normalized low centrality range: [1.600360576923077, 1000.0]\n",
      "\n",
      "Best results:\n",
      "Best threshold percentile: 1\n",
      "Best correlation: 0.3700728872230385\n",
      "Composite range: [1.600360576923077, 1000.0]\n",
      "\n",
      "Created composite_ranking_doctypebranch_threshold_composite_ranking\n",
      "count    5938.000000\n",
      "mean      860.109717\n",
      "std       267.705169\n",
      "min         1.600361\n",
      "25%       789.573618\n",
      "50%      1000.000000\n",
      "75%      1000.000000\n",
      "max      1000.000000\n",
      "dtype: float64\n",
      "Values in DataFrame: 0    1000.0\n",
      "1    1000.0\n",
      "2    1000.0\n",
      "3    1000.0\n",
      "4    1000.0\n",
      "Name: composite_ranking_doctypebranch_threshold_composite_ranking, dtype: float64\n",
      "\n",
      "After creating rankings for doctypebranch:\n",
      "Column composite_ranking_importance_weight_composite_ranking exists with first value: 1000.0000000000999\n",
      "Column composite_ranking_importance_threshold_composite_ranking exists with first value: 1000.0\n",
      "Column composite_ranking_doctypebranch_weight_composite_ranking exists with first value: 1000.0000000000999\n",
      "Column composite_ranking_doctypebranch_threshold_composite_ranking exists with first value: 1000.0\n",
      "Found composite columns: ['composite_ranking_importance_weight_composite_ranking', 'composite_ranking_importance_threshold_composite_ranking', 'composite_ranking_doctypebranch_weight_composite_ranking', 'composite_ranking_doctypebranch_threshold_composite_ranking']\n",
      "Correlation between composite_ranking_importance_weight_composite_ranking and importance: 0.42233110999129997\n",
      "Correlation between composite_ranking_importance_weight_composite_ranking and doctypebranch: 0.3700728872230385\n",
      "Correlation between composite_ranking_importance_threshold_composite_ranking and importance: 0.42233110999129997\n",
      "Correlation between composite_ranking_importance_threshold_composite_ranking and doctypebranch: 0.3700728872230385\n",
      "Correlation between composite_ranking_doctypebranch_weight_composite_ranking and importance: 0.42233110999129997\n",
      "Correlation between composite_ranking_doctypebranch_weight_composite_ranking and doctypebranch: 0.3700728872230385\n",
      "Correlation between composite_ranking_doctypebranch_threshold_composite_ranking and importance: 0.42233110999129997\n",
      "Correlation between composite_ranking_doctypebranch_threshold_composite_ranking and doctypebranch: 0.3700728872230385\n",
      "Generated correlations:  dict_keys([('degree_centrality', 'importance'), ('degree_centrality', 'doctypebranch'), ('in_degree_centrality', 'importance'), ('in_degree_centrality', 'doctypebranch'), ('out_degree_centrality', 'importance'), ('out_degree_centrality', 'doctypebranch'), ('betweenness_centrality', 'importance'), ('betweenness_centrality', 'doctypebranch'), ('closeness_centrality', 'importance'), ('closeness_centrality', 'doctypebranch'), ('core_number', 'importance'), ('core_number', 'doctypebranch'), ('relative_in_degree_centrality', 'importance'), ('relative_in_degree_centrality', 'doctypebranch'), ('eigenvector_centrality', 'importance'), ('eigenvector_centrality', 'doctypebranch'), ('pagerank', 'importance'), ('pagerank', 'doctypebranch'), ('hits_hub', 'importance'), ('hits_hub', 'doctypebranch'), ('hits_authority', 'importance'), ('hits_authority', 'doctypebranch'), ('harmonic_centrality', 'importance'), ('harmonic_centrality', 'doctypebranch'), ('disruption', 'importance'), ('disruption', 'doctypebranch'), ('composite_ranking_importance_weight_composite_ranking', 'importance'), ('composite_ranking_importance_weight_composite_ranking', 'doctypebranch'), ('composite_ranking_importance_threshold_composite_ranking', 'importance'), ('composite_ranking_importance_threshold_composite_ranking', 'doctypebranch'), ('composite_ranking_doctypebranch_weight_composite_ranking', 'importance'), ('composite_ranking_doctypebranch_weight_composite_ranking', 'doctypebranch'), ('composite_ranking_doctypebranch_threshold_composite_ranking', 'importance'), ('composite_ranking_doctypebranch_threshold_composite_ranking', 'doctypebranch')])\n",
      "WARNING: Correlations for weight_composite_ranking and threshold_composite_ranking are too similar - they should produce different results\n",
      "Plotting for correlations:  dict_keys([('degree_centrality', 'importance'), ('degree_centrality', 'doctypebranch'), ('in_degree_centrality', 'importance'), ('in_degree_centrality', 'doctypebranch'), ('out_degree_centrality', 'importance'), ('out_degree_centrality', 'doctypebranch'), ('betweenness_centrality', 'importance'), ('betweenness_centrality', 'doctypebranch'), ('closeness_centrality', 'importance'), ('closeness_centrality', 'doctypebranch'), ('core_number', 'importance'), ('core_number', 'doctypebranch'), ('relative_in_degree_centrality', 'importance'), ('relative_in_degree_centrality', 'doctypebranch'), ('eigenvector_centrality', 'importance'), ('eigenvector_centrality', 'doctypebranch'), ('pagerank', 'importance'), ('pagerank', 'doctypebranch'), ('hits_hub', 'importance'), ('hits_hub', 'doctypebranch'), ('hits_authority', 'importance'), ('hits_authority', 'doctypebranch'), ('harmonic_centrality', 'importance'), ('harmonic_centrality', 'doctypebranch'), ('disruption', 'importance'), ('disruption', 'doctypebranch'), ('composite_ranking_importance_weight_composite_ranking', 'importance'), ('composite_ranking_importance_weight_composite_ranking', 'doctypebranch'), ('composite_ranking_importance_threshold_composite_ranking', 'importance'), ('composite_ranking_importance_threshold_composite_ranking', 'doctypebranch'), ('composite_ranking_doctypebranch_weight_composite_ranking', 'importance'), ('composite_ranking_doctypebranch_weight_composite_ranking', 'doctypebranch'), ('composite_ranking_doctypebranch_threshold_composite_ranking', 'importance'), ('composite_ranking_doctypebranch_threshold_composite_ranking', 'doctypebranch')])\n",
      "Successfully saved total_df to results/test/split-balanced-importance/article_1/total_df.csv\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m network_name, data \u001b[38;5;129;01min\u001b[39;00m splitTest\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAnalyzing network: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnetwork_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_network\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnodes_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnodes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43medges_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43medges\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mground_truths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGROUND_TRUTHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcentralities\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCENTRALITIES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcomposite_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_composite_ranking\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthreshold_composite_ranking\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresults/test/split-balanced-importance/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mnetwork_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     network_results[network_name] \u001b[38;5;241m=\u001b[39m results\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Before comparison\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[61], line 305\u001b[0m, in \u001b[0;36manalyze_network\u001b[0;34m(nodes_df, edges_df, ground_truths, centralities, composite_functions, output_path, network_name)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: Failed to save analysis results to JSON: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 305\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m analysis_results\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # TEST\n",
    "# network_results = {}\n",
    "\n",
    "# splitTest = load_networks('networks/merged/split-balanced-importance')\n",
    "# # Sort networks by size and take the 8 biggest ones\n",
    "# splitTest = dict(sorted(splitTest.items(), key=lambda x: len(x[1]['nodes']), reverse=True)[:3])\n",
    "\n",
    "\n",
    "\n",
    "# # Analyze Networks\n",
    "# for network_name, data in splitTest.items():\n",
    "#     print(f\"\\nAnalyzing network: {network_name}\")\n",
    "#     results = analyze_network(\n",
    "#         nodes_df=data['nodes'],\n",
    "#         edges_df=data['edges'],\n",
    "#         ground_truths=GROUND_TRUTHS,\n",
    "#         centralities=CENTRALITIES,\n",
    "#         composite_functions=['weight_composite_ranking', 'threshold_composite_ranking'],\n",
    "#         output_path=f'results/test/split-balanced-importance/{network_name}'\n",
    "#     )\n",
    "#     network_results[network_name] = results\n",
    "\n",
    "# # Before comparison\n",
    "# if not network_results:\n",
    "#     raise ValueError(\"No networks were successfully analyzed. Check if data/split directory contains valid network data.\")\n",
    "\n",
    "# # Compare results across networks\n",
    "# analysis = compare_networks(network_results, 'results/test/split-balanced-importance/comparisons')\n",
    "\n",
    "# # Visualize results\n",
    "# visualize_network_commonalities(analysis, 'results/test/split-balanced-importance/comparisons')\n",
    "\n",
    "\n",
    "\n",
    "# # FOR TESTING, SELECT THE 3 BIGGEST NETWORKS\n",
    "# print(\"TESTING CROSS-NETWORK CORRELATIONS\")\n",
    "# # Sort networks by size and take the 3 biggest ones\n",
    "\n",
    "# # Analyze Networks\n",
    "# analysis = compare_networks(network_results, 'results/test/full/comparisons')\n",
    "\n",
    "# # Visualize results\n",
    "# visualize_network_commonalities(analysis, 'results/test/full/comparisons', print_correlations=True, compare_all=True)\n",
    "# assert 1==2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Compilation\n",
    "- Analise entire network \n",
    "- Split between balanced and unbalanced\n",
    "- Differentiate sets of networks between minimum node count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_total_edges(edges_df: pd.DataFrame) -> int:\n",
    "    \"\"\"\n",
    "    Count total number of edges in the network, considering multiple targets per entry.\n",
    "    \n",
    "    Args:\n",
    "        edges_df: DataFrame containing edges with 'target' column that may contain multiple targets\n",
    "        \n",
    "    Returns:\n",
    "        int: Total number of edges in the network\n",
    "    \"\"\"\n",
    "    total_edges = 0\n",
    "    \n",
    "    # Iterate through each row\n",
    "    for _, row in edges_df.iterrows():\n",
    "        # Handle references column\n",
    "        if isinstance(row['references'], str):\n",
    "            # Clean the string and convert to list\n",
    "            refs_str = row['references'].strip('[]').replace(\"'\", \"\").replace('\"', \"\")\n",
    "            # Split by comma and clean each ECLI\n",
    "            references = [ref.strip() for ref in refs_str.split(',') if ref.strip()]\n",
    "            # Count valid ECLI references\n",
    "            edge_count = len([ref for ref in references if ref.startswith('ECLI:')])\n",
    "            total_edges += edge_count\n",
    "        elif isinstance(row['references'], list):\n",
    "            # If references is already a list\n",
    "            edge_count = len([ref for ref in row['references'] if isinstance(ref, str) and ref.startswith('ECLI:')])\n",
    "            total_edges += edge_count\n",
    "            \n",
    "    return total_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LOAD COMPLETE NETWORKS (min 50 nodes)\n",
    "network_results = {}\n",
    "\n",
    "# Load full complete networks\n",
    "full_unbalanced = load_networks('networks/merged-article-edges/full-unbalanced')\n",
    "full_balanced_importance = load_networks('networks/merged-article-edges/full-balanced-importance')\n",
    "full_balanced_doctypebranch = load_networks('networks/merged-article-edges/full-balanced-doctypebranch')\n",
    "\n",
    "# Print detailed statistics for full networks\n",
    "print(\"\\n=== Full Network Statistics ===\\n\")\n",
    "\n",
    "# Print statistics for all network types\n",
    "for network_type, network_data in [\n",
    "    (\"Unbalanced Network:\", full_unbalanced),\n",
    "    (\"Balanced (Importance) Network:\", full_balanced_importance), \n",
    "    (\"Balanced (Doctype/Branch) Network:\", full_balanced_doctypebranch)\n",
    "]:\n",
    "    print(f\"\\n{network_type}\")\n",
    "    for name, data in network_data.items():\n",
    "        print(f\"Network: {name}\")\n",
    "        print(f\"Nodes: {len(data['nodes'])}\")\n",
    "        print(f\"Edges: {count_total_edges(data['edges'])}\")\n",
    "        \n",
    "        # Get importance distribution\n",
    "        importance_dist = data['nodes']['importance'].value_counts()\n",
    "        print(\"\\nImportance Distribution:\")\n",
    "        for imp, count in importance_dist.items():\n",
    "            print(f\"  {imp}: {count} ({count/len(data['nodes'])*100:.1f}%)\")\n",
    "            \n",
    "        # Get doctype/branch distribution\n",
    "        doctype_dist = data['nodes']['doctypebranch'].value_counts()\n",
    "        print(\"\\nDoctype/Branch Distribution:\")\n",
    "        for doc, count in doctype_dist.items():\n",
    "            print(f\"  {doc}: {count} ({count/len(data['nodes'])*100:.1f}%)\")\n",
    "        print()\n",
    "\n",
    "\n",
    "# Load full split networks\n",
    "split_unbalanced = load_networks('networks/merged-article-edges/split-unbalanced')\n",
    "split_balanced_importance = load_networks('networks/merged-article-edges/split-balanced-importance')\n",
    "split_balanced_doctypebranch = load_networks('networks/merged-article-edges/split-balanced-doctypebranch')\n",
    "\n",
    "# Form networks with min 100 nodes\n",
    "importance_merged_100_cutoff_unbalanced = {name: data for name, data in split_unbalanced.items() if len(data['nodes']) >= 100}\n",
    "importance_merged_100_cutoff_balanced_importance = {name: data for name, data in split_balanced_importance.items() if len(data['nodes']) >= 100}\n",
    "importance_merged_100_cutoff_balanced_doctypebranch = {name: data for name, data in split_balanced_doctypebranch.items() if len(data['nodes']) >= 100}\n",
    "\n",
    "# Form networks with min 150 nodes\n",
    "importance_merged_150_cutoff_unbalanced = {name: data for name, data in split_unbalanced.items() if len(data['nodes']) >= 150}\n",
    "importance_merged_150_cutoff_balanced_importance = {name: data for name, data in split_balanced_importance.items() if len(data['nodes']) >= 150}\n",
    "importance_merged_150_cutoff_balanced_doctypebranch = {name: data for name, data in split_balanced_doctypebranch.items() if len(data['nodes']) >= 150}\n",
    "\n",
    "# Print network statistics\n",
    "def print_network_stats(network_dict: dict, name: str):\n",
    "    \"\"\"Print detailed statistics for a set of networks\"\"\"\n",
    "    print(f\"\\n=== {name} Statistics ===\")\n",
    "    print(f\"Total networks: {len(network_dict)}\")\n",
    "    \n",
    "    for network_name, data in network_dict.items():\n",
    "        print(f\"\\nNetwork: {network_name}\")\n",
    "        print(f\"Nodes: {len(data['nodes'])}\")\n",
    "        print(f\"Edges: {count_total_edges(data['edges'])}\")\n",
    "        \n",
    "        # Get importance distribution\n",
    "        importance_dist = data['nodes']['importance'].value_counts()\n",
    "        print(\"\\nImportance Distribution:\")\n",
    "        for imp, count in importance_dist.items():\n",
    "            print(f\"  {imp}: {count} ({count/len(data['nodes'])*100:.1f}%)\")\n",
    "            \n",
    "        # Get doctype/branch distribution\n",
    "        doctype_dist = data['nodes']['doctypebranch'].value_counts()\n",
    "        print(\"\\nDoctype/Branch Distribution:\")\n",
    "        for doc, count in doctype_dist.items():\n",
    "            print(f\"  {doc}: {count} ({count/len(data['nodes'])*100:.1f}%)\")\n",
    "\n",
    "# Print statistics for each cutoff level\n",
    "network_sets = [\n",
    "    (split_unbalanced, \"Split Networks (50+ nodes) - Unbalanced\"),\n",
    "    (split_balanced_importance, \"Split Networks (50+ nodes) - Balanced by Importance\"),\n",
    "    (split_balanced_doctypebranch, \"Split Networks (50+ nodes) - Balanced by Doctype/Branch\"),\n",
    "    (importance_merged_100_cutoff_unbalanced, \"Split Networks (100+ nodes) - Unbalanced\"),\n",
    "    (importance_merged_100_cutoff_balanced_importance, \"Split Networks (100+ nodes) - Balanced by Importance\"),\n",
    "    (importance_merged_100_cutoff_balanced_doctypebranch, \"Split Networks (100+ nodes) - Balanced by Doctype/Branch\"),\n",
    "    (importance_merged_150_cutoff_unbalanced, \"Split Networks (150+ nodes) - Unbalanced\"),\n",
    "    (importance_merged_150_cutoff_balanced_importance, \"Split Networks (150+ nodes) - Balanced by Importance\"),\n",
    "    (importance_merged_150_cutoff_balanced_doctypebranch, \"Split Networks (150+ nodes) - Balanced by Doctype/Branch\")\n",
    "]\n",
    "\n",
    "for network_dict, name in network_sets:\n",
    "    print_network_stats(network_dict, name)\n",
    "\n",
    "full_networks = [full_unbalanced, full_balanced_importance, full_balanced_doctypebranch]\n",
    "split_networks_50 = [split_unbalanced, split_balanced_importance, split_balanced_doctypebranch]\n",
    "split_networks_100 = [importance_merged_100_cutoff_unbalanced, importance_merged_100_cutoff_balanced_importance, importance_merged_100_cutoff_balanced_doctypebranch]\n",
    "split_networks_150 = [importance_merged_150_cutoff_unbalanced, importance_merged_150_cutoff_balanced_importance, importance_merged_150_cutoff_balanced_doctypebranch]\n",
    "\n",
    "# Define your network sets\n",
    "all_iterations = [full_networks, split_networks_50, split_networks_100, split_networks_150]\n",
    "iteration_names = ['importance-merged', 'importance-merged-50-cutoff', 'importance-merged-100-cutoff', 'importance-merged-150-cutoff']\n",
    "\n",
    "# Process each set separately\n",
    "for iteration, name in zip(all_iterations, iteration_names):\n",
    "    print(f\"\\n=== Processing {name} networks ===\")\n",
    "    \n",
    "    # Set output path\n",
    "    output_base = f'results/merged-subarticles-edges/{name}'\n",
    "    \n",
    "    # Create base directory if it doesn't exist\n",
    "    os.makedirs(output_base, exist_ok=True)\n",
    "    \n",
    "    # For importance-merged, store results to compare across types\n",
    "    cross_type_results = {} if name == 'importance-merged' else None\n",
    "    \n",
    "    # Process each type within the iteration (unbalanced, balanced_importance, balanced_doctypebranch)\n",
    "    for i, network_set in enumerate(iteration):\n",
    "        if i == 0:\n",
    "            print(\"\\nAnalyzing Unbalanced Networks\")\n",
    "            set_name = \"unbalanced\"\n",
    "        elif i == 1:\n",
    "            print(\"\\nAnalyzing Balanced Networks (Importance)\")\n",
    "            set_name = \"balanced-importance\"\n",
    "        elif i == 2:\n",
    "            print(\"\\nAnalyzing Balanced Networks (Doctype/Branch)\")\n",
    "            set_name = \"balanced-doctypebranch\"\n",
    "            \n",
    "        # Skip empty network sets\n",
    "        if not network_set:\n",
    "            print(f\"No networks in {set_name} set\")\n",
    "            continue\n",
    "            \n",
    "        # Create set directory\n",
    "        set_path = os.path.join(output_base, set_name)\n",
    "        os.makedirs(set_path, exist_ok=True)\n",
    "        os.makedirs(os.path.join(set_path, 'comparisons'), exist_ok=True)\n",
    "        \n",
    "        network_results = {}\n",
    "        \n",
    "        # Analyze each network in the set\n",
    "        for network_name, data in network_set.items():\n",
    "            print(f\"\\nAnalyzing network: {network_name}\")\n",
    "            try:\n",
    "                results = analyze_network(\n",
    "                    nodes_df=data['nodes'],\n",
    "                    edges_df=data['edges'],\n",
    "                    ground_truths=GROUND_TRUTHS,\n",
    "                    centralities=CENTRALITIES,\n",
    "                    composite_functions=['weight_composite_ranking', 'threshold_composite_ranking'],\n",
    "                    output_path=os.path.join(set_path, network_name)\n",
    "                )\n",
    "                network_results[network_name] = results\n",
    "                \n",
    "                # For importance-merged, store results for cross-type comparison\n",
    "                if name == 'importance-merged':\n",
    "                    cross_type_results[f\"{set_name}_{network_name}\"] = results\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error analyzing network {network_name}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        # Compare results within this specific set\n",
    "        if network_results:\n",
    "            try:\n",
    "                analysis = compare_networks(network_results, os.path.join(set_path, 'comparisons'))\n",
    "                visualize_network_commonalities(\n",
    "                    analysis, \n",
    "                    os.path.join(set_path, 'comparisons'),\n",
    "                    print_correlations=True,\n",
    "                    compare_all=True\n",
    "                )\n",
    "                print(f\"Successfully completed analysis for {name} - {set_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error in comparison/visualization for {name} - {set_name}: {str(e)}\")\n",
    "        else:\n",
    "            print(f\"No results to compare for {name} - {set_name}\")\n",
    "    \n",
    "    # For importance-merged, perform cross-type comparison\n",
    "    if name == 'importance-merged' and cross_type_results:\n",
    "        print(\"\\n=== Performing Cross-Type Comparison for Importance-Merged Networks ===\")\n",
    "        try:\n",
    "            # Create comparisons directory at the importance-merged level\n",
    "            cross_type_path = os.path.join(output_base, 'comparisons')\n",
    "            os.makedirs(cross_type_path, exist_ok=True)\n",
    "            \n",
    "            # Compare across all types\n",
    "            cross_type_analysis = compare_networks(cross_type_results, cross_type_path)\n",
    "            visualize_network_commonalities(\n",
    "                cross_type_analysis,\n",
    "                cross_type_path,\n",
    "                print_correlations=True,\n",
    "                compare_all=True\n",
    "            )\n",
    "            print(\"Successfully completed cross-type comparison for importance-merged networks\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error in cross-type comparison for importance-merged: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
